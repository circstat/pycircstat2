{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#pycircstat2-circular-statistics-with-python","title":"PyCircStat2: Circular statistics with Python","text":"<p>A rework of pycircstat.</p> <p>Key Features | Installlation |  API Reference | Examples ( Books | Topics )</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p>One-Stop Circular Data Analysis Pipeline with <code>Circular</code> Class </p> <p>The <code>Circular</code> class simplifies circular data analysis by providing automatic data transformation, descriptive statistics, hypothesis testing, and visualization tools\u2014all in one place.  </p> </li> <li> <p>Compatibility with Legacy APIs </p> <p>APIs for descriptive statistics and hypothesis testing follow the conventions established by the original circstat-matlab and pycircstat, ensuring ease of use for existing users.</p> </li> <li> <p>Wide-Ranging Circular Distributions </p> <p>The package supports a variety of circular distributions, including:  </p> <ul> <li>Symmetric distributions: Circular Uniform, Cardioid, Cartwright, Wrapped Normal, Wrapped Cauchy, von Mises (and its flat-top extension), and Jones-Pewsey.</li> <li>Asymmetric distributions: Sine-skewed Jones-Pewsey, Asymmetric Extended Jones-Pewsey, Inverse Batschelet.</li> </ul> </li> </ul> <p>Also see the full feature checklist here.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install the latest tagged version:</p> <pre><code>pip install pycircstat2\n</code></pre> <p>Or to install the development version, clone the repository and install it with <code>pip install -e</code>:</p> <pre><code>git clone https://github.com/circstat/pycircstat2\npip install -e pycircstat2\n</code></pre>"},{"location":"#api-reference","title":"API Reference","text":"<p>The API reference is available here.</p>"},{"location":"#example-notebooks","title":"Example notebooks","text":"<p>In the notebooks below, we reproduce examples and figures from a few textbooks on circular statistics.</p>"},{"location":"#books","title":"Books","text":"<ul> <li>Statistical Analysis of Circular Data (Fisher, 1993)</li> <li>Chapter 26 and 27 from Biostatistical Analysis (Zar, 2010).</li> <li>Circular Statistics in R (Pewsey, et al., 2014)</li> </ul> <p>And a few more examples on selective topics:</p>"},{"location":"#topics","title":"Topics","text":"<ol> <li>Utils</li> <li>Descriptive Statistics</li> <li>Hypothesis Testing</li> <li>Circular Models</li> <li>Regression</li> <li>Clustering</li> </ol>"},{"location":"feature-checklist/","title":"Feature Checklist","text":""},{"location":"feature-checklist/#1-descriptive-statistics","title":"1. Descriptive Statistics","text":"Feature PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Measures of Central Tendency Circular Mean <code>circ_mean</code> <code>mean(alpha)</code> <code>circ_mean(alpha)</code> <code>circ.mean</code> <code>mean.circular</code> Circular Mean CI <code>circ_mean_ci</code> <code>mean(alpha, ci=95)</code> <code>circ_confmean</code> - <code>mle.vonmises.bootstrap.ci</code> Circular Median <code>circ_median</code> <code>median</code> <code>circ_median</code> - <code>median.circular</code>/<code>medianHL.circular</code> Circular Median CI <code>circ_median_ci</code> - - - - Circular Quantile <code>circ_quantile</code> - - - <code>quantile.circular</code> Measures of Spread &amp; Dispersion Resultant Vector Length <code>circ_r</code> <code>resultant_vector_length</code> <code>circ_r</code> <code>est.rho</code> <code>rho.circular</code> Angular Variance <code>angular_var</code> <code>avar</code> <code>circ_var</code> - <code>angular.variance</code> Angular Standard Deviation <code>angular_std</code> <code>astd</code> <code>circ_std</code> - <code>angular.deviation</code> Circular Variance <code>circ_var</code> <code>var</code> <code>circ_var</code> <code>circ.disp</code> <code>var.circular</code> Circular Standard Deviation <code>circ_std</code> <code>std</code> <code>circ_std</code> - <code>sd.circular</code> Circular Dispersion <code>circ_dispersion</code> - - - - Higher-Order Statistics Circular Moment <code>circ_moment</code> <code>moment</code> <code>circ_moment</code> <code>tri.moment</code> <code>trigonometric.moment</code> Circular Skewness <code>circ_skewness</code> <code>skewness</code> <code>circ_skewness</code> - - Circular Kurtosis <code>circ_kurtosis</code> <code>kurtoisis</code> <code>circ_kurtosis</code> - - Distance &amp; Pairwise Comparisons Mean deviation <code>circ_mean_deviation</code> - - - <code>meandeviation</code> Circular Distance <code>circ_dist</code> <code>cdist</code> <code>circ_dist</code> - - Pairwise Circular Distance <code>circ_pairdist</code> <code>pairwise_cdiff</code> <code>circ_dist2</code> - <code>dist.circular</code>"},{"location":"feature-checklist/#2-hypothesis-testing","title":"2. Hypothesis Testing","text":""},{"location":"feature-checklist/#one-sample-tests-for-significance","title":"One-Sample Tests for Significance","text":"Feature H0 PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Mean Direction Rayleigh Test \\(\\rho=0\\) <sup>1</sup> <code>rayleigh_test</code> <code>rayleigh</code> <code>circ_rtest</code> <code>r.test</code> <code>rayleigh.test</code> V-Test \\(\\rho=0\\) <code>V_test</code> <code>vtest</code> <code>circ_vtest</code> <code>v0.test</code> - One-sample Test \\(\\tilde\\mu=\u03bc_0\\) <code>one_sample_test</code> <code>mtest</code> <code>circ_mtest</code> - - Change Point Test no change point <code>change_point_test</code> - - <code>change.pt</code> <code>change.point</code> Median Direction Hodges-Ajne (omnibus) Test \\(\\rho=0\\) <code>omnibus_test</code> <code>omnibus</code> <code>circ_otest</code> - - Batschelet Test \\(\\rho=0\\) <code>batschelet_test</code> - - - - Binomial Test \\(\\tilde\\theta = \\theta_0\\) <sup>2</sup> <code>binomial_test</code> <code>medtest</code> <code>circ_medtest</code> - - Symmetry Test around median \\(\\text{symmetry}\\) <code>symmetry_test</code> <code>symtest</code> <code>circ_symtest</code> - -"},{"location":"feature-checklist/#multi-sample-tests-for-significance","title":"Multi-Sample Tests for Significance","text":"Feature H0 PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Mean Direction Circular Analysis of Variance \\(\\mu_1 = \\dots = \\mu_n\\) <code>circ_anova</code> - - - <code>aov.circular</code> Watson-Williams Test <sup>4</sup> \\(\\mu_1 = \\dots = \\mu_n\\) <code>watson_williams_test</code> <code>watson_williams</code> <code>circ_wwtest</code> - <code>watson.williams.test</code> Harrison-Kanji Test<sup>5</sup> \\(\\mu_1 = \\dots = \\mu_n\\) <code>harrison_kanji_test</code> <code>hktest</code> <code>circ_hktest</code> - - Median Direction Common Median Test \\(\\tilde{\\theta}_1 = \\dots = \\tilde{\\theta}_n\\) <code>common_median_test</code> <code>cmtest</code> <code>circ_cmtest</code> - - Concentration Concentration Test (F-test) \\(\\kappa_1 = \\dots = \\kappa_n\\) <code>concentration_test</code> - <code>circ_ktest</code> - - Equal Kappa Test \\(\\kappa_1 = \\dots = \\kappa_n\\) <code>equal_kappa_test</code> - - - <code>equal.kappa.test</code> Distribution Homogeneity Watson's U2 Test \\(F_1 = F_2\\) <sup>3</sup> <code>watson_u2_test</code> - - <code>watson.two</code> <code>watson.two.test</code> Wallraff Test \\(F_1 = F_2\\) <code>wallraff_test</code> - - - <code>wallraff.test</code> Wheeler-Watson Test \\(F_1 = F_2\\) <code>wheeler_watson_test</code> - - - <code>watson.wheeler.test</code> Angular Randomization Test \\(F_1 = F_2\\) <code>angular_randomisation_test</code> - - - - Rao's Tests for Homogeneity \\(F_1 = F_2\\) <code>rao_homogeneity_test</code> - - <code>rao.homogeneity</code> <code>rao.test</code>"},{"location":"feature-checklist/#goodness-of-fit-tests","title":"Goodness-of-fit Tests","text":"Feature H0 PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Kuiper\u2019s Test \\(\\rho = 0\\) <code>circ_kuiper_test</code> <code>kupier</code> <code>circ_kuipertest</code> <code>kuiper</code> <code>kuiper.test</code> Rao\u2019s Spacing Test \\(\\rho = 0\\) <code>rao_spacing_test</code> <code>raospacing</code> <code>circ_raotest</code> <code>rao.spacing</code> <code>rao.spacing.test</code> Watson's Test \\(\\rho = 0\\) <code>watson_test</code> - - <code>watson</code> <code>watson.test</code> Circular Range Test \\(\\rho = 0\\) <code>circ_range_test</code> - - <code>circ_range</code> <code>range.circular</code>"},{"location":"feature-checklist/#3-correlation-regression","title":"3. Correlation &amp; Regression","text":"Feature PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Circular-Circular Correlation <code>circ_corrcc</code> <code>corrcc</code> <code>circ_corrcc</code> <code>circ.cor</code> <code>cor.circular</code> Circular-Linear Correlation <code>circ_corrcl</code> <code>corrcl</code> <code>circ_corrcl</code> - - Circular-Circular Regression <code>CCRegression</code> - - <code>circ.reg</code> <code>lm.circular(type=\"c-c\")</code> Circular-Linear Regression <code>CLRegression</code> - - - <code>lm.circular(type=\"c-l\")</code>"},{"location":"feature-checklist/#4-circular-distributions","title":"4. Circular Distributions","text":""},{"location":"feature-checklist/#symmetric-circular-distributions","title":"Symmetric Circular Distributions","text":"Feature Method PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Circular Uniform PDF <code>circularuniform.pdf</code> - - - <code>dcircularuniform</code> CDF <code>circularuniform.cdf</code> - - - - PPF <code>circularuniform.ppf</code> - - - - RVS <code>circularuniform.rvs</code> - - - <code>rcircularuniform</code> Fit <code>circularuniform.fit</code> - - - - Triangular PDF <code>triangular.pdf</code> <code>triangular.pdf</code> - <code>dtri</code> - CDF <code>triangular.cdf</code> <code>triangular.cdf</code> - - - PPF <code>triangular.ppf</code> <code>triangular.ppf</code> - - - RVS <code>triangular.rvs</code> <code>triangular.rvs</code> - <code>rtri</code> - Fit <code>triangular.fit</code> <code>triangular.fit</code> - - - Cardioid PDF <code>cardioid.pdf</code> <code>cardioid.pdf</code> - <code>dcard</code> <code>dcardioid</code> CDF <code>cardioid.cdf</code> <code>cardioid.cdf</code> - - - PPF <code>cardioid.ppf</code> <code>cardioid.ppf</code> - - RVS <code>cardioid.rvs</code> <code>cardioid.rvs</code> - <code>rcard</code> <code>rcardioid</code> Fit <code>cardioid.fit</code> <code>cardioid.fit</code> - - Cartwright PDF <code>cartwright.pdf</code> - - - <code>dcarthwrite</code> CDF <code>cartwright.cdf</code> - - - - PPF <code>cartwright.ppf</code> - - - - RVS <code>cartwright.rvs</code> - - - - Fit <code>cartwright.fit</code> - - - - Wrapped Normal PDF <code>wrapnorm.pdf</code> - - <code>dwrpnorm</code> <code>dwrappednormal</code> CDF <code>wrapnorm.cdf</code> - - - <code>pwrappednormal</code> PPF <code>wrapnorm.ppf</code> - - - <code>qwrappednormal</code> RVS <code>wrapnorm.rvs</code> - - <code>rwrpnorm</code> <code>rwrappednormal</code> Fit <code>wrapnorm.fit</code> - - - <code>mle.wrappednormal</code> Wrapped Cauchy PDF <code>wrapcauchy.pdf</code> - - <code>dwrpcauchy</code> <code>dwrappedcauchy</code> CDF <code>wrapcauchy.cdf</code> - - - - PPF <code>wrapcauchy.ppf</code> - - - - RVS <code>wrapcauchy.rvs</code> - - <code>rwrpcauchy</code> <code>rwrappedcauchy</code> Fit <code>wrapcauchy.fit</code> - - - <code>mle.wrappedcauchy</code> Von Mises PDF <code>vonmises.pdf</code> - <code>circ_vmpdf</code> <code>dvm</code> <code>dvonmises</code> CDF <code>vonmises.cdf</code> - - <code>pvm</code> <code>pvonmises</code> PPF <code>vonmises.ppf</code> - - - <code>qvonmises</code> RVS <code>vonmises.rvs</code> - <code>circ_vmrnd</code> <code>rvm</code> <code>rvonmises</code> Fit <code>vonmises.fit</code> - <code>circ_vmpar</code> <code>vm.ml</code> <code>mle.vonmises</code> Flattopped Von Mises PDF <code>vonmises_flattopped.pdf</code> - - - - CDF <code>vonmises_flattopped.cdf</code> - - - - PPF <code>vonmises_flattopped.ppf</code> - - - - RVS <code>vonmises_flattopped.rvs</code> - - - - Fit <code>vonmises_flattopped.fit</code> - - - - Jones-Pewsey PDF <code>jonespewsey.pdf</code> - - - <code>djonespewsey</code> CDF <code>jonespewsey.cdf</code> - - - - PPF <code>jonespewsey.ppf</code> - - - - RVS <code>jonespewsey.rvs</code> - - - - Fit <code>jonespewsey.fit</code> - - - - Kato-Jones PDF - - - - <code>dkatojones</code> CDF - - - - - PPF - - - - - RVS - - - - <code>rkatojones</code> Fit - - - - -"},{"location":"feature-checklist/#asymmetric-circular-distributions","title":"Asymmetric Circular Distributions","text":"Feature Method PyCircStat2 PyCircStat CircStat (MATLAB) CircStats (R) circular (R) Jones-Pewsey Sine-Skewed PDF <code>jonespewsey_sineskewed.pdf</code> - - - - CDF <code>jonespewsey_sineskewed.cdf</code> - - - - PPF <code>jonespewsey_sineskewed.ppf</code> - - - - RVS <code>jonespewsey_sineskewed.rvs</code> - - - - Fit <code>jonespewsey_sineskewed.fit</code> - - - - Jones-Pewsey Asymmetric PDF <code>jonespewsey_asym.pdf</code> - - - - CDF <code>jonespewsey_asym.cdf</code> - - - - PPF <code>jonespewsey_asym.ppf</code> - - - - RVS <code>jonespewsey_asym.rvs</code> - - - - Fit <code>jonespewsey_asym.fit</code> - - - - Inverse Batschelet PDF <code>inverse_batschelet.pdf</code> - - - - CDF <code>inverse_batschelet.cdf</code> - - - - PPF <code>inverse_batschelet.ppf</code> - - - - RVS <code>inverse_batschelet.rvs</code> - - - - Fit <code>inverse_batschelet.fit</code> - - - - Wrapped Stable PDF <code>wrapstable.pdf</code> - - - - CDF <code>wrapstable.cdf</code> - - - - PPF <code>wrapstable.ppf</code> - - - - RVS <code>wrapstable.rvs</code> - - <code>rwrpstab</code> - Fit <code>wrapstable.fit</code> - - - - Asymmetric Trangular PDF - - - - <code>dasytriangular</code> Projected Normal PDF - - - - <code>dpnorm</code> RVS - - - - <code>rpnorm</code> <ol> <li> <p>\\(\\rho=0\\) stands for uniform distributed.\u00a0\u21a9</p> </li> <li> <p>\\(\\theta\\) stands for median.\u00a0\u21a9</p> </li> <li> <p>\\(F\\) stands for distributions.\u00a0\u21a9</p> </li> <li> <p>Yet anothr one-way ANOVA.\u00a0\u21a9</p> </li> <li> <p>Two-way ANOVA.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/base/","title":"Circular Data Base","text":""},{"location":"reference/base/#pycircstat2.base.Circular","title":"<code>Circular</code>","text":"<p>Circular Data Analysis Object.</p> <p>This class encapsulates circular data and provides tools for descriptive statistics, hypothesis testing, and visualization. It automatically computes key circular statistics and tests when the data are loaded.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array - like(n)</code> <p>The raw circular data, typically in degrees, radians, or other angular units.</p> required <code>w</code> <code>array - like(n) or None</code> <p>Frequencies or weights for the data points. If None, all data points are treated equally. Default is None.</p> <code>None</code> <code>bins</code> <code>(int, array - like(n + 1) or None)</code> <p>Number of bins or bin edges to group the data. If None, the data is not binned. Default is None.</p> <code>None</code> <code>unit</code> <code>str</code> <p>Unit of the input data. Must be one of {\"degree\", \"radian\", \"hour\"}. Default is \"degree\".</p> <code>'degree'</code> <code>full_cycle</code> <code>int, float, or None</code> <p>The total range of values that complete one full cycle in the chosen unit. If None, the value is inferred based on the unit:</p> <ul> <li>360 for degrees,</li> <li>\\(2\\pi\\) for radians,</li> <li>24 for hours.</li> </ul> <p>Custom values can be set explicitly for other units. Default is None.</p> <code>None</code> <code>n_clusters_max</code> <code>int</code> <p>Maximum number of clusters to test for a mixture of von Mises distributions. Default is 1.</p> <code>1</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments to customize the computation of statistics such as the median.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>n</code> <code>int</code> <p>Total sample size, including weights.</p> <code>mean</code> <code>float</code> <p>Angular mean in radians.</p> <code>mean_ci</code> <code>tuple of float</code> <p>Confidence interval for the angular mean, if applicable.</p> <code>median</code> <code>float</code> <p>Angular median in radians.</p> <code>median_ci</code> <code>tuple of float</code> <p>Confidence interval for the angular median, if computed.</p> <code>r</code> <code>float</code> <p>Resultant vector length, measuring data concentration (0 to 1).</p> <code>kappa</code> <code>float</code> <p>Concentration parameter, measuring data sharpness.</p> <code>s</code> <code>float</code> <p>Angular deviation, measuring data dispersion.</p> <code>skewness</code> <code>float</code> <p>Circular skewness of the data.</p> <code>kurtosis</code> <code>float</code> <p>Circular kurtosis of the data.</p> <code>R</code> <code>float</code> <p>Rayleigh's R statistic, derived from the resultant vector length.</p> <code>mixtures</code> <code>list</code> <p>Mixture models of von Mises distributions fitted to the data (if <code>n_clusters_max &gt; 1</code>).</p> <p>Methods:</p> Name Description <code>summary</code> <p>Returns a detailed summary of the computed statistics.</p> <code>plot</code> <p>Visualizes the circular data, including histograms and other representations.</p> Notes <ul> <li>Angular data is automatically converted to radians for internal computations.</li> <li>Data can be grouped or ungrouped. Ungrouped data is handled by assigning equal weights.</li> <li>The Rayleigh test for angular mean is computed, with p-values indicating significance.</li> <li>Confidence intervals for the angular mean are approximated using either bootstrap   or dispersion methods, depending on the sample size and significance.</li> </ul> References <ul> <li>Zar, J. H. (2010). Biostatistical Analysis (5th Edition). Pearson.</li> <li>Fisher, N. I. (1995). Statistical Analysis of Circular Data. Cambridge University Press.</li> </ul> <p>Examples:</p>"},{"location":"reference/base/#pycircstat2.base.Circular--basic-usage","title":"Basic Usage","text":"<pre><code>data = [30, 60, 90, 120, 150]\ncirc = Circular(data, unit=\"degree\")\nprint(circ.summary())\n</code></pre>"},{"location":"reference/base/#pycircstat2.base.Circular--grouped-data","title":"Grouped Data","text":"<pre><code>data = [0, 30, 60, 90]\nweights = [1, 2, 3, 4]\ncirc = Circular(data, w=weights, unit=\"degree\")\nprint(circ.summary())\n</code></pre> Source code in <code>pycircstat2/base.py</code> <pre><code>class Circular:\n    r\"\"\"\n    Circular Data Analysis Object.\n\n    This class encapsulates circular data and provides tools for descriptive statistics,\n    hypothesis testing, and visualization. It automatically computes key circular\n    statistics and tests when the data are loaded.\n\n    Parameters\n    ----------\n    data : array-like (n,)\n        The raw circular data, typically in degrees, radians, or other angular units.\n\n    w : array-like (n,) or None, optional\n        Frequencies or weights for the data points. If None, all data points are treated equally.\n        Default is None.\n\n    bins : int, array-like (n+1,) or None, optional\n        Number of bins or bin edges to group the data. If None, the data is not binned.\n        Default is None.\n\n    unit : str, optional\n        Unit of the input data. Must be one of {\"degree\", \"radian\", \"hour\"}.\n        Default is \"degree\".\n\n    full_cycle : int, float, or None, optional\n        The total range of values that complete one full cycle in the chosen unit.\n        If None, the value is inferred based on the unit:\n\n        - 360 for degrees,\n        - $2\\pi$ for radians,\n        - 24 for hours.\n\n        Custom values can be set explicitly for other units.\n        Default is None.\n\n    n_clusters_max : int, optional\n        Maximum number of clusters to test for a mixture of von Mises distributions.\n        Default is 1.\n\n    kwargs : dict, optional\n        Additional keyword arguments to customize the computation of statistics such as the median.\n\n    Attributes\n    ----------\n    n : int\n        Total sample size, including weights.\n\n    mean : float\n        Angular mean in radians.\n\n    mean_ci : tuple of float\n        Confidence interval for the angular mean, if applicable.\n\n    median : float\n        Angular median in radians.\n\n    median_ci : tuple of float\n        Confidence interval for the angular median, if computed.\n\n    r : float\n        Resultant vector length, measuring data concentration (0 to 1).\n\n    kappa : float\n        Concentration parameter, measuring data sharpness.\n\n    s : float\n        Angular deviation, measuring data dispersion.\n\n    skewness : float\n        Circular skewness of the data.\n\n    kurtosis : float\n        Circular kurtosis of the data.\n\n    R : float\n        Rayleigh's R statistic, derived from the resultant vector length.\n\n    mixtures : list\n        Mixture models of von Mises distributions fitted to the data (if `n_clusters_max &gt; 1`).\n\n    Methods\n    -------\n    summary()\n        Returns a detailed summary of the computed statistics.\n\n    plot(ax=None, kind=None, **kwargs)\n        Visualizes the circular data, including histograms and other representations.\n\n    Notes\n    -----\n    - Angular data is automatically converted to radians for internal computations.\n    - Data can be grouped or ungrouped. Ungrouped data is handled by assigning equal weights.\n    - The Rayleigh test for angular mean is computed, with p-values indicating significance.\n    - Confidence intervals for the angular mean are approximated using either bootstrap\n      or dispersion methods, depending on the sample size and significance.\n\n    References\n    ----------\n    - Zar, J. H. (2010). Biostatistical Analysis (5th Edition). Pearson.\n    - Fisher, N. I. (1995). Statistical Analysis of Circular Data. Cambridge University Press.\n\n    Examples\n    --------\n\n    #### Basic Usage\n\n    ```python\n    data = [30, 60, 90, 120, 150]\n    circ = Circular(data, unit=\"degree\")\n    print(circ.summary())\n    ```\n\n    #### Grouped Data\n\n    ```python\n    data = [0, 30, 60, 90]\n    weights = [1, 2, 3, 4]\n    circ = Circular(data, w=weights, unit=\"degree\")\n    print(circ.summary())\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        data: Union[np.ndarray, list],  # angle\n        w: Optional[Union[np.ndarray, list]] = None,  # frequency\n        bins: Optional[Union[int, np.ndarray]] = None,\n        unit: str = \"degree\",\n        full_cycle: Optional[Union[\n            int, float\n        ]] = None,  # number of intervals in the full cycle\n        n_clusters_max: int = 1,  # number of clusters to be tested for mixture of von Mises\n        rotate: Optional[float] = None, # in rad\n        **kwargs,\n    ):\n        # meta\n        self.unit = unit\n        if full_cycle is None:\n            if unit == \"degree\":\n                self.full_cycle = full_cycle = 360\n            elif unit == \"radian\":\n                self.full_cycle = full_cycle = 2 * np.pi\n            elif unit == \"hour\":\n                self.full_cycle = full_cycle = 24\n            else:\n                raise ValueError(\n                    \"You need to provide a value for `full_cycle` if it is not `degree` or `hour`.\"\n                )\n        else:\n            self.full_cycle = full_cycle\n\n        self.n_clusters_max = n_clusters_max\n        self.kwargs_median = kwargs_median = {\n            **{\n                \"method\": \"deviation\",\n                \"return_average\": True,\n                \"average_method\": \"all\",\n            },\n            **kwargs.pop(\"kwargs_median\", {}),\n        }\n        self.kwargs_mean_ci = kwargs_mean_ci = kwargs.pop(\"kwargs_mean_ci\", None)\n\n        # data\n        self.data = data = np.array(data) if isinstance(data, list) else data\n        self.alpha = alpha = np.array(data2rad(data, full_cycle)) if rotate is None else rotate_data(np.array(data2rad(data, full_cycle)), rotate, unit=\"radian\")\n\n        # data preprocessing\n        if bins is None:\n            if w is None:  # ungrouped data, because no `w` is provided.\n                self.w = w = np.ones_like(alpha).astype(int)\n                self.grouped = grouped = False\n                self.bin_size = bin_size = 0.0\n            else:  # grouped data\n                assert len(w) == len(alpha), \"`w` and `data` must be the same length.\"\n                assert len(w) == len(\n                    np.arange(0, 2 * np.pi, 2 * np.pi / len(w))\n                ), \"Grouped data should included empty bins.\"\n                self.w = w = np.asarray(w)\n                self.grouped = grouped = True\n                self.bin_size = bin_size = np.diff(alpha).min()\n                self.alpha_lb = alpha - bin_size / 2\n                self.alpha_ub = alpha + bin_size / 2\n\n        # bin data usingse np.histogram\n        else:\n            if isinstance(bins, int) or isinstance(bins, np.ndarray):\n                w, alpha = np.histogram(\n                    alpha, bins=bins, range=(0, 2 * np.pi)\n                )  # np.histogram return bin edges\n            self.w = w = np.asarray(w)\n            self.alpha_lb = alpha[:-1]  # bin lower bound\n            self.alpha_ub = alpha[1:]  # bin upper bound\n            self.alpha = alpha = 0.5 * (alpha[:-1] + alpha[1:])  # get bin centers\n            self.grouped = grouped = True\n            self.bin_size = bin_size = np.diff(alpha).min()\n\n        # sample size\n        self.n = n = np.sum(w).astype(int)\n\n        # angular mean and resultant vector length\n        self.mean, self.r = (_, r) = circ_mean_and_r(alpha=alpha, w=w)\n\n        # z-score and p-value from rayleigh test for angular mean\n        self.mean_test_result = rayleigh_test_result = rayleigh_test(n=n, r=r)\n        mean_pval = rayleigh_test_result.pval\n\n        # Rayleigh's R\n        self.R = n * r\n\n        # kappa\n        self.kappa = circ_kappa(r=r, n=n)\n\n        # confidence interval for angular mean\n        # in practice, the equations for approximating mean ci for 8 &lt;= n &lt;= 12 in zar 2010\n        # can still yield nan\n        if self.kwargs_mean_ci is None:\n            if mean_pval &lt; 0.05 and (8 &lt;= self.n &lt; 25):\n                self.method_mean_ci = method_mean_ci = \"bootstrap\"\n                self.mean_ci_level = mean_ci_level = 0.95\n            elif mean_pval &lt; 0.05 and self.n &gt;= 25:\n                # Eq 4.22 (Fisher, 1995)\n                self.method_mean_ci = method_mean_ci = \"dispersion\"\n                self.mean_ci_level = mean_ci_level = 0.95\n            else:  # mean_pval &gt; 0.05\n                self.method_mean_ci = method_mean_ci = None\n                self.mean_ci_level = mean_ci_level = np.nan\n        else:\n            self.method_mean_ci = method_mean_ci = kwargs_mean_ci.pop(\n                \"method\", \"bootstrap\"\n            )\n            self.mean_ci_level = mean_ci_level = 0.95\n\n        if method_mean_ci is not None and mean_pval &lt; 0.05:\n            self.mean_lb, self.mean_ub = mean_lb, mean_ub = circ_mean_ci(\n                alpha=self.alpha,\n                w=self.w,\n                mean=self.mean,\n                r=self.r,\n                n=self.n,\n                ci=mean_ci_level,\n                method=method_mean_ci,\n            )\n        else:\n            self.mean_lb, self.mean_ub = np.nan, np.nan\n\n        # angular deviation, circular standard deviation, adjusted resultant vector length (if needed)\n        self.s = angular_std(r=r, bin_size=bin_size)\n        self.s0 = circ_std(r=r, bin_size=bin_size)\n\n        # angular median\n        if n &gt; 10000 and kwargs_median[\"method\"] is not None:\n            print(\n                \"Sample size is large (n&gt;10000), it will take a while to find the median.\\nOr set `kwargs_median={'method': None}` to skip.\"\n            )\n\n        self.median = median = circ_median(\n            alpha=alpha,\n            w=w,\n            method=kwargs_median[\"method\"],\n            return_average=kwargs_median[\"return_average\"],\n            average_method=kwargs_median[\"average_method\"],\n        )\n\n        # confidence inerval for angular median (only for ungrouped data)\n        # it's unclear how to do it for grouped data.\n        if not grouped and not np.isnan(median):\n            self.median_lb, self.median_ub, self.median_ci_level = circ_median_ci(\n                median=float(median), alpha=alpha\n            )\n\n        self.skewness = circ_skewness(alpha=alpha, w=w)\n        self.kurtosis = circ_kurtosis(alpha=alpha, w=w)\n\n        # check multimodality\n        self.mixtures = []\n        if n_clusters_max &gt; 1:\n            for k in range(1, n_clusters_max + 1):\n                m = MovM(\n                    n_clusters=k,\n                    full_cycle=full_cycle,\n                    unit=\"radian\",\n                    random_seed=0,\n                )\n                m.fit(np.repeat(alpha, w))\n                self.mixtures.append(m)\n            self.mixtures_BIC = [m.compute_BIC() for m in self.mixtures]\n            if not np.isnan(self.mixtures_BIC).all():\n                self.mixture_opt = self.mixtures[np.nanargmin(self.mixtures_BIC)]\n            else:\n                self.mixture_opt = None\n\n    def __repr__(self):\n        unit = self.unit\n        k = self.full_cycle\n\n        docs = \"Circular Data\\n\"\n        docs += \"=============\\n\\n\"\n\n        docs += \"Summary\\n\"\n        docs += \"-------\\n\"\n        docs += \"  Grouped?: Yes\\n\" if self.grouped else \"  Grouped?: No\\n\"\n        if self.n_clusters_max &gt; 1 and self.mixture_opt is not None:\n            docs += (\n                \"  Unimodal?: Yes \\n\"\n                if len(self.mixture_opt.m_) == 1\n                else f\"  Unimodal?: No (n_clusters={len(self.mixture_opt.m_)}) \\n\"\n            )\n\n        docs += f\"  Unit: {unit}\\n\"\n        docs += f\"  Sample size: {self.n}\\n\"\n\n        docs += f\"  Angular mean: {rad2data(self.mean, k=k):.02f} ( p={self.mean_test_result.pval:.04f} {significance_code(self.mean_test_result.pval)} ) \\n\"\n\n        if hasattr(self, \"mean_lb\") and not np.isnan(self.mean_lb):\n            docs += f\"  Angular mean CI ({self.mean_ci_level:.2f}): {rad2data(self.mean_lb, k=k):.02f} - {rad2data(self.mean_ub, k=k):.02f}\\n\"\n\n        docs += f\"  Angular median: {rad2data(self.median, k=k):.02f} \\n\"\n        if hasattr(self, \"median_lb\") and not np.isnan(self.median_lb):\n            docs += f\"  Angular median CI ({self.median_ci_level:.2f}): {rad2data(self.median_lb, k=k):.02f} - {rad2data(self.median_ub, k=k):.02f}\\n\"\n\n        docs += f\"  Angular deviation (s): {rad2data(self.s, k=k):.02f} \\n\"\n        docs += f\"  Circular standard deviation (s0): {rad2data(self.s0, k=k):.02f} \\n\"\n        docs += f\"  Concentration (r): {self.r:0.2f}\\n\"\n        docs += f\"  Concentration (kappa): {self.kappa:0.2f}\\n\"\n        docs += f\"  Skewness: {self.skewness:0.3f}\\n\"\n        docs += f\"  Kurtosis: {self.kurtosis:0.3f}\\n\"\n\n        docs += \"\\n\"\n\n        docs += \"Signif. codes:\\n\"\n        docs += \"--------------\\n\"\n        docs += \" 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\\n\\n\"\n\n        docs += \"Method\\n\"\n        docs += \"------\\n\"\n        docs += f\"  Angular median: {self.kwargs_median['method']}\\n\"\n        docs += f\"  Angular mean CI: {self.method_mean_ci}\\n\"\n\n        return docs\n\n    def __str__(self):\n        return self.__repr__()\n\n    def summary(self):\n        r\"\"\"\n        Summary of basic statistics for circular data.\n\n        This method generates a textual summary of the key descriptive and inferential\n        statistics computed for the circular data. It provides information about\n        the data type, concentration, dispersion, and more.\n\n        The summary includes the following components:\n\n        1. **Grouping**:\n\n            Indicates whether the data is grouped (binned) or ungrouped.\n\n        2. **Unimodality**:\n\n            For models with mixtures of von Mises distributions, it specifies whether\n        the data is unimodal or multimodal, along with the number of clusters if applicable.\n\n        3. **Data Characteristics**:\n\n            - The unit of measurement (e.g., degrees, radians, hours).\n            - Total sample size, including weights if provided.\n\n        4. **Angular Mean**:\n\n            - The angular mean, with its corresponding p-value from the Rayleigh test.\n            - The confidence interval (CI) for the angular mean, if available.\n\n        5. **Angular Median**:\n\n            - The angular median, representing the central tendency.\n            - The confidence interval (CI) for the angular median, if applicable.\n\n        6. **Measures of Dispersion**:\n\n            - Angular deviation ($s$): A measure of spread in circular data.\n            - Circular standard deviation ($s_0$): An alternative dispersion measure.\n\n        7. **Measures of Concentration**:\n\n            - Resultant vector length ($r$): A measure of data concentration, ranging from 0 (uniform) to 1 (highly concentrated).\n            - Concentration parameter ($\\kappa$): Indicates sharpness or clustering of the data.\n\n        8. **Higher-Order Statistics**:\n\n            - Circular skewness: A measure of asymmetry.\n            - Circular kurtosis: A measure of peakedness or flatness relative to a uniform distribution.\n\n        9. **Significance Codes**:\n\n            - A guide to interpret the p-values of statistical tests.\n\n        10. **Methods**:\n\n            - The method used for calculating the angular median.\n            - The method used for estimating confidence intervals for the angular mean.\n        \"\"\"\n\n        return self.__repr__()\n\n    def plot(self, ax=None, config=None):\n        \"\"\"\n        Visualize circular data.\n\n        This method provides various visualization options for circular data, including scatter\n        plots, density plots, and rose diagrams. It is a wrapper around the `circ_plot` function.\n\n        Parameters\n        ----------\n        ax : matplotlib.axes._axes.Axes, optional\n            The matplotlib Axes object where the plot will be drawn. If None, a new Axes object\n            is created. Default is None.\n        config: dict, optional\n            Configuration dictionary that overrides defaults.\n\n        Returns\n        -------\n        ax : matplotlib.axes._axes.Axes\n            The matplotlib Axes object containing the plot.\n\n        Notes\n        -----\n        - This method supports both grouped and ungrouped data.\n        - Density estimation can be performed using either nonparametric methods or mixtures\n        of von Mises distributions.\n        - The rose diagram represents grouped data as a histogram over angular bins.\n        - Confidence intervals for the mean and median are plotted as arcs on the circle.\n\n        Examples\n        --------\n        ```\n        from pycircstat2 import load_data, Circular\n\n        data = load_data(\"B3\", source=\"fisher\")[\"\u03b8\"].values\n        c = Circular(data, unit=\"degree\")\n        c.plot(config={\"scatter\": {\"color\" : \"blue\", \"size\": 15}})\n        ```\n\n        See docstring of `circ_plot` for more examples and customization options.\n        \"\"\"\n        ax = circ_plot(self, ax=ax, config=config)\n</code></pre>"},{"location":"reference/base/#pycircstat2.base.Circular.summary","title":"<code>summary()</code>","text":"<p>Summary of basic statistics for circular data.</p> <p>This method generates a textual summary of the key descriptive and inferential statistics computed for the circular data. It provides information about the data type, concentration, dispersion, and more.</p> <p>The summary includes the following components:</p> <ol> <li> <p>Grouping:</p> <p>Indicates whether the data is grouped (binned) or ungrouped.</p> </li> <li> <p>Unimodality:</p> <p>For models with mixtures of von Mises distributions, it specifies whether the data is unimodal or multimodal, along with the number of clusters if applicable.</p> </li> <li> <p>Data Characteristics:</p> <ul> <li>The unit of measurement (e.g., degrees, radians, hours).</li> <li>Total sample size, including weights if provided.</li> </ul> </li> <li> <p>Angular Mean:</p> <ul> <li>The angular mean, with its corresponding p-value from the Rayleigh test.</li> <li>The confidence interval (CI) for the angular mean, if available.</li> </ul> </li> <li> <p>Angular Median:</p> <ul> <li>The angular median, representing the central tendency.</li> <li>The confidence interval (CI) for the angular median, if applicable.</li> </ul> </li> <li> <p>Measures of Dispersion:</p> <ul> <li>Angular deviation (\\(s\\)): A measure of spread in circular data.</li> <li>Circular standard deviation (\\(s_0\\)): An alternative dispersion measure.</li> </ul> </li> <li> <p>Measures of Concentration:</p> <ul> <li>Resultant vector length (\\(r\\)): A measure of data concentration, ranging from 0 (uniform) to 1 (highly concentrated).</li> <li>Concentration parameter (\\(\\kappa\\)): Indicates sharpness or clustering of the data.</li> </ul> </li> <li> <p>Higher-Order Statistics:</p> <ul> <li>Circular skewness: A measure of asymmetry.</li> <li>Circular kurtosis: A measure of peakedness or flatness relative to a uniform distribution.</li> </ul> </li> <li> <p>Significance Codes:</p> <ul> <li>A guide to interpret the p-values of statistical tests.</li> </ul> </li> <li> <p>Methods:</p> <ul> <li>The method used for calculating the angular median.</li> <li>The method used for estimating confidence intervals for the angular mean.</li> </ul> </li> </ol> Source code in <code>pycircstat2/base.py</code> <pre><code>def summary(self):\n    r\"\"\"\n    Summary of basic statistics for circular data.\n\n    This method generates a textual summary of the key descriptive and inferential\n    statistics computed for the circular data. It provides information about\n    the data type, concentration, dispersion, and more.\n\n    The summary includes the following components:\n\n    1. **Grouping**:\n\n        Indicates whether the data is grouped (binned) or ungrouped.\n\n    2. **Unimodality**:\n\n        For models with mixtures of von Mises distributions, it specifies whether\n    the data is unimodal or multimodal, along with the number of clusters if applicable.\n\n    3. **Data Characteristics**:\n\n        - The unit of measurement (e.g., degrees, radians, hours).\n        - Total sample size, including weights if provided.\n\n    4. **Angular Mean**:\n\n        - The angular mean, with its corresponding p-value from the Rayleigh test.\n        - The confidence interval (CI) for the angular mean, if available.\n\n    5. **Angular Median**:\n\n        - The angular median, representing the central tendency.\n        - The confidence interval (CI) for the angular median, if applicable.\n\n    6. **Measures of Dispersion**:\n\n        - Angular deviation ($s$): A measure of spread in circular data.\n        - Circular standard deviation ($s_0$): An alternative dispersion measure.\n\n    7. **Measures of Concentration**:\n\n        - Resultant vector length ($r$): A measure of data concentration, ranging from 0 (uniform) to 1 (highly concentrated).\n        - Concentration parameter ($\\kappa$): Indicates sharpness or clustering of the data.\n\n    8. **Higher-Order Statistics**:\n\n        - Circular skewness: A measure of asymmetry.\n        - Circular kurtosis: A measure of peakedness or flatness relative to a uniform distribution.\n\n    9. **Significance Codes**:\n\n        - A guide to interpret the p-values of statistical tests.\n\n    10. **Methods**:\n\n        - The method used for calculating the angular median.\n        - The method used for estimating confidence intervals for the angular mean.\n    \"\"\"\n\n    return self.__repr__()\n</code></pre>"},{"location":"reference/base/#pycircstat2.base.Circular.plot","title":"<code>plot(ax=None, config=None)</code>","text":"<p>Visualize circular data.</p> <p>This method provides various visualization options for circular data, including scatter plots, density plots, and rose diagrams. It is a wrapper around the <code>circ_plot</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The matplotlib Axes object where the plot will be drawn. If None, a new Axes object is created. Default is None.</p> <code>None</code> <code>config</code> <p>Configuration dictionary that overrides defaults.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The matplotlib Axes object containing the plot.</p> Notes <ul> <li>This method supports both grouped and ungrouped data.</li> <li>Density estimation can be performed using either nonparametric methods or mixtures of von Mises distributions.</li> <li>The rose diagram represents grouped data as a histogram over angular bins.</li> <li>Confidence intervals for the mean and median are plotted as arcs on the circle.</li> </ul> <p>Examples:</p> <pre><code>from pycircstat2 import load_data, Circular\n\ndata = load_data(\"B3\", source=\"fisher\")[\"\u03b8\"].values\nc = Circular(data, unit=\"degree\")\nc.plot(config={\"scatter\": {\"color\" : \"blue\", \"size\": 15}})\n</code></pre> <p>See docstring of <code>circ_plot</code> for more examples and customization options.</p> Source code in <code>pycircstat2/base.py</code> <pre><code>def plot(self, ax=None, config=None):\n    \"\"\"\n    Visualize circular data.\n\n    This method provides various visualization options for circular data, including scatter\n    plots, density plots, and rose diagrams. It is a wrapper around the `circ_plot` function.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes._axes.Axes, optional\n        The matplotlib Axes object where the plot will be drawn. If None, a new Axes object\n        is created. Default is None.\n    config: dict, optional\n        Configuration dictionary that overrides defaults.\n\n    Returns\n    -------\n    ax : matplotlib.axes._axes.Axes\n        The matplotlib Axes object containing the plot.\n\n    Notes\n    -----\n    - This method supports both grouped and ungrouped data.\n    - Density estimation can be performed using either nonparametric methods or mixtures\n    of von Mises distributions.\n    - The rose diagram represents grouped data as a histogram over angular bins.\n    - Confidence intervals for the mean and median are plotted as arcs on the circle.\n\n    Examples\n    --------\n    ```\n    from pycircstat2 import load_data, Circular\n\n    data = load_data(\"B3\", source=\"fisher\")[\"\u03b8\"].values\n    c = Circular(data, unit=\"degree\")\n    c.plot(config={\"scatter\": {\"color\" : \"blue\", \"size\": 15}})\n    ```\n\n    See docstring of `circ_plot` for more examples and customization options.\n    \"\"\"\n    ax = circ_plot(self, ax=ax, config=config)\n</code></pre>"},{"location":"reference/clustering/","title":"Clustering","text":""},{"location":"reference/clustering/#pycircstat2.clustering.MovM","title":"<code>MovM</code>","text":"<p>Mixture of von Mises (MovM) Clustering.</p> <p>This class implements the Expectation-Maximization (EM) algorithm for clustering  circular data using a mixture of von Mises distributions. It is analogous to  Gaussian Mixture Models (GMM) but adapted for directional statistics.</p> <p>Parameters:</p> Name Type Description Default <code>burnin</code> <code>int</code> <p>Number of initial iterations before checking for convergence.</p> <code>30</code> <code>n_clusters</code> <code>int</code> <p>The number of von Mises distributions (clusters) to fit.</p> <code>5</code> <code>n_iters</code> <code>int</code> <p>Maximum number of iterations for the EM algorithm.</p> <code>100</code> <code>full_cycle</code> <code>int</code> <p>Used for converting degree-based data into radians.</p> <code>360</code> <code>unit</code> <code>(degree, radian)</code> <p>Specifies whether input data is in degrees or radians.</p> <code>\"degree\"</code> <code>random_seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>2046</code> <code>threshold</code> <code>float</code> <p>Convergence threshold based on the negative log-likelihood difference.</p> <code>1e-16</code> <p>Attributes:</p> Name Type Description <code>converged</code> <code>bool</code> <p>Whether the algorithm has converged.</p> <code>nLL</code> <code>ndarray</code> <p>Array of negative log-likelihood values over iterations.</p> <code>m</code> <code>ndarray</code> <p>Cluster means (circular means).</p> <code>r</code> <code>ndarray</code> <p>Cluster mean resultant vectors.</p> <code>p</code> <code>ndarray</code> <p>Cluster probabilities.</p> <code>kappa</code> <code>ndarray</code> <p>Concentration parameters for each von Mises component.</p> <code>gamma</code> <code>ndarray</code> <p>Responsibility matrix (posterior probabilities of clusters for each data point).</p> <code>labels</code> <code>ndarray</code> <p>The most probable cluster assignment for each data point.</p> <p>Examples:</p> <pre><code>import numpy as np\nfrom pycircstat2.clustering import MovM\nnp.random.seed(42)\nx1 = np.random.vonmises(mu=0, kappa=5, size=100)\nx2 = np.random.vonmises(mu=np.pi, kappa=10, size=100)\nx = np.concatenate([x1, x2])\nnp.random.shuffle(x)\nmovm = MovM(n_clusters=2, n_iters=200, unit=\"radian\", random_seed=42)\nmovm.fit(x, verbose=False)\n</code></pre> Source code in <code>pycircstat2/clustering.py</code> <pre><code>class MovM:\n    \"\"\"\n    Mixture of von Mises (MovM) Clustering.\n\n    This class implements the Expectation-Maximization (EM) algorithm for clustering \n    circular data using a mixture of von Mises distributions. It is analogous to \n    Gaussian Mixture Models (GMM) but adapted for directional statistics.\n\n    Parameters\n    ----------\n    burnin : int, default=30\n        Number of initial iterations before checking for convergence.\n    n_clusters : int, default=5\n        The number of von Mises distributions (clusters) to fit.\n    n_iters : int, default=100\n        Maximum number of iterations for the EM algorithm.\n    full_cycle : int, default=360\n        Used for converting degree-based data into radians.\n    unit : {\"degree\", \"radian\"}, default=\"degree\"\n        Specifies whether input data is in degrees or radians.\n    random_seed : int, default=2046\n        Random seed for reproducibility.\n    threshold : float, default=1e-16\n        Convergence threshold based on the negative log-likelihood difference.\n\n    Attributes\n    ----------\n    converged : bool\n        Whether the algorithm has converged.\n    nLL : np.ndarray\n        Array of negative log-likelihood values over iterations.\n    m : np.ndarray\n        Cluster means (circular means).\n    r : np.ndarray\n        Cluster mean resultant vectors.\n    p : np.ndarray\n        Cluster probabilities.\n    kappa : np.ndarray\n        Concentration parameters for each von Mises component.\n    gamma : np.ndarray\n        Responsibility matrix (posterior probabilities of clusters for each data point).\n    labels : np.ndarray\n        The most probable cluster assignment for each data point.\n\n    Examples\n    --------\n        import numpy as np\n        from pycircstat2.clustering import MovM\n        np.random.seed(42)\n        x1 = np.random.vonmises(mu=0, kappa=5, size=100)\n        x2 = np.random.vonmises(mu=np.pi, kappa=10, size=100)\n        x = np.concatenate([x1, x2])\n        np.random.shuffle(x)\n        movm = MovM(n_clusters=2, n_iters=200, unit=\"radian\", random_seed=42)\n        movm.fit(x, verbose=False)\n    \"\"\"\n\n    def __init__(\n        self,\n        burnin: int = 30,\n        n_clusters: int = 5,\n        n_iters: int = 100,\n        full_cycle: Union[int, float] = 360,\n        unit: str = \"degree\",\n        random_seed: int = 2046,\n        threshold: float = 1e-16,\n    ):\n        self.burnin = (\n            burnin  # wait untill burinin step of iterations for convergence\n        )\n        self.threshold = threshold  # convergence threshold\n        self.n_clusters = n_clusters  # number of clusters to estimate\n        self.n_iters = n_iters  # maximum number of iterations for EM\n        self.full_cycle = full_cycle  # for data conversion\n        self.unit = unit  # for data conversion\n        self.random_seed = random_seed\n        self.converged = False  # place holder\n\n        self.m_ = None  # cluster means\n        self.r_ = None  # cluster mean resultant vectors\n        self.p_ = None  # cluster probabilities\n        self.kappa_ = None  # cluster kappas\n        self.gamma_ = None  # update gamma one last time\n        self.labels_ = None # final cluster assignments\n\n    def _initialize(\n        self,\n        x: np.ndarray,\n        n_clusters_init: int,\n    ) -&gt; tuple:\n        \"\"\"\n        Initializes cluster parameters before running the EM algorithm.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            Input circular data in radians.\n        n_clusters_init : int\n            Number of initial clusters.\n\n        Returns\n        -------\n        tuple\n            - m (np.ndarray): Initial cluster means.\n            - kappa (np.ndarray): Initial concentration parameters.\n            - p (np.ndarray): Initial cluster probabilities.\n        \"\"\"\n        # number of samples\n        n = len(x)  \n\n        # initial cluster probability\n        p = np.ones(n_clusters_init) / n_clusters_init \n\n        # initial labels\n        z = np.random.choice(np.arange(n_clusters_init), size=n) \n\n        # initial means and resultant vector lengths\n        m, r = map(\n            np.array,\n            zip(*[circ_mean_and_r(x[z == i]) for i in range(n_clusters_init)]),\n        )  \n\n        # initial kappa (without correction by hard-coding a larger enough n)\n        kappa = np.array([circ_kappa(r=r[i]) for i in range(n_clusters_init)])  \n\n        return m, kappa, p\n\n    def fit(self, X: np.ndarray, verbose: Union[bool, int] = 0):\n        \"\"\"\n        Fits the mixture of von Mises model to the given data using the EM algorithm.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Input data points in degrees or radians.\n        verbose : bool or int, default=0\n            If True, prints progress every iteration. If an integer, prints every `verbose` iterations.\n\n        Updates\n        -------\n        - self.m : Fitted cluster means.\n        - self.kappa : Fitted concentration parameters.\n        - self.p : Fitted cluster probabilities.\n        - self.labels : Final cluster assignments.\n        \"\"\"\n        # seed\n        np.random.seed(self.random_seed)\n\n        # meta\n        self.data = X\n        self.alpha = alpha = (\n            X if self.unit == \"radian\" else data2rad(X, self.full_cycle)\n        )\n        self.n = n = len(X)\n\n        # init\n        m, kappa, p = self._initialize(alpha, self.n_clusters)\n\n        # EM\n        if verbose:\n            print(\"Iter\".ljust(10) + \"nLL\")\n        self.nLL = np.ones(self.n_iters) * np.nan\n        for i in range(self.n_iters):\n            # E step\n            gamma = self.compute_gamma(alpha=self.alpha, p=p, m=m, kappa=kappa)\n            gamma_normed = gamma / np.sum(gamma, axis=0)\n\n            # M step\n            p = (\n                np.sum(gamma_normed, axis=1)\n                / np.sum(gamma_normed, axis=1).sum()\n            )\n\n            m, r = map(\n                np.array,\n                zip(\n                    *[\n                        circ_mean_and_r(alpha=alpha, w=gamma_normed[i])\n                        for i in range(self.n_clusters)\n                    ]\n                ),\n            )\n            kappa = np.array(\n                [circ_kappa(r=r[i]) for i in range(self.n_clusters)]\n            )\n\n            nLL = self.compute_nLL(gamma)\n            self.nLL[i] = nLL\n\n            if verbose:\n                if i % int(verbose) == 0:\n                    print(f\"{i}\".ljust(10) + f\"{nLL:.03f}\")\n\n            if (\n                i &gt; self.burnin\n                and np.abs(self.nLL[i] - self.nLL[i - 1]) &lt; self.threshold\n            ):\n                self.nLL = self.nLL[~np.isnan(self.nLL)]\n                self.converged = True\n                self.converged_iters = len(self.nLL)\n\n                if verbose:\n                    print(f\"Converged at iter {i}. Final nLL = {nLL:.3f}\\n\")\n                break\n        else:\n            if verbose:\n                print(\n                    f\"Reached max iter {self.n_iters}. Final nLL = {nLL:.3f}\\n\"\n                )\n\n        # save results\n        self.m_ = m  # cluster means\n        self.r_ = r  # cluster mean resultant vectors\n        self.p_ = p  # cluster probabilities\n        self.kappa_ = kappa  # cluster kappas\n        self.gamma_ = self.compute_gamma(\n            alpha=self.alpha, p=p, m=m, kappa=kappa\n        )  # update gamma one last time\n        self.labels_ = self.gamma_.argmax(axis=0)\n\n    def compute_gamma(\n        self,\n        alpha: np.ndarray,\n        p: np.ndarray,\n        m: np.ndarray,\n        kappa: np.ndarray,\n    )-&gt; np.ndarray:\n        \"\"\"\n        Computes posterior probabilities (responsibilities) for each cluster.\n\n        Returns\n        -------\n        np.ndarray\n            Cluster assignment probabilities for each data point.\n        \"\"\"\n        gamma = np.vstack(\n            [\n                p[i] * vonmises.pdf(alpha, kappa=kappa[i], mu=m[i])\n                for i in range(self.n_clusters)\n            ]\n        )\n        return gamma\n\n    def compute_nLL(self, gamma: np.ndarray)-&gt; float:\n        \"\"\"\n        Computes the negative log-likelihood.\n\n        Parameters\n        ----------\n        gamma : np.ndarray\n            The responsibility matrix (posterior probabilities of clusters for each data point).\n\n        Returns\n        -------\n        float\n            The negative log-likelihood value.\n        \"\"\"\n        nLL = -np.sum(np.log(np.sum(gamma, axis=0) + 1e-16))\n        return nLL\n\n    def compute_BIC(self)-&gt; float:\n        \"\"\"\n        Computes the Bayesian Information Criterion (BIC) for model selection.\n\n        Returns\n        -------\n        float\n            The computed BIC value.\n        \"\"\"\n        nLL = self.compute_nLL(self.gamma_)\n        nparams = self.n_clusters * 3 - 1  # n_means + n_kappas + (n_ps - 1)\n        bic = 2 * nLL + np.log(self.n) * nparams\n\n        return bic\n\n    def predict_density(\n        self,\n        x: Optional[np.ndarray] = None,\n        unit: Union[str, None] = None,\n        full_cycle: Union[float, int, None] = None,\n    )-&gt; np.ndarray:\n        \"\"\"\n        Predicts density estimates for given points.\n\n        Parameters\n        ----------\n        x : np.ndarray, optional\n            Points at which to estimate the density.\n        unit : {\"degree\", \"radian\"}, optional\n            Specifies whether input data is in degrees or radians.\n        full_cycle : int, optional\n            Number of intervals for data conversion.\n\n        Returns\n        -------\n        np.ndarray\n            Estimated density at the provided points.\n        \"\"\"\n        unit = self.unit if unit is None else unit\n        full_cycle = self.full_cycle if full_cycle is None else full_cycle\n\n        if x is None:\n            x = np.linspace(0, 2 * np.pi, 100)\n\n        alpha = x if unit == \"radian\" else data2rad(x, full_cycle)\n\n        d = [\n            self.p_[i] * vonmises.pdf(alpha, kappa=self.kappa_[i], mu=self.m_[i])\n            for i in range(self.n_clusters)\n        ]\n        return np.sum(d, axis=0)\n\n    def predict(self, x: np.ndarray)-&gt; np.ndarray:\n        \"\"\"\n        Predicts cluster assignments for new data.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            New data points in degrees or radians.\n\n        Returns\n        -------\n        np.ndarray\n            Predicted cluster labels.\n        \"\"\"\n        alpha = x if self.unit == \"radian\" else data2rad(x, self.full_cycle)\n\n        gamma = self.compute_gamma(\n            alpha=alpha, p=self.p_, m=self.m_, kappa=self.kappa_\n        )\n\n        return gamma.argmax(axis=0)\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.fit","title":"<code>fit(X, verbose=0)</code>","text":"<p>Fits the mixture of von Mises model to the given data using the EM algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input data points in degrees or radians.</p> required <code>verbose</code> <code>bool or int</code> <p>If True, prints progress every iteration. If an integer, prints every <code>verbose</code> iterations.</p> <code>0</code> Updates <ul> <li>self.m : Fitted cluster means.</li> <li>self.kappa : Fitted concentration parameters.</li> <li>self.p : Fitted cluster probabilities.</li> <li>self.labels : Final cluster assignments.</li> </ul> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def fit(self, X: np.ndarray, verbose: Union[bool, int] = 0):\n    \"\"\"\n    Fits the mixture of von Mises model to the given data using the EM algorithm.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        Input data points in degrees or radians.\n    verbose : bool or int, default=0\n        If True, prints progress every iteration. If an integer, prints every `verbose` iterations.\n\n    Updates\n    -------\n    - self.m : Fitted cluster means.\n    - self.kappa : Fitted concentration parameters.\n    - self.p : Fitted cluster probabilities.\n    - self.labels : Final cluster assignments.\n    \"\"\"\n    # seed\n    np.random.seed(self.random_seed)\n\n    # meta\n    self.data = X\n    self.alpha = alpha = (\n        X if self.unit == \"radian\" else data2rad(X, self.full_cycle)\n    )\n    self.n = n = len(X)\n\n    # init\n    m, kappa, p = self._initialize(alpha, self.n_clusters)\n\n    # EM\n    if verbose:\n        print(\"Iter\".ljust(10) + \"nLL\")\n    self.nLL = np.ones(self.n_iters) * np.nan\n    for i in range(self.n_iters):\n        # E step\n        gamma = self.compute_gamma(alpha=self.alpha, p=p, m=m, kappa=kappa)\n        gamma_normed = gamma / np.sum(gamma, axis=0)\n\n        # M step\n        p = (\n            np.sum(gamma_normed, axis=1)\n            / np.sum(gamma_normed, axis=1).sum()\n        )\n\n        m, r = map(\n            np.array,\n            zip(\n                *[\n                    circ_mean_and_r(alpha=alpha, w=gamma_normed[i])\n                    for i in range(self.n_clusters)\n                ]\n            ),\n        )\n        kappa = np.array(\n            [circ_kappa(r=r[i]) for i in range(self.n_clusters)]\n        )\n\n        nLL = self.compute_nLL(gamma)\n        self.nLL[i] = nLL\n\n        if verbose:\n            if i % int(verbose) == 0:\n                print(f\"{i}\".ljust(10) + f\"{nLL:.03f}\")\n\n        if (\n            i &gt; self.burnin\n            and np.abs(self.nLL[i] - self.nLL[i - 1]) &lt; self.threshold\n        ):\n            self.nLL = self.nLL[~np.isnan(self.nLL)]\n            self.converged = True\n            self.converged_iters = len(self.nLL)\n\n            if verbose:\n                print(f\"Converged at iter {i}. Final nLL = {nLL:.3f}\\n\")\n            break\n    else:\n        if verbose:\n            print(\n                f\"Reached max iter {self.n_iters}. Final nLL = {nLL:.3f}\\n\"\n            )\n\n    # save results\n    self.m_ = m  # cluster means\n    self.r_ = r  # cluster mean resultant vectors\n    self.p_ = p  # cluster probabilities\n    self.kappa_ = kappa  # cluster kappas\n    self.gamma_ = self.compute_gamma(\n        alpha=self.alpha, p=p, m=m, kappa=kappa\n    )  # update gamma one last time\n    self.labels_ = self.gamma_.argmax(axis=0)\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.compute_gamma","title":"<code>compute_gamma(alpha, p, m, kappa)</code>","text":"<p>Computes posterior probabilities (responsibilities) for each cluster.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Cluster assignment probabilities for each data point.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def compute_gamma(\n    self,\n    alpha: np.ndarray,\n    p: np.ndarray,\n    m: np.ndarray,\n    kappa: np.ndarray,\n)-&gt; np.ndarray:\n    \"\"\"\n    Computes posterior probabilities (responsibilities) for each cluster.\n\n    Returns\n    -------\n    np.ndarray\n        Cluster assignment probabilities for each data point.\n    \"\"\"\n    gamma = np.vstack(\n        [\n            p[i] * vonmises.pdf(alpha, kappa=kappa[i], mu=m[i])\n            for i in range(self.n_clusters)\n        ]\n    )\n    return gamma\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.compute_nLL","title":"<code>compute_nLL(gamma)</code>","text":"<p>Computes the negative log-likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>ndarray</code> <p>The responsibility matrix (posterior probabilities of clusters for each data point).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The negative log-likelihood value.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def compute_nLL(self, gamma: np.ndarray)-&gt; float:\n    \"\"\"\n    Computes the negative log-likelihood.\n\n    Parameters\n    ----------\n    gamma : np.ndarray\n        The responsibility matrix (posterior probabilities of clusters for each data point).\n\n    Returns\n    -------\n    float\n        The negative log-likelihood value.\n    \"\"\"\n    nLL = -np.sum(np.log(np.sum(gamma, axis=0) + 1e-16))\n    return nLL\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.compute_BIC","title":"<code>compute_BIC()</code>","text":"<p>Computes the Bayesian Information Criterion (BIC) for model selection.</p> <p>Returns:</p> Type Description <code>float</code> <p>The computed BIC value.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def compute_BIC(self)-&gt; float:\n    \"\"\"\n    Computes the Bayesian Information Criterion (BIC) for model selection.\n\n    Returns\n    -------\n    float\n        The computed BIC value.\n    \"\"\"\n    nLL = self.compute_nLL(self.gamma_)\n    nparams = self.n_clusters * 3 - 1  # n_means + n_kappas + (n_ps - 1)\n    bic = 2 * nLL + np.log(self.n) * nparams\n\n    return bic\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.predict_density","title":"<code>predict_density(x=None, unit=None, full_cycle=None)</code>","text":"<p>Predicts density estimates for given points.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to estimate the density.</p> <code>None</code> <code>unit</code> <code>(degree, radian)</code> <p>Specifies whether input data is in degrees or radians.</p> <code>\"degree\"</code> <code>full_cycle</code> <code>int</code> <p>Number of intervals for data conversion.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Estimated density at the provided points.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def predict_density(\n    self,\n    x: Optional[np.ndarray] = None,\n    unit: Union[str, None] = None,\n    full_cycle: Union[float, int, None] = None,\n)-&gt; np.ndarray:\n    \"\"\"\n    Predicts density estimates for given points.\n\n    Parameters\n    ----------\n    x : np.ndarray, optional\n        Points at which to estimate the density.\n    unit : {\"degree\", \"radian\"}, optional\n        Specifies whether input data is in degrees or radians.\n    full_cycle : int, optional\n        Number of intervals for data conversion.\n\n    Returns\n    -------\n    np.ndarray\n        Estimated density at the provided points.\n    \"\"\"\n    unit = self.unit if unit is None else unit\n    full_cycle = self.full_cycle if full_cycle is None else full_cycle\n\n    if x is None:\n        x = np.linspace(0, 2 * np.pi, 100)\n\n    alpha = x if unit == \"radian\" else data2rad(x, full_cycle)\n\n    d = [\n        self.p_[i] * vonmises.pdf(alpha, kappa=self.kappa_[i], mu=self.m_[i])\n        for i in range(self.n_clusters)\n    ]\n    return np.sum(d, axis=0)\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.MovM.predict","title":"<code>predict(x)</code>","text":"<p>Predicts cluster assignments for new data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>New data points in degrees or radians.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted cluster labels.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def predict(self, x: np.ndarray)-&gt; np.ndarray:\n    \"\"\"\n    Predicts cluster assignments for new data.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        New data points in degrees or radians.\n\n    Returns\n    -------\n    np.ndarray\n        Predicted cluster labels.\n    \"\"\"\n    alpha = x if self.unit == \"radian\" else data2rad(x, self.full_cycle)\n\n    gamma = self.compute_gamma(\n        alpha=alpha, p=self.p_, m=self.m_, kappa=self.kappa_\n    )\n\n    return gamma.argmax(axis=0)\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircHAC","title":"<code>CircHAC</code>","text":"<p>Hierarchical agglomerative clustering for circular (1D) data, with optional dendrogram tracking.</p> <p>Each merge is recorded: (clusterA, clusterB, distance, new_cluster_size).</p> <p>This is a \"center-merge\" approach: each cluster is represented by its circular mean, and we merge the two clusters with the smallest absolute circular difference in means (using circ_dist). The merges form a dendrogram we can plot or output.</p> <p>Parameters:</p> Name Type Description Default <code>n_clusters</code> <code>int</code> <p>Number of clusters desired.</p> <code>2</code> <code>n_init_clusters</code> <code>int or None</code> <p>If None, every point starts as its own cluster (default HAC). If a number, <code>CircKMeans</code> is used to pre-cluster data before HAC.</p> <code>None</code> <code>unit</code> <code>(radian, degree)</code> <p>If \"degree\", data is converted to radians internally.</p> <code>\"radian\"</code> <code>full_cycle</code> <code>int</code> <p>For data conversion if unit=\"degree\".</p> <code>360</code> <code>metric</code> <code>(center, geodesic, angularseparation, chord)</code> <p>The distance metric used to measure the difference between cluster centers. We'll take its absolute value so that it's a nonnegative distance.</p> <code>\"center\"</code> <code>random_seed</code> <code>int</code> <p>Not used by default, but if you add any random steps, you may set it here.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>centers_</code> <code>(ndarray, shape(k))</code> <p>Final cluster center angles (in radians).</p> <code>r_</code> <code>(ndarray, shape(k))</code> <p>Resultant vector length for each cluster.</p> <code>labels_</code> <code>(ndarray, shape(n_samples))</code> <p>Cluster assignment for each data point, in {0, ..., k-1}.</p> <code>merges_</code> <code>(ndarray, shape(m, 4))</code> <p>Dendrogram merge history: - merges_[step, 0] = ID of cluster A - merges_[step, 1] = ID of cluster B - merges_[step, 2] = distance used to merge - merges_[step, 3] = new cluster size after merge Note: these cluster IDs are the \"old\" ones, not necessarily 0..(k-1) at each step.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>class CircHAC:\n    \"\"\"\n    Hierarchical agglomerative clustering for circular (1D) data,\n    with optional dendrogram tracking.\n\n    Each merge is recorded: (clusterA, clusterB, distance, new_cluster_size).\n\n    This is a \"center-merge\" approach: each cluster is represented by its\n    circular mean, and we merge the two clusters with the smallest\n    *absolute* circular difference in means (using circ_dist).\n    The merges form a dendrogram we can plot or output.\n\n    Parameters\n    ----------\n    n_clusters : int, default=2\n        Number of clusters desired.\n    n_init_clusters : int or None, default=None\n        If None, every point starts as its own cluster (default HAC).\n        If a number, `CircKMeans` is used to pre-cluster data before HAC.\n    unit : {\"radian\", \"degree\"}, default=\"degree\"\n        If \"degree\", data is converted to radians internally.\n    full_cycle : int, default=360\n        For data conversion if unit=\"degree\".\n    metric : {\"center\", \"geodesic\", \"angularseparation\", \"chord\"}, default=\"center\"\n        The distance metric used to measure the difference between cluster centers.\n        We'll take its absolute value so that it's a nonnegative distance.\n    random_seed : int, optional\n        Not used by default, but if you add any random steps, you may set it here.\n\n    Attributes\n    ----------\n    centers_ : np.ndarray, shape (k,)\n        Final cluster center angles (in radians).\n    r_ : np.ndarray, shape (k,)\n        Resultant vector length for each cluster.\n    labels_ : np.ndarray, shape (n_samples,)\n        Cluster assignment for each data point, in {0, ..., k-1}.\n    merges_ : np.ndarray, shape (m, 4)\n        Dendrogram merge history:\n        - merges_[step, 0] = ID of cluster A\n        - merges_[step, 1] = ID of cluster B\n        - merges_[step, 2] = distance used to merge\n        - merges_[step, 3] = new cluster size after merge\n        Note: these cluster IDs are the \"old\" ones, not necessarily 0..(k-1) at each step.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters=2,\n        n_init_clusters=None, \n        unit=\"degree\",\n        full_cycle=360,\n        metric=\"center\",\n        random_seed=None\n    ):\n        self.n_clusters = n_clusters\n        self.n_init_clusters = n_init_clusters\n        self.unit = unit\n        self.full_cycle = full_cycle\n        self.metric = metric\n        self.random_seed = random_seed\n\n        self.centers_ = None\n        self.r_ = None\n        self.labels_ = None\n        self.merges_ = None\n\n    def _initialize_clusters(self, X):\n        \"\"\"Initializes clusters using CircKMeans or default HAC.\"\"\"\n        n_samples = len(X)\n\n        # Default HAC: every point is its own cluster\n        if self.n_init_clusters is None or self.n_init_clusters &gt;= n_samples:\n            return np.arange(n_samples), X  # Standard HAC\n\n        # Use CircKMeans for pre-clustering\n        kmeans = CircKMeans(n_clusters=self.n_init_clusters, unit=\"radian\", metric=self.metric, random_seed=self.random_seed)\n        kmeans.fit(X)\n\n        init_labels = kmeans.labels_\n        init_centers = kmeans.centers_\n\n        return init_labels, init_centers\n\n    def fit(self, X):\n        \"\"\"\n        Perform agglomerative clustering on `X`.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Input angles in degrees or radians.\n\n        Returns\n        -------\n        self : CircHAC\n        \"\"\"\n        self.data = X = np.asarray(X)\n        if self.unit == \"degree\":\n            self.alpha = alpha = data2rad(X, k=self.full_cycle)\n        else:\n            self.alpha = alpha = X\n\n        n = len(alpha)\n        if n &lt;= self.n_clusters:\n            self.labels_ = np.arange(n)\n            self.centers_ = alpha.copy()\n            self.r_ = np.ones(n)\n            self.merges_ = np.empty((0, 4))\n            return self\n\n        # Step 1: Initialize with pre-clustering or start from scratch\n        cluster_ids, cluster_means = self._initialize_clusters(alpha)\n        cluster_sizes = np.ones(len(cluster_means), dtype=int)\n\n        merges = []  # Track merge history\n\n        while len(np.unique(cluster_ids)) &gt; self.n_clusters:\n            # Compute cluster means\n            unique_clusters = np.unique(cluster_ids)\n            cluster_means_dict = {c: cluster_means[c] for c in unique_clusters}\n\n            # Find best pair to merge\n            best_dist = np.inf\n            best_i, best_j = None, None\n            for i in unique_clusters:\n                for j in unique_clusters:\n                    if j &lt;= i:\n                        continue\n                    dist_ij = circ_dist(cluster_means_dict[i], cluster_means_dict[j], metric=self.metric)\n                    if dist_ij &lt; best_dist:\n                        best_dist = dist_ij\n                        best_i, best_j = i, j\n\n            if best_i is None or best_j is None:\n                break  # No valid merge found\n\n            # Record merge\n            new_size = cluster_sizes[best_i] + cluster_sizes[best_j]\n            merges.append([best_i, best_j, best_dist, new_size])\n\n            # Merge clusters\n            cluster_ids[cluster_ids == best_j] = best_i\n            cluster_sizes[best_i] = new_size\n            cluster_means[best_i] = circ_mean_and_r(alpha[cluster_ids == best_i])[0]\n\n        # Assign final cluster labels\n        unique_ids = np.unique(cluster_ids)\n        label_map = {old_id: new_id for new_id, old_id in enumerate(unique_ids)}\n        self.labels_ = np.array([label_map[c] for c in cluster_ids], dtype=int)\n\n        # Compute final cluster centers and resultant lengths\n        k = len(unique_ids)\n        self.centers_ = np.zeros(k, dtype=float)\n        self.r_ = np.zeros(k, dtype=float)\n        for i in range(k):\n            subset = alpha[self.labels_ == i]\n            mean_i, r_i = circ_mean_and_r(subset)\n            self.centers_[i] = mean_i\n            self.r_[i] = r_i\n\n        # Store merges\n        self.merges_ = np.array(merges, dtype=object)\n\n    def predict(self, alpha):\n        \"\"\"\n        Assign new angles to the closest cluster center.\n\n        Parameters\n        ----------\n        alpha : array-like of shape (n_samples,)\n\n        Returns\n        -------\n        labels : np.ndarray of shape (n_samples,)\n        \"\"\"\n        alpha = np.asarray(alpha)\n        if self.unit == \"degree\":\n            alpha = data2rad(alpha, k=self.full_cycle)\n        else:\n            alpha = alpha\n\n        n_samples = len(alpha)\n        k = len(self.centers_)\n        labels = np.zeros(n_samples, dtype=int)\n        for i in range(n_samples):\n            a_i = alpha[i]\n            # measure distance to each center\n            best_c, best_d = None, np.inf\n            for c in range(k):\n                dist_ic = circ_dist(a_i, self.centers_[c], metric=self.metric)\n                dval = float(abs(dist_ic))\n                if dval &lt; best_d:\n                    best_d = dval\n                    best_c = c\n            labels[i] = best_c\n        return labels\n\n    def plot_dendrogram(self, ax=None, **kwargs):\n        \"\"\"\n        Plot a rudimentary dendrogram from merges_.\n\n        This is a basic approach that uses cluster IDs directly as \"labels\"\n        on the x-axis. Because cluster IDs might not be contiguous or in ascending\n        order, the result can look jumbled. A more sophisticated approach\n        would re-compute a consistent labeling for each step.\n\n        Parameters\n        ----------\n        ax : matplotlib Axes, optional\n            If None, create a new figure/axes.\n        **kwargs : dict\n            Passed along to ax.plot(), e.g. color, linewidth, etc.\n\n        Returns\n        -------\n        ax : matplotlib Axes\n        \"\"\"\n        import matplotlib.pyplot as plt\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(6, 4))\n        merges = self.merges_\n        if merges.size == 0:\n            ax.set_title(\"No merges recorded (maybe n &lt;= n_clusters?).\")\n            return ax\n\n        # merges_ is (step, 4): [clusterA, clusterB, dist, new_size]\n        # We want to plot something like a dendrogram:\n        #  - each row is a merge event\n        #  - x-axis might show cluster A and cluster B, y the 'distance'\n        # But cluster IDs might keep re-labelling, so a quick hack is we show them as is.\n\n        for step, (ca, cb, distval, new_size) in enumerate(merges):\n            # We'll draw a \"u\" connecting ca and cb at height distval\n            # Then the newly formed cluster could get ID=cb or something\n            # This is a naive approach that won't produce a fancy SciPy-like dendrogram\n            # but enough to illustrate what's happening.\n\n            x1, x2 = ca, cb\n            y = distval\n            # a line from (x1, 0) to (x1, y), from (x2, 0) to (x2, y),\n            # then a horizontal line across at y\n            # we can color them or style them with kwargs\n\n            ax.plot([x1, x1], [0, y], **kwargs)\n            ax.plot([x2, x2], [0, y], **kwargs)\n            ax.plot([x1, x2], [y, y], **kwargs)\n\n        ax.set_title(\"Rudimentary Dendrogram\")\n        ax.set_xlabel(\"Cluster ID (raw internal IDs)\")\n        ax.set_ylabel(\"Distance\")\n        return ax\n\n\n    def silhouette_score(self):\n        \"\"\"\n        Compute the average silhouette for a cluster assignment on circular data.\n\n        angles: np.ndarray shape (n,) in radians\n        labels: np.ndarray shape (n,) in {0,1,...,K-1}\n        metric: \"chord\", \"geodesic\", \"center\", etc.\n\n        Returns\n        -------\n        float\n            The mean silhouette over all points.\n        \"\"\"\n        angles = self.alpha\n        labels = self.labels_\n        metric = self.metric\n        n = len(angles)\n        if n &lt; 2:\n            return 0.0\n\n        silhouette_values = np.zeros(n, dtype=float)\n\n        # Precompute all pairwise distances\n        # shape =&gt; (n,n)\n        pairwise = circ_dist(angles[:,None], angles[None,:], metric=metric)\n        pairwise = np.abs(pairwise)  # ensure nonnegative\n\n        for i in range(n):\n            c_i = labels[i]\n            # points in cluster c_i\n            in_cluster_i = (labels == c_i)\n            # average distance to own cluster\n            # excluding the point itself\n            a_i = pairwise[i, in_cluster_i].mean() if in_cluster_i.sum() &gt; 1 else 0.0\n\n            # find min average distance to another cluster\n            b_i = np.inf\n            for c_other in np.unique(labels):\n                if c_other == c_i:\n                    continue\n                in_other = (labels == c_other)\n                dist_i_other = pairwise[i, in_other].mean()\n                if dist_i_other &lt; b_i:\n                    b_i = dist_i_other\n\n            silhouette_values[i] = (b_i - a_i) / max(a_i, b_i) if max(a_i, b_i) &gt; 0 else 0.0\n\n        return silhouette_values.mean()\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircHAC.fit","title":"<code>fit(X)</code>","text":"<p>Perform agglomerative clustering on <code>X</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input angles in degrees or radians.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>CircHAC</code> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def fit(self, X):\n    \"\"\"\n    Perform agglomerative clustering on `X`.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        Input angles in degrees or radians.\n\n    Returns\n    -------\n    self : CircHAC\n    \"\"\"\n    self.data = X = np.asarray(X)\n    if self.unit == \"degree\":\n        self.alpha = alpha = data2rad(X, k=self.full_cycle)\n    else:\n        self.alpha = alpha = X\n\n    n = len(alpha)\n    if n &lt;= self.n_clusters:\n        self.labels_ = np.arange(n)\n        self.centers_ = alpha.copy()\n        self.r_ = np.ones(n)\n        self.merges_ = np.empty((0, 4))\n        return self\n\n    # Step 1: Initialize with pre-clustering or start from scratch\n    cluster_ids, cluster_means = self._initialize_clusters(alpha)\n    cluster_sizes = np.ones(len(cluster_means), dtype=int)\n\n    merges = []  # Track merge history\n\n    while len(np.unique(cluster_ids)) &gt; self.n_clusters:\n        # Compute cluster means\n        unique_clusters = np.unique(cluster_ids)\n        cluster_means_dict = {c: cluster_means[c] for c in unique_clusters}\n\n        # Find best pair to merge\n        best_dist = np.inf\n        best_i, best_j = None, None\n        for i in unique_clusters:\n            for j in unique_clusters:\n                if j &lt;= i:\n                    continue\n                dist_ij = circ_dist(cluster_means_dict[i], cluster_means_dict[j], metric=self.metric)\n                if dist_ij &lt; best_dist:\n                    best_dist = dist_ij\n                    best_i, best_j = i, j\n\n        if best_i is None or best_j is None:\n            break  # No valid merge found\n\n        # Record merge\n        new_size = cluster_sizes[best_i] + cluster_sizes[best_j]\n        merges.append([best_i, best_j, best_dist, new_size])\n\n        # Merge clusters\n        cluster_ids[cluster_ids == best_j] = best_i\n        cluster_sizes[best_i] = new_size\n        cluster_means[best_i] = circ_mean_and_r(alpha[cluster_ids == best_i])[0]\n\n    # Assign final cluster labels\n    unique_ids = np.unique(cluster_ids)\n    label_map = {old_id: new_id for new_id, old_id in enumerate(unique_ids)}\n    self.labels_ = np.array([label_map[c] for c in cluster_ids], dtype=int)\n\n    # Compute final cluster centers and resultant lengths\n    k = len(unique_ids)\n    self.centers_ = np.zeros(k, dtype=float)\n    self.r_ = np.zeros(k, dtype=float)\n    for i in range(k):\n        subset = alpha[self.labels_ == i]\n        mean_i, r_i = circ_mean_and_r(subset)\n        self.centers_[i] = mean_i\n        self.r_[i] = r_i\n\n    # Store merges\n    self.merges_ = np.array(merges, dtype=object)\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircHAC.predict","title":"<code>predict(alpha)</code>","text":"<p>Assign new angles to the closest cluster center.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>array-like of shape (n_samples,)</code> required <p>Returns:</p> Name Type Description <code>labels</code> <code>np.ndarray of shape (n_samples,)</code> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def predict(self, alpha):\n    \"\"\"\n    Assign new angles to the closest cluster center.\n\n    Parameters\n    ----------\n    alpha : array-like of shape (n_samples,)\n\n    Returns\n    -------\n    labels : np.ndarray of shape (n_samples,)\n    \"\"\"\n    alpha = np.asarray(alpha)\n    if self.unit == \"degree\":\n        alpha = data2rad(alpha, k=self.full_cycle)\n    else:\n        alpha = alpha\n\n    n_samples = len(alpha)\n    k = len(self.centers_)\n    labels = np.zeros(n_samples, dtype=int)\n    for i in range(n_samples):\n        a_i = alpha[i]\n        # measure distance to each center\n        best_c, best_d = None, np.inf\n        for c in range(k):\n            dist_ic = circ_dist(a_i, self.centers_[c], metric=self.metric)\n            dval = float(abs(dist_ic))\n            if dval &lt; best_d:\n                best_d = dval\n                best_c = c\n        labels[i] = best_c\n    return labels\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircHAC.plot_dendrogram","title":"<code>plot_dendrogram(ax=None, **kwargs)</code>","text":"<p>Plot a rudimentary dendrogram from merges_.</p> <p>This is a basic approach that uses cluster IDs directly as \"labels\" on the x-axis. Because cluster IDs might not be contiguous or in ascending order, the result can look jumbled. A more sophisticated approach would re-compute a consistent labeling for each step.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>matplotlib Axes</code> <p>If None, create a new figure/axes.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Passed along to ax.plot(), e.g. color, linewidth, etc.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>matplotlib Axes</code> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def plot_dendrogram(self, ax=None, **kwargs):\n    \"\"\"\n    Plot a rudimentary dendrogram from merges_.\n\n    This is a basic approach that uses cluster IDs directly as \"labels\"\n    on the x-axis. Because cluster IDs might not be contiguous or in ascending\n    order, the result can look jumbled. A more sophisticated approach\n    would re-compute a consistent labeling for each step.\n\n    Parameters\n    ----------\n    ax : matplotlib Axes, optional\n        If None, create a new figure/axes.\n    **kwargs : dict\n        Passed along to ax.plot(), e.g. color, linewidth, etc.\n\n    Returns\n    -------\n    ax : matplotlib Axes\n    \"\"\"\n    import matplotlib.pyplot as plt\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(6, 4))\n    merges = self.merges_\n    if merges.size == 0:\n        ax.set_title(\"No merges recorded (maybe n &lt;= n_clusters?).\")\n        return ax\n\n    # merges_ is (step, 4): [clusterA, clusterB, dist, new_size]\n    # We want to plot something like a dendrogram:\n    #  - each row is a merge event\n    #  - x-axis might show cluster A and cluster B, y the 'distance'\n    # But cluster IDs might keep re-labelling, so a quick hack is we show them as is.\n\n    for step, (ca, cb, distval, new_size) in enumerate(merges):\n        # We'll draw a \"u\" connecting ca and cb at height distval\n        # Then the newly formed cluster could get ID=cb or something\n        # This is a naive approach that won't produce a fancy SciPy-like dendrogram\n        # but enough to illustrate what's happening.\n\n        x1, x2 = ca, cb\n        y = distval\n        # a line from (x1, 0) to (x1, y), from (x2, 0) to (x2, y),\n        # then a horizontal line across at y\n        # we can color them or style them with kwargs\n\n        ax.plot([x1, x1], [0, y], **kwargs)\n        ax.plot([x2, x2], [0, y], **kwargs)\n        ax.plot([x1, x2], [y, y], **kwargs)\n\n    ax.set_title(\"Rudimentary Dendrogram\")\n    ax.set_xlabel(\"Cluster ID (raw internal IDs)\")\n    ax.set_ylabel(\"Distance\")\n    return ax\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircHAC.silhouette_score","title":"<code>silhouette_score()</code>","text":"<p>Compute the average silhouette for a cluster assignment on circular data.</p> <p>angles: np.ndarray shape (n,) in radians labels: np.ndarray shape (n,) in {0,1,...,K-1} metric: \"chord\", \"geodesic\", \"center\", etc.</p> <p>Returns:</p> Type Description <code>float</code> <p>The mean silhouette over all points.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def silhouette_score(self):\n    \"\"\"\n    Compute the average silhouette for a cluster assignment on circular data.\n\n    angles: np.ndarray shape (n,) in radians\n    labels: np.ndarray shape (n,) in {0,1,...,K-1}\n    metric: \"chord\", \"geodesic\", \"center\", etc.\n\n    Returns\n    -------\n    float\n        The mean silhouette over all points.\n    \"\"\"\n    angles = self.alpha\n    labels = self.labels_\n    metric = self.metric\n    n = len(angles)\n    if n &lt; 2:\n        return 0.0\n\n    silhouette_values = np.zeros(n, dtype=float)\n\n    # Precompute all pairwise distances\n    # shape =&gt; (n,n)\n    pairwise = circ_dist(angles[:,None], angles[None,:], metric=metric)\n    pairwise = np.abs(pairwise)  # ensure nonnegative\n\n    for i in range(n):\n        c_i = labels[i]\n        # points in cluster c_i\n        in_cluster_i = (labels == c_i)\n        # average distance to own cluster\n        # excluding the point itself\n        a_i = pairwise[i, in_cluster_i].mean() if in_cluster_i.sum() &gt; 1 else 0.0\n\n        # find min average distance to another cluster\n        b_i = np.inf\n        for c_other in np.unique(labels):\n            if c_other == c_i:\n                continue\n            in_other = (labels == c_other)\n            dist_i_other = pairwise[i, in_other].mean()\n            if dist_i_other &lt; b_i:\n                b_i = dist_i_other\n\n        silhouette_values[i] = (b_i - a_i) / max(a_i, b_i) if max(a_i, b_i) &gt; 0 else 0.0\n\n    return silhouette_values.mean()\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircKMeans","title":"<code>CircKMeans</code>","text":"<p>K-Means clustering for circular (1D) data.</p> <p>This is analogous to standard K-Means, but uses circular distance and circular means. The algorithm is:</p> <p>1) Initialize cluster centers (angles in radians). 2) Assignment step:    Assign each data point to the cluster with the minimal    circular distance. 3) Update step:    Recompute each cluster center as the circular mean of    the assigned points. 4) Repeat until convergence or max_iters.</p> <p>Parameters:</p> Name Type Description Default <code>n_clusters</code> <code>int</code> <p>Number of clusters to form.</p> <code>2</code> <code>max_iter</code> <code>int</code> <p>Maximum number of iterations.</p> <code>100</code> <code>metric</code> <code>(center, chord, geodesic, angularseparation)</code> <p>The distance measure used for assignment.</p> <code>\"center\"</code> <code>unit</code> <code>(degree, radian)</code> <p>Whether input data is in degrees or radians. If \"degree\", we convert to radians internally.</p> <code>\"degree\",\"radian\"</code> <code>full_cycle</code> <code>int</code> <p>For data conversion if unit=\"degree\".</p> <code>360</code> <code>tol</code> <code>float</code> <p>Convergence threshold. If centers move less than <code>tol</code> in total, the algorithm stops.</p> <code>1e-6</code> <code>random_seed</code> <code>int</code> <p>For reproducible initialization.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>centers_</code> <code>(ndarray, shape(n_clusters))</code> <p>The final cluster center angles (in radians).</p> <code>labels_</code> <code>(ndarray, shape(n_samples))</code> <p>The assigned cluster indices for each data point.</p> <code>inertia_</code> <code>float</code> <p>The final sum of distances (or sum of squared distances) if you prefer, from each point to its cluster center. By default, we store sum of chosen distance measure.</p> Source code in <code>pycircstat2/clustering.py</code> <pre><code>class CircKMeans:\n    \"\"\"\n    K-Means clustering for circular (1D) data.\n\n    This is analogous to standard K-Means, but uses circular\n    distance and circular means. The algorithm is:\n\n    1) Initialize cluster centers (angles in radians).\n    2) Assignment step:\n       Assign each data point to the cluster with the minimal\n       circular distance.\n    3) Update step:\n       Recompute each cluster center as the circular mean of\n       the assigned points.\n    4) Repeat until convergence or max_iters.\n\n    Parameters\n    ----------\n    n_clusters : int, default=2\n        Number of clusters to form.\n    max_iter : int, default=100\n        Maximum number of iterations.\n    metric : {\"center\", \"chord\", \"geodesic\", \"angularseparation\"}, default=\"chord\"\n        The distance measure used for assignment.\n    unit : {\"degree\",\"radian\"}, default=\"degree\"\n        Whether input data is in degrees or radians.\n        If \"degree\", we convert to radians internally.\n    full_cycle : int, default=360\n        For data conversion if unit=\"degree\".\n    tol : float, default=1e-6\n        Convergence threshold. If centers move less than `tol` in total,\n        the algorithm stops.\n    random_seed : int, default=None\n        For reproducible initialization.\n\n    Attributes\n    ----------\n    centers_ : np.ndarray, shape (n_clusters,)\n        The final cluster center angles (in radians).\n    labels_ : np.ndarray, shape (n_samples,)\n        The assigned cluster indices for each data point.\n    inertia_ : float\n        The final sum of distances (or sum of squared distances) if you prefer,\n        from each point to its cluster center. By default, we store\n        sum of chosen distance measure.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters=2,\n        max_iter=100,\n        metric=\"center\",\n        unit=\"degree\",\n        full_cycle=360,\n        tol=1e-6,\n        random_seed=None\n    ):\n        self.n_clusters = n_clusters\n        self.max_iter = max_iter\n        self.metric = metric\n        self.unit = unit\n        self.full_cycle = full_cycle\n        self.tol = tol\n        self.random_seed = random_seed\n\n        self.centers_ = None\n        self.labels_ = None\n        self.inertia_ = None\n\n    def fit(self, X):\n        \"\"\"\n        Fit the K-means on 1D circular data.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples,)\n            Angles in degrees (if self.unit==\"degree\") or radians.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        self.data = X = np.asarray(X)\n        if self.unit == \"degree\":\n            self.alpha = alpha = data2rad(X, k=self.full_cycle)\n        else:\n            self.alpha = alpha = X\n\n        rng = np.random.default_rng(self.random_seed)\n\n        n_samples = len(alpha)\n        if n_samples &lt; self.n_clusters:\n            # trivial: each point is its own cluster\n            self.labels_ = np.arange(n_samples)\n            self.centers_ = alpha.copy()\n            self.inertia_ = 0.0\n            return self\n\n        # 1) initialize cluster centers by picking random points from data\n        init_indices = rng.choice(n_samples, size=self.n_clusters, replace=False)\n        centers = alpha[init_indices]\n\n        labels = np.zeros(n_samples, dtype=int)\n        for iteration in range(self.max_iter):\n            # 2) assignment step\n            dist_mat = np.zeros((self.n_clusters, n_samples))\n            for c in range(self.n_clusters):\n                # measure distance from alpha to center[c]\n                dist_mat[c] = np.abs(circ_dist(alpha, centers[c], metric=self.metric))\n\n            labels_new = dist_mat.argmin(axis=0)\n\n            # 3) update step\n            new_centers = np.zeros_like(centers)\n            for c in range(self.n_clusters):\n                mask = (labels_new == c)\n                if np.any(mask):\n                    # circular mean of assigned points\n                    m, _ = circ_mean_and_r(alpha[mask])\n                    new_centers[c] = m\n                else:\n                    # if no points assigned, keep old center or random re-init\n                    new_centers[c] = centers[c]\n\n            # check for shift\n            shift = np.sum(np.abs(np.angle(np.exp(1j*centers) / np.exp(1j*new_centers))))\n            # or a simpler approach: sum of circ_dist(centers, new_centers)\n            # shift = float(np.sum(np.abs(circ_dist(centers, new_centers, metric=self.metric))))\n\n            labels = labels_new\n            centers = new_centers\n\n            if shift &lt; self.tol:\n                break\n\n        # final\n        self.centers_ = centers\n        self.labels_ = labels\n\n        # compute final inertia =&gt; sum of distances from points to assigned center\n        total_dist = 0.0\n        for c in range(self.n_clusters):\n            mask = (labels == c)\n            if np.any(mask):\n                dvals = np.abs(circ_dist(alpha[mask], centers[c], metric=self.metric))\n                total_dist += dvals.sum()\n        self.inertia_ = total_dist\n\n    def predict(self, X):\n        \"\"\"\n        Predict cluster assignment for new data.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples,)\n\n        Returns\n        -------\n        labels : np.ndarray, shape (n_samples,)\n        \"\"\"\n        X = np.asarray(X)\n        if self.unit == \"degree\":\n            alpha = data2rad(X, k=self.full_cycle)\n        else:\n            alpha = X\n\n        n_samples = len(alpha)\n        labels = np.zeros(n_samples, dtype=int)\n        if self.centers_ is None:\n            raise ValueError(\"Model not fitted. Call fit() first.\")\n\n        dist_mat = np.zeros((self.n_clusters, n_samples))\n        for c in range(self.n_clusters):\n            dist_mat[c] = np.abs(circ_dist(alpha, self.centers_[c], metric=self.metric))\n        labels = dist_mat.argmin(axis=0)\n        return labels\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircKMeans.fit","title":"<code>fit(X)</code>","text":"<p>Fit the K-means on 1D circular data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>(array - like, shape(n_samples))</code> <p>Angles in degrees (if self.unit==\"degree\") or radians.</p> required <p>Returns:</p> Type Description <code>self</code> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def fit(self, X):\n    \"\"\"\n    Fit the K-means on 1D circular data.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_samples,)\n        Angles in degrees (if self.unit==\"degree\") or radians.\n\n    Returns\n    -------\n    self\n    \"\"\"\n    self.data = X = np.asarray(X)\n    if self.unit == \"degree\":\n        self.alpha = alpha = data2rad(X, k=self.full_cycle)\n    else:\n        self.alpha = alpha = X\n\n    rng = np.random.default_rng(self.random_seed)\n\n    n_samples = len(alpha)\n    if n_samples &lt; self.n_clusters:\n        # trivial: each point is its own cluster\n        self.labels_ = np.arange(n_samples)\n        self.centers_ = alpha.copy()\n        self.inertia_ = 0.0\n        return self\n\n    # 1) initialize cluster centers by picking random points from data\n    init_indices = rng.choice(n_samples, size=self.n_clusters, replace=False)\n    centers = alpha[init_indices]\n\n    labels = np.zeros(n_samples, dtype=int)\n    for iteration in range(self.max_iter):\n        # 2) assignment step\n        dist_mat = np.zeros((self.n_clusters, n_samples))\n        for c in range(self.n_clusters):\n            # measure distance from alpha to center[c]\n            dist_mat[c] = np.abs(circ_dist(alpha, centers[c], metric=self.metric))\n\n        labels_new = dist_mat.argmin(axis=0)\n\n        # 3) update step\n        new_centers = np.zeros_like(centers)\n        for c in range(self.n_clusters):\n            mask = (labels_new == c)\n            if np.any(mask):\n                # circular mean of assigned points\n                m, _ = circ_mean_and_r(alpha[mask])\n                new_centers[c] = m\n            else:\n                # if no points assigned, keep old center or random re-init\n                new_centers[c] = centers[c]\n\n        # check for shift\n        shift = np.sum(np.abs(np.angle(np.exp(1j*centers) / np.exp(1j*new_centers))))\n        # or a simpler approach: sum of circ_dist(centers, new_centers)\n        # shift = float(np.sum(np.abs(circ_dist(centers, new_centers, metric=self.metric))))\n\n        labels = labels_new\n        centers = new_centers\n\n        if shift &lt; self.tol:\n            break\n\n    # final\n    self.centers_ = centers\n    self.labels_ = labels\n\n    # compute final inertia =&gt; sum of distances from points to assigned center\n    total_dist = 0.0\n    for c in range(self.n_clusters):\n        mask = (labels == c)\n        if np.any(mask):\n            dvals = np.abs(circ_dist(alpha[mask], centers[c], metric=self.metric))\n            total_dist += dvals.sum()\n    self.inertia_ = total_dist\n</code></pre>"},{"location":"reference/clustering/#pycircstat2.clustering.CircKMeans.predict","title":"<code>predict(X)</code>","text":"<p>Predict cluster assignment for new data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>(array - like, shape(n_samples))</code> required <p>Returns:</p> Name Type Description <code>labels</code> <code>(ndarray, shape(n_samples))</code> Source code in <code>pycircstat2/clustering.py</code> <pre><code>def predict(self, X):\n    \"\"\"\n    Predict cluster assignment for new data.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_samples,)\n\n    Returns\n    -------\n    labels : np.ndarray, shape (n_samples,)\n    \"\"\"\n    X = np.asarray(X)\n    if self.unit == \"degree\":\n        alpha = data2rad(X, k=self.full_cycle)\n    else:\n        alpha = X\n\n    n_samples = len(alpha)\n    labels = np.zeros(n_samples, dtype=int)\n    if self.centers_ is None:\n        raise ValueError(\"Model not fitted. Call fit() first.\")\n\n    dist_mat = np.zeros((self.n_clusters, n_samples))\n    for c in range(self.n_clusters):\n        dist_mat[c] = np.abs(circ_dist(alpha, self.centers_[c], metric=self.metric))\n    labels = dist_mat.argmin(axis=0)\n    return labels\n</code></pre>"},{"location":"reference/correlation/","title":"Correlation","text":""},{"location":"reference/correlation/#pycircstat2.correlation.circ_corrcc","title":"<code>circ_corrcc(a, b, method='fl', test=False, strict=True)</code>","text":"<p>Angular-Angular / Spherical Correlation.</p> <p>Three methods are available:</p> <ul> <li>'fl' (Fisher &amp; Lee, 1983): T-linear association. The correlation coefficient</li> </ul> \\[ r = \\frac{\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin(a_{ij}) \\sin(b_{ij})}{\\sqrt{\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin^2(a_{ij}) \\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin^2(b_{ij})}} \\] <ul> <li>'js' (Jammalamadaka &amp; SenGupta, 2001)</li> </ul> \\[ r = \\frac{\\sum \\sin(a_i - \\bar{a}) \\sin(b_i - \\bar{b})}{\\sqrt{\\sum \\sin^2(a_i - \\bar{a}) \\sum \\sin^2(b_i - \\bar{b})}} \\] <ul> <li>'nonparametric'</li> </ul> \\[ r = \\frac{\\sum \\cos(C \\cdot \\text{rankdiff})^2 + \\sum \\sin(C \\cdot \\text{rankdiff})^2}{n^2} - \\frac{\\sum \\cos(C \\cdot \\text{ranksum})^2 + \\sum \\sin(C \\cdot \\text{ranksum})^2}{n^2} \\] <p>, where \\(C = 2\\pi / n\\) and \\(\\text{rankdiff} = \\text{rank}_a - \\text{rank}_b\\) and \\(\\text{ranksum} = \\text{rank}_a + \\text{rank}_b\\).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[Type[Circular], ndarray]</code> <p>Angles in radian</p> required <code>b</code> <code>Union[Type[Circular], ndarray]</code> <p>Angles in radian</p> required <code>method</code> <code>str</code> <ul> <li>'fl' (Fisher &amp; Lee, 1983): T-linear association. The correlation coefficient   is computed as:</li> <li>'js' (Jammalamadaka &amp; SenGupta, 2001)</li> <li>'nonparametric'</li> </ul> <code>'fl'</code> <code>test</code> <code>bool</code> <p>Return significant test results.</p> <code>False</code> <code>strict</code> <code>bool</code> <p>Strict mode. If True, raise an error when mean direction is not significant. Only for method=\"js\" (Jammalamadaka &amp; SenGupta, 2001).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>r</code> <code>float</code> <p>Correlation coefficient.</p> <code>reject</code> <code>bool</code> <p>Return significant test if <code>test</code> is set to True.</p> Source code in <code>pycircstat2/correlation.py</code> <pre><code>def circ_corrcc(\n    a: Union[Type[Circular], np.ndarray],\n    b: Union[Type[Circular], np.ndarray],\n    method: str = \"fl\",\n    test: bool = False,\n    strict: bool = True,\n) -&gt; Union[float, CorrelationResult]:\n    r\"\"\"\n    Angular-Angular / Spherical Correlation.\n\n    Three methods are available:\n\n    - 'fl' (Fisher &amp; Lee, 1983): T-linear association. The correlation coefficient\n\n    $$\n    r = \\frac{\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin(a_{ij}) \\sin(b_{ij})}{\\sqrt{\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin^2(a_{ij}) \\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\sin^2(b_{ij})}}\n    $$\n\n    - 'js' (Jammalamadaka &amp; SenGupta, 2001)\n\n    $$\n    r = \\frac{\\sum \\sin(a_i - \\bar{a}) \\sin(b_i - \\bar{b})}{\\sqrt{\\sum \\sin^2(a_i - \\bar{a}) \\sum \\sin^2(b_i - \\bar{b})}}\n    $$\n\n    - 'nonparametric'\n\n    $$\n    r = \\frac{\\sum \\cos(C \\cdot \\text{rankdiff})^2 + \\sum \\sin(C \\cdot \\text{rankdiff})^2}{n^2} - \\frac{\\sum \\cos(C \\cdot \\text{ranksum})^2 + \\sum \\sin(C \\cdot \\text{ranksum})^2}{n^2}\n    $$\n\n    , where $C = 2\\pi / n$ and $\\text{rankdiff} = \\text{rank}_a - \\text{rank}_b$ and $\\text{ranksum} = \\text{rank}_a + \\text{rank}_b$.\n\n\n    Parameters\n    ----------\n    a: Circular or np.ndarray\n        Angles in radian\n    b: Circular or np.ndarray\n        Angles in radian\n    method: str\n        - 'fl' (Fisher &amp; Lee, 1983): T-linear association. The correlation coefficient\n          is computed as:\n        - 'js' (Jammalamadaka &amp; SenGupta, 2001)\n        - 'nonparametric'\n    test: bool\n        Return significant test results.\n    strict: bool\n        Strict mode. If True, raise an error when mean direction is\n        not significant. Only for method=\"js\" (Jammalamadaka &amp; SenGupta, 2001).\n\n    Returns\n    -------\n    r: float\n        Correlation coefficient.\n    reject: bool\n        Return significant test if `test` is set to True.\n    \"\"\"\n\n    if method == \"fl\":  # Fisher &amp; Lee (1983)\n        _corr = _circ_corrcc_fl\n    elif method == \"js\":  # Jammalamadaka &amp; SenGupta (2001)\n        _corr = _circ_corrcc_js\n    elif method == \"nonparametric\":\n        _corr = _circ_corrcc_np\n    else:\n        raise ValueError(\"Invalid method. Choose from 'fl', 'js', 'nonparametric'.\")\n\n    result = _corr(a, b, test, strict)\n\n    if test:\n        return result\n    else:\n        return result.r\n</code></pre>"},{"location":"reference/correlation/#pycircstat2.correlation.circ_corrcl","title":"<code>circ_corrcl(a, x)</code>","text":"<p>Angular-Linear / Cylindrical Correlation based on Mardia (1972).</p> <p>Also known as Linear-circular or C-linear association (Fisher, 1993).</p> \\[ r = \\sqrt{\\frac{r_{xc}^2 + r_{xs}^2 - 2r_{xc}r_{xs}r_{cs}}{1 - r_{cs}^2}} \\] <p>where \\(r_{xc}\\), \\(r_{xs}\\), and \\(r_{cs}\\) are the correlation coefficients between \\(\\cos(a)\\) and \\(x\\), \\(x\\) and \\(\\sin(a)\\), and \\(\\sin(a)\\) and \\(\\cos(a)\\), respectively.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[Type[Circular], ndarray]</code> <p>Angles in radian</p> required <code>x</code> <code>ndarray</code> <p>Linear variable</p> required <p>Returns:</p> Name Type Description <code>ral</code> <code>float</code> <p>correlation coefficient.</p> <code>pval</code> <code>float</code> Reference <p>P658-659, Section 27.15(b) of Example 27.21 (Zar, 2010).</p> Source code in <code>pycircstat2/correlation.py</code> <pre><code>def circ_corrcl(\n    a: Union[Type[Circular], np.ndarray],\n    x: np.ndarray,\n) -&gt; CorrelationResult:\n    r\"\"\"Angular-Linear / Cylindrical Correlation based on Mardia (1972).\n\n    Also known as Linear-circular or C-linear association (Fisher, 1993).\n\n    $$\n    r = \\sqrt{\\frac{r_{xc}^2 + r_{xs}^2 - 2r_{xc}r_{xs}r_{cs}}{1 - r_{cs}^2}}\n    $$\n\n    where $r_{xc}$, $r_{xs}$, and $r_{cs}$ are the correlation coefficients between\n    $\\cos(a)$ and $x$, $x$ and $\\sin(a)$, and $\\sin(a)$ and $\\cos(a)$, respectively.\n\n    Parameters\n    ----------\n    a: Circular or np.ndarray\n        Angles in radian\n    x: np.ndarray\n        Linear variable\n\n    Returns\n    -------\n    ral: float\n        correlation coefficient.\n    pval: float\n\n    Reference\n    ----\n    P658-659, Section 27.15(b) of Example 27.21 (Zar, 2010).\n    \"\"\"\n\n    a_alpha = np.array(a.alpha) if isinstance(a, Circular) else a\n\n    if len(a_alpha) != len(x):\n        raise ValueError(\"`a` and `x` must be the same length.\")\n\n    n = len(a_alpha)\n\n    rxc = np.corrcoef(np.cos(a), x)[0, 1]\n    rxs = np.corrcoef(x, np.sin(a))[0, 1]\n    rcs = np.corrcoef(np.sin(a), np.cos(a))[0, 1]\n\n    num = rxc**2 + rxs**2 - 2 * rxc * rxs * rcs\n    den = 1 - rcs**2\n    r = np.sqrt(num / den)\n\n    pval = 1 - chi2(df=2).cdf(n * r**2)\n\n    return CorrelationResult(r=r, p_value=pval)\n</code></pre>"},{"location":"reference/descriptive/","title":"Descriptive Statistics","text":""},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_r","title":"<code>circ_r(alpha=None, w=None, Cbar=None, Sbar=None)</code>","text":"<p>Circular mean resultant vector length (r).</p> \\[ r = \\sqrt{\\bar{C}^2 + \\bar{S}^2} \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>Cbar</code> <code>Optional[float]</code> <p>Precomputed intermediate values</p> <code>None</code> <code>Sbar</code> <code>Optional[float]</code> <p>Precomputed intermediate values</p> <code>None</code> <p>Returns:</p> Name Type Description <code>r</code> <code>float</code> <p>Resultant vector length</p> References <p>Implementation of Example 26.5 (Zar, 2010)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_r(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    Cbar: Optional[float] = None,\n    Sbar: Optional[float] = None,\n) -&gt; float:\n    r\"\"\"\n    Circular mean resultant vector length (r).\n\n    $$\n    r = \\sqrt{\\bar{C}^2 + \\bar{S}^2}\n    $$\n\n    Parameters\n    ----------\n    alpha: np.array (n, )\n        Angles in radian.\n    w: np.array (n,)\n        Frequencies or weights\n    Cbar, Sbar: float\n        Precomputed intermediate values\n\n    Returns\n    -------\n    r: float\n        Resultant vector length\n\n    References\n    ----------\n    Implementation of Example 26.5 (Zar, 2010)\n    \"\"\"\n    if Cbar is None or Sbar is None:\n        if alpha is None:\n            raise ValueError(\"`alpha` is required if `Cbar` and `Sbar` are not provided.\")\n        w = np.ones_like(alpha) if w is None else w\n        Cbar, Sbar = compute_C_and_S(alpha, w)\n\n    r = np.sqrt(Cbar**2 + Sbar**2)\n\n    return r\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean","title":"<code>circ_mean(alpha, w=None)</code>","text":"<p>Circular mean (m).</p> \\[\\cos\\bar\\theta = C/R,\\space \\sin\\bar\\theta = S/R\\] <p>or </p> \\[ \\bar\\theta = \\begin{cases}  \\tan^{-1}\\left(S/C\\right), &amp; \\text{if } S &gt; 0, C &gt; 0 \\\\  \\tan^{-1}\\left(S/C\\right) + \\pi, &amp; \\text{if } C &lt; 0 \\\\  \\tan^{-1}\\left(S/C\\right) + 2\\pi, &amp; \\text{S &lt; 0, C &gt; 0} \\end{cases} \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>float or NaN</code> <p>Circular mean</p> Note <p>Implementation of Example 26.5 (Zar, 2010)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n) -&gt; float:\n    r\"\"\"\n    Circular mean (m).\n\n    $$\\cos\\bar\\theta = C/R,\\space \\sin\\bar\\theta = S/R$$\n\n    or \n\n    $$\n    \\bar\\theta =\n    \\begin{cases} \n    \\tan^{-1}\\left(S/C\\right), &amp; \\text{if } S &gt; 0, C &gt; 0 \\\\ \n    \\tan^{-1}\\left(S/C\\right) + \\pi, &amp; \\text{if } C &lt; 0 \\\\ \n    \\tan^{-1}\\left(S/C\\right) + 2\\pi, &amp; \\text{S &lt; 0, C &gt; 0}\n    \\end{cases}\n    $$\n\n    Parameters\n    ----------\n    alpha: np.array (n, )\n        Angles in radian.\n    w: np.array (n,)\n        Frequencies or weights\n\n    Returns\n    -------\n    m: float or NaN\n        Circular mean\n\n    Note\n    ----\n    Implementation of Example 26.5 (Zar, 2010)\n    \"\"\"\n    if w is None:\n        w = np.ones_like(alpha)\n\n    # mean resultant vecotr length\n    Cbar, Sbar = compute_C_and_S(alpha, w)\n    r = circ_r(alpha, w, Cbar, Sbar)\n\n    # angular mean\n    if np.isclose(r, 0):\n        m = np.nan\n    else:\n        m = np.arctan2(Sbar, Cbar)\n\n    return float(angmod(m))\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_and_r","title":"<code>circ_mean_and_r(alpha, w=None)</code>","text":"<p>Circular mean (m) and resultant vector length (r).</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>float or NaN</code> <p>Circular mean</p> <code>r</code> <code>float</code> <p>Resultant vector length</p> Note <p>Implementation of Example 26.5 (Zar, 2010)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean_and_r(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Circular mean (m) and resultant vector length (r).\n\n    Parameters\n    ----------\n    alpha: np.array (n, )\n        Angles in radian.\n    w: np.array (n,)\n        Frequencies or weights\n\n    Returns\n    -------\n    m: float or NaN\n        Circular mean\n    r: float\n        Resultant vector length\n\n    Note\n    ----\n    Implementation of Example 26.5 (Zar, 2010)\n    \"\"\"\n    if w is None:\n        w = np.ones_like(alpha)\n\n    # mean resultant vecotr length\n    Cbar, Sbar = compute_C_and_S(alpha, w)\n    r = circ_r(alpha, w, Cbar, Sbar)\n\n    # angular mean\n    if np.isclose(r, 0):\n        m = np.nan\n        return float(m), r\n    else:\n        m = np.arctan2(Sbar, Cbar)\n\n        return float(angmod(m)), r\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_and_r_of_means","title":"<code>circ_mean_and_r_of_means(circs=None, ms=None, rs=None)</code>","text":"<p>The Mean of a set of Mean Angles</p> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>Union[list, None]</code> <p>a list of Circular Objects</p> <code>None</code> <code>ms</code> <code>Optional[ndarray]</code> <p>a set of mean angles in radian</p> <code>None</code> <code>rs</code> <code>Optional[ndarray]</code> <p>a set of mean resultant vecotr lengths</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>float</code> <p>mean of means in radian</p> <code>r</code> <code>float</code> <p>mean of mean resultant vector lengths</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean_and_r_of_means(\n    circs: Union[list, None] = None,\n    ms: Optional[np.ndarray] = None,\n    rs: Optional[np.ndarray] = None,\n) -&gt; Tuple[float, float]:\n    \"\"\"The Mean of a set of Mean Angles\n\n    Parameters\n    ----------\n    circs: list\n        a list of Circular Objects\n\n    ms: np.array (n, )\n        a set of mean angles in radian\n\n    rs: np.array (n, )\n        a set of mean resultant vecotr lengths\n\n    Returns\n    -------\n    m: float\n        mean of means in radian\n\n    r: float\n        mean of mean resultant vector lengths\n\n    \"\"\"\n\n    if circs is None:\n        assert isinstance(ms, np.ndarray) and isinstance(rs, np.ndarray), (\n            \"If `circs` is None, then `ms` and `rs` are needed.\"\n        )\n    else:\n        ms, rs = map(np.array, zip(*[(circ.mean, circ.r) for circ in circs]))\n\n    X = np.mean(np.cos(ms) * rs)\n    Y = np.mean(np.sin(ms) * rs)\n    r = np.sqrt(X**2 + Y**2)\n    C = X / r\n    S = Y / r\n\n    m = angmod(np.arctan2(S, C))\n\n    return float(m), r\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_moment","title":"<code>circ_moment(alpha, w=None, p=1, mean=None, centered=False)</code>","text":"<p>Compute the p-th circular moment.</p> \\[ m^{\\prime}_{p} = \\bar{C}_{p} + i\\bar{S}_{p} \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights. If None, equal weights are used.</p> <code>None</code> <code>p</code> <code>int</code> <p>Order of the moment to compute.</p> <code>1</code> <code>mean</code> <code>Union[float, ndarray, None]</code> <p>Precomputed circular mean. If None, mean is computed internally.</p> <code>None</code> <code>centered</code> <code>bool</code> <p>If True, center alpha by subtracting the mean.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>mp</code> <code>complex</code> <p>The p-th circular moment as a complex number.</p> Note <p>Implementation of Equation 2.24 (Fisher, 1993).</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_moment(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    p: int = 1,\n    mean: Union[float, np.ndarray, None] = None,\n    centered: bool = False,\n) -&gt; complex:\n    r\"\"\"\n    Compute the p-th circular moment.\n\n    $$\n    m^{\\prime}_{p} = \\bar{C}_{p} + i\\bar{S}_{p}\n    $$\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        Angles in radian.\n    w: np.ndarray, optional\n        Frequencies or weights. If None, equal weights are used.\n    p: int, optional\n        Order of the moment to compute.\n    mean: float, optional\n        Precomputed circular mean. If None, mean is computed internally.\n    centered: bool, optional\n        If True, center alpha by subtracting the mean.\n\n    Returns\n    -------\n    mp: complex\n        The p-th circular moment as a complex number.\n\n    Note\n    ----\n    Implementation of Equation 2.24 (Fisher, 1993).\n    \"\"\"\n    if w is None:\n        w = np.ones_like(alpha)\n\n    if mean is None:\n        mean = circ_mean(alpha, w) if centered else 0.0\n\n    Cbar, Sbar = compute_C_and_S(alpha, w, p, mean)\n\n    return Cbar + 1j * Sbar\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_dispersion","title":"<code>circ_dispersion(alpha, w=None, mean=None)</code>","text":"<p>Sample Circular Dispersion, defined by Equation 2.28 (Fisher, 1993):</p> \\[ \\hat\\delta = (1 - \\hat\\rho_{2})/(2 \\hat\\rho_{1}^{2}) \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>mean</code> <p>Precomputed circular mean.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dispersion</code> <code>float</code> <p>Sample Circular Dispersion</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_dispersion(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    mean=None,\n) -&gt; float:\n    r\"\"\"\n    Sample Circular Dispersion, defined by Equation 2.28 (Fisher, 1993):\n\n    $$\n    \\hat\\delta = (1 - \\hat\\rho_{2})/(2 \\hat\\rho_{1}^{2})\n    $$\n\n    Parameters\n    ----------\n\n    alpha: np.array, (n, )\n        Angles in radian.\n    w: None or np.array, (n)\n        Frequencies or weights\n    mean: None or float\n        Precomputed circular mean.\n\n    Returns\n    -------\n    dispersion: float\n        Sample Circular Dispersion\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    mp1 = circ_moment(alpha=alpha, w=w, p=1, mean=mean, centered=False)  # eq(2.26)\n    mp2 = circ_moment(alpha=alpha, w=w, p=2, mean=mean, centered=False)  # eq(2.27)\n\n    r1 = np.abs(mp1)\n    r2 = np.abs(mp2)\n\n    dispersion = (1 - r2) / (2 * r1**2)  # eq(2.28)\n\n    return dispersion\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_skewness","title":"<code>circ_skewness(alpha, w=None)</code>","text":"<p>Circular skewness, as defined by Equation 2.29 (Fisher, 1993):</p> \\[\\hat s = [\\hat\\rho_2 \\sin(\\hat\\mu_2 - 2 \\hat\\mu_1)] / (1 - \\hat\\rho_1)^{\\frac{3}{2}}\\] <p>But unlike the implementation of Fisher (1993), here we followed Pewsey et al. (2014) by NOT centering the second moment.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <p>Returns:</p> Name Type Description <code>skewness</code> <code>float</code> <p>Circular Skewness</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_skewness(alpha: np.ndarray, w: Optional[np.ndarray] = None) -&gt; float:\n    r\"\"\"\n    Circular skewness, as defined by Equation 2.29 (Fisher, 1993):\n\n    $$\\hat s = [\\hat\\rho_2 \\sin(\\hat\\mu_2 - 2 \\hat\\mu_1)] / (1 - \\hat\\rho_1)^{\\frac{3}{2}}$$\n\n    But unlike the implementation of Fisher (1993), here we followed Pewsey et al. (2014) by NOT centering the second moment.\n\n    Parameters\n    ----------\n\n    alpha: np.array, (n, )\n        Angles in radian.\n    w: None or np.array, (n)\n        Frequencies or weights\n\n    Returns\n    -------\n    skewness: float\n        Circular Skewness\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    mp1 = circ_moment(alpha=alpha, w=w, p=1, mean=None, centered=False)\n    mp2 = circ_moment(alpha=alpha, w=w, p=2, mean=None, centered=False)  # eq(2.27)\n\n    u1, r1 = convert_moment(mp1)\n    u2, r2 = convert_moment(mp2)\n\n    skewness = (r2 * np.sin(u2 - 2 * u1)) / (1 - r1) ** 1.5\n\n    return skewness\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_kurtosis","title":"<code>circ_kurtosis(alpha, w=None)</code>","text":"<p>Circular kurtosis, as defined by Equation 2.30 (Fisher, 1993):</p> \\[\\hat k = [\\hat\\rho_2 \\cos(\\hat\\mu_2 - 2 \\hat\\mu_1) - \\hat\\rho_1^4] / (1 - \\hat\\rho_1)^{2}\\] <p>But unlike the implementation of Fisher (1993), here we followed Pewsey et al. (2014) by NOT centering the second moment.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <p>Returns:</p> Name Type Description <code>kurtosis</code> <code>float</code> <p>Circular Kurtosis</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_kurtosis(alpha: np.ndarray, w: Optional[np.ndarray] = None) -&gt; float:\n    r\"\"\"\n    Circular kurtosis, as defined by Equation 2.30 (Fisher, 1993):\n\n    $$\\hat k = [\\hat\\rho_2 \\cos(\\hat\\mu_2 - 2 \\hat\\mu_1) - \\hat\\rho_1^4] / (1 - \\hat\\rho_1)^{2}$$\n\n    But unlike the implementation of Fisher (1993), here we followed Pewsey et al. (2014) by **NOT** centering the second moment.\n\n    Parameters\n    ----------\n\n    alpha: np.array, (n, )\n        Angles in radian.\n    w: None or np.array, (n)\n        Frequencies or weights\n\n    Returns\n    -------\n    kurtosis: float\n        Circular Kurtosis\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    mp1 = circ_moment(alpha=alpha, w=w, p=1, mean=None, centered=False)\n    mp2 = circ_moment(alpha=alpha, w=w, p=2, mean=None, centered=False)  # eq(2.27)\n\n    u1, r1 = convert_moment(mp1)\n    u2, r2 = convert_moment(mp2)\n\n    kurtosis = (r2 * np.cos(u2 - 2 * u1) - r1**4) / (1 - r1) ** 2\n\n    return kurtosis\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.angular_var","title":"<code>angular_var(alpha=None, w=None, r=None, bin_size=None)</code>","text":"<p>Angular variance</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length</p> <code>None</code> <code>bin_size</code> <code>Optional[float]</code> <p>Interval size of grouped data. Needed for correcting biased r.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>angular_variance</code> <code>float</code> <p>Angular variance, range from 0 to 2.</p> References <ul> <li>Batschlet (1965, 1981), from Section 26.5 of Zar (2010)</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def angular_var(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    r: Optional[float] = None,\n    bin_size: Optional[float] = None,\n) -&gt; float:\n    r\"\"\"\n    Angular variance\n\n    Parameters\n    ----------\n    alpha: np.array (n, ) or None\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    r: float or None\n        Resultant vector length\n    bin_size: float\n        Interval size of grouped data. Needed for correcting biased r.\n\n    Returns\n    -------\n    angular_variance: float\n        Angular variance, range from 0 to 2.\n\n    References\n    ----------\n    - Batschlet (1965, 1981), from Section 26.5 of Zar (2010)\n    \"\"\"\n\n    variance = circ_var(alpha=alpha, w=w, r=r, bin_size=bin_size)\n    angular_variance = 2 * variance\n    return angular_variance\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.angular_std","title":"<code>angular_std(alpha=None, w=None, r=None, bin_size=None)</code>","text":"<p>Angular (standard) deviation</p> \\[ s = \\sqrt{2V} = \\sqrt{2(1 - r)} \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length</p> <code>None</code> <code>bin_size</code> <code>Optional[float]</code> <p>Interval size of grouped data. Needed for correcting biased r.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>angular_std</code> <code>float</code> <p>Angular (standard) deviation, range from 0 to sqrt(2).</p> References <ul> <li>Equation 26.20 of Zar (2010)</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def angular_std(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    r: Optional[float] = None,\n    bin_size: Optional[float] = None,\n) -&gt; float:\n    r\"\"\"\n    Angular (standard) deviation\n\n    $$\n    s = \\sqrt{2V} = \\sqrt{2(1 - r)}\n    $$\n\n    Parameters\n    ----------\n    alpha: np.array (n, ) or None\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    r: float or None\n        Resultant vector length\n    bin_size: float\n        Interval size of grouped data. Needed for correcting biased r.\n\n    Returns\n    -------\n    angular_std: float\n        Angular (standard) deviation, range from 0 to sqrt(2).\n\n    References\n    ----------\n    - Equation 26.20 of Zar (2010)\n    \"\"\"\n\n    angular_variance = angular_var(alpha=alpha, w=w, r=r, bin_size=bin_size)\n    angular_std = np.sqrt(angular_variance)\n    return angular_std\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_var","title":"<code>circ_var(alpha=None, w=None, r=None, bin_size=None)</code>","text":"<p>Circular variance</p> \\[ V = 1 - r \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length</p> <code>None</code> <code>bin_size</code> <code>Optional[float]</code> <p>Interval size of grouped data. Needed for correcting biased r.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>variance</code> <code>float</code> <p>Circular variance, range from 0 to 1.</p> References <ul> <li>Equation 2.11 of Fisher (1993)</li> <li>Equation 26.17 of Zar (2010)</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_var(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    r: Optional[float] = None,\n    bin_size: Optional[float] = None,\n) -&gt; float:\n    r\"\"\"\n    Circular variance\n\n    $$ V = 1 - r $$\n\n    Parameters\n    ----------\n    alpha: np.array (n, ) or None\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    r: float or None\n        Resultant vector length\n    bin_size: float\n        Interval size of grouped data. Needed for correcting biased r.\n\n    Returns\n    -------\n    variance: float\n        Circular variance, range from 0 to 1.\n\n    References\n    ----------\n    - Equation 2.11 of Fisher (1993)\n    - Equation 26.17 of Zar (2010)\n    \"\"\"\n\n    # If `r` is provided, use it directly\n    if r is None:\n        if alpha is None:\n            raise ValueError(\"If `r` is None, then `alpha` is required to compute it.\")\n        r = circ_r(alpha, w)  # `circ_r` already handles `w=None` as `np.ones_like(alpha)`\n\n    # Determine bin_size if not explicitly provided\n    if bin_size is None and w is not None and not np.all(w == w[0]):\n        if alpha is None:\n            raise ValueError(\"If `bin_size` is None but `w` is provided, `alpha` must be given.\")\n        bin_size = float(np.diff(alpha).min())\n\n    # Correct `r` if binning is applied\n    rc = r if bin_size is None or bin_size == 0 else r * (bin_size / (2 * np.sin(bin_size / 2)))\n\n    variance = 1 - rc\n\n    return variance\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_std","title":"<code>circ_std(alpha=None, w=None, r=None, bin_size=None)</code>","text":"<p>Circular standard deviation (s).</p> \\[ s = \\sqrt{-2 \\ln(1 - V)} \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length</p> <code>None</code> <code>bin_size</code> <code>Optional[float]</code> <p>Interval size of grouped data. Needed for correcting biased r.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>s</code> <code>float</code> <p>Circular standard deviation.</p> References <p>Implementation of Equation 26.15-16/20-21 (Zar, 2010)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_std(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    r: Optional[float] = None,\n    bin_size: Optional[float] = None,\n) -&gt; float:\n    r\"\"\"\n    Circular standard deviation (s).\n\n    $$ s = \\sqrt{-2 \\ln(1 - V)} $$\n\n    Parameters\n    ----------\n    alpha: np.array (n, ) or None\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    r: float or None\n        Resultant vector length\n    bin_size: float\n        Interval size of grouped data.\n        Needed for correcting biased r.\n\n    Returns\n    -------\n    s: float\n        Circular standard deviation.\n\n    References\n    ----------\n    Implementation of Equation 26.15-16/20-21 (Zar, 2010)\n    \"\"\"\n    var = circ_var(alpha=alpha, w=w, r=r, bin_size=bin_size)\n\n    # circular standard deviation\n    s = np.sqrt(-2 * np.log(1 - var))  # eq(26.21)\n\n    return s\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_median","title":"<code>circ_median(alpha, w=None, method='deviation', return_average=True, average_method='all', verbose=False)</code>","text":"<p>Circular median.</p> <p>Two ways to compute the circular median for ungrouped data (Fisher, 1993):</p> <ul> <li><code>deviation</code>: find the angle that has the minimal mean deviation.</li> <li><code>count</code>: find the angle that has the equally devide the number of points on the right and left of it.</li> </ul> <p>For grouped data, we use the method described in Mardia (1972).</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>method</code> <code>str</code> <ul> <li>For ungrouped data, there are two ways</li> <li>To compute the medians:<ul> <li>deviation</li> <li>count</li> </ul> </li> <li>Set to <code>none</code> to return np.nan.</li> </ul> <code>'deviation'</code> <code>return_average</code> <code>bool</code> <p>Return the average of the median</p> <code>True</code> <code>average_method</code> <code>str</code> <ul> <li>all: circular mean of all medians</li> <li>unique: circular mean of unique medians</li> </ul> <code>'all'</code> <p>Returns:</p> Name Type Description <code>median</code> <code>float or NaN</code> References <ul> <li>For ungrouped data: Section 2.3.2 of Fisher (1993)</li> <li>For grouped data: Mardia (1972)</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_median(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    method: str = \"deviation\",\n    return_average: bool = True,\n    average_method: str = \"all\",\n    verbose: bool = False,\n) -&gt; Union[float, np.ndarray]:\n    r\"\"\"\n    Circular median.\n\n    Two ways to compute the circular median for ungrouped data (Fisher, 1993):\n\n    - `deviation`: find the angle that has the minimal mean deviation.\n    - `count`: find the angle that has the equally devide the number of points on the right and left of it.\n\n    For grouped data, we use the method described in Mardia (1972).\n\n    Parameters\n    ----------\n    alpha: np.array (n, )\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    method: str\n        - For ungrouped data, there are two ways\n        - To compute the medians:\n            - deviation\n            - count\n        - Set to `none` to return np.nan.\n    return_average: bool\n        Return the average of the median\n    average_method: str\n        - all: circular mean of all medians\n        - unique: circular mean of unique medians\n\n    Returns\n    -------\n    median: float or NaN\n\n    References\n    ----------\n    - For ungrouped data: Section 2.3.2 of Fisher (1993)\n    - For grouped data: Mardia (1972)\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    # edge cases for early exit\n    # if all points coincide, return the first point\n    if np.isclose(circ_r(alpha, w), 1.0, atol=1e-12):\n        if verbose:\n            print(\"All points coincide, returning the first point as median.\")\n        return alpha[0]\n\n    # grouped data\n    if not np.all(w == 1):\n        median = _circ_median_grouped(alpha, w)\n    # ungrouped data\n    else:\n        # find which data point that can divide the dataset into two half\n        if method == \"count\":\n            median = _circ_median_count(alpha)\n        # find the angle that has the minimal mean deviation\n        elif method == \"deviation\":\n            median = _circ_median_mean_deviation(alpha)\n        elif method == \"none\" or method is None:\n            median = np.nan\n        else:\n            raise ValueError(\n                f\"Method `{method}` for `circ_median` is not supported.\\nTry `deviation` or `count`\"\n            )\n\n    if return_average:\n        if average_method == \"all\":\n            # Circular mean of all medians\n            median = circ_mean(alpha=np.asarray(median))\n        elif average_method == \"unique\":\n            # Circular mean of unique medians\n            median = circ_mean(alpha=np.unique(median))\n        else:\n            raise ValueError(\n                f\"Average method `{average_method}` is not supported.\\nTry `all` or `unique`.\"\n            )\n\n    return angmod(median)\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_deviation_chuncked","title":"<code>circ_mean_deviation_chuncked(alpha, beta, chunk_size=1000)</code>","text":"<p>Optimized circular mean deviation with chunking.</p> \\[ \\delta = \\pi - \\frac{1}{n} \\sum^{n}_{1}\\left| \\pi - \\left| \\alpha - \\beta \\right| \\right| \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Data in radians.</p> required <code>beta</code> <code>ndarray</code> <p>Reference angles in radians.</p> required <code>chunk_size</code> <code>int</code> <p>Number of rows to process in chunks.</p> <code>1000</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Circular mean deviation.</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean_deviation_chuncked(\n    alpha: Union[np.ndarray, float, int, list],\n    beta: Union[np.ndarray, float, int, list],\n    chunk_size=1000,\n):\n    r\"\"\"\n    Optimized circular mean deviation with chunking.\n\n    $$\n    \\delta = \\pi - \\frac{1}{n} \\sum^{n}_{1}\\left| \\pi - \\left| \\alpha - \\beta \\right| \\right|\n    $$\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Data in radians.\n    beta : np.ndarray\n        Reference angles in radians.\n    chunk_size : int\n        Number of rows to process in chunks.\n\n    Returns\n    -------\n    np.ndarray\n        Circular mean deviation.\n    \"\"\"\n    if not isinstance(alpha, np.ndarray):\n        alpha = np.array([alpha])\n\n    if not isinstance(beta, np.ndarray):\n        beta = np.array([beta])\n\n    n = len(beta)\n    result = np.zeros(n)\n\n    for i in range(0, n, chunk_size):\n        beta_chunk = beta[i : i + chunk_size]\n        angdist = np.pi - np.abs(np.pi - np.abs(alpha - beta_chunk[:, None]))\n        result[i : i + chunk_size] = np.mean(angdist, axis=1).round(5)\n\n    return result\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_deviation","title":"<code>circ_mean_deviation(alpha, beta)</code>","text":"<p>Circular mean deviation.</p> \\[ \\delta = \\pi - \\left| \\pi - \\left| \\alpha - \\beta \\right| \\right| / n \\] <p>It is the mean angular distance from one data point to all others. The circular median of a set of data should be the point with minimal circular mean deviation.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Union[ndarray, float, int, list]</code> <p>Data in radian.</p> required <code>beta</code> <code>Union[ndarray, float, int, list]</code> <p>reference angle in radian.</p> required <p>Returns:</p> Type Description <code>circular mean deviation: np.array</code> Note <p>eq 2.32, Section 2.3.2, Fisher (1993)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean_deviation(\n    alpha: Union[np.ndarray, float, int, list],\n    beta: Union[np.ndarray, float, int, list],\n) -&gt; np.ndarray:\n    r\"\"\"\n    Circular mean deviation.\n\n    $$\n    \\delta = \\pi - \\left| \\pi - \\left| \\alpha - \\beta \\right| \\right| / n\n    $$\n\n    It is the mean angular distance from one data point to all others.\n    The circular median of a set of data should be the point with minimal\n    circular mean deviation.\n\n    Parameters\n    ---------\n    alpha: np.array, int or float\n        Data in radian.\n    beta: np.array, int or float\n        reference angle in radian.\n\n    Returns\n    -------\n    circular mean deviation: np.array\n\n    Note\n    ----\n    eq 2.32, Section 2.3.2, Fisher (1993)\n    \"\"\"\n    if not isinstance(alpha, np.ndarray):\n        alpha = np.array([alpha])\n\n    if not isinstance(beta, np.ndarray):\n        beta = np.array([beta])\n\n    return (np.pi - np.mean(np.abs(np.pi - np.abs(alpha - beta[:, None])), 1)).round(5)\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_ci","title":"<code>circ_mean_ci(alpha=None, w=None, mean=None, r=None, n=None, ci=0.95, method='approximate', B=2000)</code>","text":"<p>Confidence interval of circular mean.</p> <p>There are three methods to compute the confidence interval of circular mean:</p> <ul> <li><code>approximate</code>: for n &gt; 8</li> <li><code>bootstrap</code>: for 8 &lt; n &lt; 25</li> <li><code>dispersion</code>: for n &gt;= 25</li> </ul>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_ci--approximate-method","title":"Approximate Method","text":"<p>For n as small as 8, and r \\(\\le\\) 0.9, r \\(&gt;\\) \\(\\sqrt{\\chi^{2}_{\\alpha, 1}/2n}\\), the confidence interval can be approximated by:</p> \\[ \\delta = \\arccos\\left(\\sqrt{\\frac{2n(2R^{2} - n\\chi^{2}_{\\alpha, 1})}{4n - \\chi^{2}_{\\alpha, 1}}} /R \\right) \\] <p>For r \\(\\ge\\) 0.9,</p> \\[ \\delta = \\arccos \\left(\\sqrt{n^2 - (n^2 - R^2)e^{\\chi^2_{\\alpha, 1}/n} } /R \\right) \\]"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_ci--bootstrap-method","title":"Bootstrap Method","text":"<p>For 8 \\(&lt;\\) n \\(&lt;\\) 25, the confidence interval can be computed by bootstrapping the data.</p>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_mean_ci--dispersion-method","title":"Dispersion Method","text":"<p>For n \\(\\ge\\) 25, the confidence interval can be computed by the circular dispersion:</p> \\[ \\hat\\sigma = \\hat\\delta / n\\] <p>where \\(\\hat\\delta\\) is the sample circular dispersion (see <code>circ_dispersion</code>). The confidence interval is then:</p> \\[(\\hat\\mu - \\sin^-1(z_{\\frac{1}{2}\\alpha}\\hat\\sigma),\\space \\hat\\mu + \\sin^-1(z_{\\frac{1}{2}\\alpha} \\hat\\sigma))\\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Precomputed circular mean.</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Precomputed resultant vector length.</p> <code>None</code> <code>n</code> <code>Union[int, None]</code> <p>Sample size.</p> <code>None</code> <code>ci</code> <code>float</code> <p>Confidence interval (default is 0.95).</p> <code>0.95</code> <code>method</code> <code>str</code> <ul> <li>approximate: for n &gt; 8</li> <li>bootstrap: for n &lt; 25</li> <li>dispersion: for n &gt;= 25</li> </ul> <code>'approximate'</code> <code>B</code> <code>int</code> <p>Number of samples for bootstrap.</p> <code>2000</code> <p>Returns:</p> Name Type Description <code>lower_bound</code> <code>float</code> <p>Lower bound of the confidence interval.</p> <code>upper_bound</code> <code>float</code> <p>Upper bound of the confidence</p> References <ul> <li>Section 26.7, Zar (2010)</li> <li>Section 4.4.4a/b, Fisher (1993)</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_mean_ci(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    mean: Optional[float] = None,\n    r: Optional[float] = None,\n    n: Union[int, None] = None,\n    ci: float = 0.95,\n    method: str = \"approximate\",\n    B: int = 2000,  # number of samples for bootstrap\n) -&gt; tuple[float, float]:\n    r\"\"\"\n    Confidence interval of circular mean.\n\n    There are three methods to compute the confidence interval of circular mean:\n\n    - `approximate`: for n &gt; 8\n    - `bootstrap`: for 8 &lt; n &lt; 25\n    - `dispersion`: for n &gt;= 25\n\n    ### Approximate Method\n\n    For n as small as 8, and r $\\le$ 0.9, r $&gt;$ $\\sqrt{\\chi^{2}_{\\alpha, 1}/2n}$, the confidence interval can be approximated by:\n\n    $$\n    \\delta = \\arccos\\left(\\sqrt{\\frac{2n(2R^{2} - n\\chi^{2}_{\\alpha, 1})}{4n - \\chi^{2}_{\\alpha, 1}}} /R \\right)\n    $$\n\n    For r $\\ge$ 0.9,\n\n    $$\n    \\delta = \\arccos \\left(\\sqrt{n^2 - (n^2 - R^2)e^{\\chi^2_{\\alpha, 1}/n} } /R \\right)\n    $$\n\n    ### Bootstrap Method\n\n    For 8 $&lt;$ n $&lt;$ 25, the confidence interval can be computed by bootstrapping the data.\n\n    ### Dispersion Method\n\n    For n $\\ge$ 25, the confidence interval can be computed by the circular dispersion:\n\n    $$ \\hat\\sigma = \\hat\\delta / n$$\n\n    where $\\hat\\delta$ is the sample circular dispersion (see `circ_dispersion`). The confidence interval is then:\n\n    $$(\\hat\\mu - \\sin^-1(z_{\\frac{1}{2}\\alpha}\\hat\\sigma),\\space \\hat\\mu + \\sin^-1(z_{\\frac{1}{2}\\alpha} \\hat\\sigma))$$\n\n    Parameters\n    ----------\n    alpha: np.array (n, )\n        Angles in radian.\n    w: np.array (n,) or None\n        Frequencies or weights\n    mean: float or None\n        Precomputed circular mean.\n    r: float or None\n        Precomputed resultant vector length.\n    n: int or None\n        Sample size.\n    ci: float\n        Confidence interval (default is 0.95).\n    method: str\n        - approximate: for n &gt; 8\n        - bootstrap: for n &lt; 25\n        - dispersion: for n &gt;= 25\n    B: int\n        Number of samples for bootstrap.\n\n    Returns\n    -------\n    lower_bound: float\n        Lower bound of the confidence interval.\n    upper_bound: float\n        Upper bound of the confidence\n\n    References\n    ----------\n    - Section 26.7, Zar (2010)\n    - Section 4.4.4a/b, Fisher (1993)\n    \"\"\"\n\n\n\n    #  n &gt; 8, according to Ch 26.7 (Zar, 2010)\n    if method == \"approximate\":\n        (lb, ub) = _circ_mean_ci_approximate(\n            alpha=alpha, w=w, mean=mean, r=r, n=n, ci=ci\n        )\n\n    # n &lt; 25, according to 4.4.4a (Fisher, 1993, P75)\n    elif method == \"bootstrap\" and alpha is not None:\n        (lb, ub) = _circ_mean_ci_bootstrap(alpha=alpha, B=B, ci=ci)\n\n    # n &gt;= 25, according to 4.4.4b (Fisher, 1993, P75)\n    elif method == \"dispersion\" and alpha is not None:\n        (lb, ub) = _circ_mean_ci_dispersion(alpha=alpha, w=w, mean=mean, ci=ci)\n\n    else:\n        raise ValueError(\n            f\"Method `{method}` for `circ_mean_ci` is not supported.\\nTry `dispersion`, `approximate` or `bootstrap`\"\n        )\n\n    return float(angmod(lb)), float(angmod(ub))\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_median_ci","title":"<code>circ_median_ci(median=None, alpha=None, w=None, method='deviation', ci=0.95)</code>","text":"<p>Confidence interval for circular median</p> <p>For n &gt; 15, the confidence interval can be computed by:</p> \\[ m = 1 + \\text{integer part of} \\frac{1}{2} n^{1/2} z_{\\frac{1}{2}\\alpha} \\] <p>For n \\(\\le\\) 15, the confidence interval can be selected from the table in Fisher (1993).</p> <p>Parameters:</p> Name Type Description Default <code>median</code> <code>Optional[float]</code> <p>Circular median.</p> <code>None</code> <code>alpha</code> <code>Optional[ndarray]</code> <p>Data in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies or weights</p> <code>None</code> <p>Returns:</p> Type Description <code>lower, upper, ci: tuple</code> <p>confidence intervals and alpha-level</p> Note <p>Implementation of section 4.4.2 (Fisher,1993)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_median_ci(\n    median: Optional[float] = None,\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    method: str = \"deviation\",\n    ci: float = 0.95,\n) -&gt; tuple:\n    r\"\"\"Confidence interval for circular median\n\n    For n &gt; 15, the confidence interval can be computed by:\n\n    $$\n    m = 1 + \\text{integer part of} \\frac{1}{2} n^{1/2} z_{\\frac{1}{2}\\alpha}\n    $$\n\n    For n $\\le$ 15, the confidence interval can be selected from the table in Fisher (1993).\n\n    Parameters\n    ----------\n    median: float or None\n        Circular median.\n    alpha: np.array or None\n        Data in radian.\n    w: np.array or None\n        Frequencies or weights\n\n    Returns\n    -------\n    lower, upper, ci: tuple\n        confidence intervals and alpha-level\n\n    Note\n    ----\n    Implementation of section 4.4.2 (Fisher,1993)\n    \"\"\"\n\n    if median is None:\n        if alpha is None:\n            raise ValueError(\"If `median` is None, then `alpha` is needed.\")\n        if w is None:\n            w = np.ones_like(alpha)\n        median = float(circ_median(alpha=alpha, w=w, method=method, return_average=True))\n\n    if alpha is None:\n        raise ValueError(\n            \"`alpha` is needed for computing the confidence interval for circular median.\"\n        )\n\n    n = len(alpha)\n    alpha = np.sort(alpha)\n\n    if n &gt; 15:\n        z = norm.ppf(1 - 0.5 * (1 - ci))\n\n        offset = int(1 + np.floor(0.5 * np.sqrt(n) * z))  # fisher:eq(4.19)\n\n        # idx_median = np.where(alpha.round(5) &lt; np.round(median, 5))[0][-1]\n        arr = np.where(alpha.round(5) &lt; np.round(median, 5))[0]\n        if len(arr) == 0:\n            # That means median is smaller than alpha[0] (to 5 decimals).\n            # In a circular sense, the \u201cclosest index below\u201d is alpha[-1].\n            idx_median = len(alpha) - 1\n        else:\n            idx_median = arr[-1]\n\n        idx_lb = idx_median - offset + 1\n        idx_ub = idx_median + offset\n        if np.round(median, 5) in alpha.round(5):  # don't count the median per se\n            idx_ub += 1\n\n        if idx_ub &gt; n:\n            idx_ub = idx_ub - n\n\n        if idx_lb &lt; 0:\n            idx_lb = n + idx_lb\n\n        lower, upper = alpha[int(idx_lb)], alpha[int(idx_ub)]\n\n        if not is_within_circular_range(median, lower, upper):\n            lower, upper = upper, lower\n\n    # selected confidence intervals for the median direction for n &lt; 15\n    # from A6, Fisher, 1993.\n    # We only return the widest CI if there are more than one in the table.\n\n    elif n == 3:\n        lower, upper = alpha[0], alpha[2]\n        ci = 0.75\n    elif n == 4:\n        lower, upper = alpha[0], alpha[3]\n        ci = 0.875\n    elif n == 5:\n        lower, upper = alpha[0], alpha[4]\n        ci = 0.937\n    elif n == 6:\n        lower, upper = alpha[0], alpha[5]\n        ci = 0.97\n    elif n == 7:\n        lower, upper = alpha[0], alpha[6]\n        ci = 0.984\n    elif n == 8:\n        lower, upper = alpha[0], alpha[7]\n        ci = 0.992\n    elif n == 9:\n        lower, upper = alpha[0], alpha[8]\n        ci = 0.996\n    elif n == 10:\n        lower, upper = alpha[1], alpha[8]\n        ci = 0.978\n    elif n == 11:\n        lower, upper = alpha[1], alpha[9]\n        ci = 0.99\n    elif n == 12:\n        lower, upper = alpha[2], alpha[9]\n        ci = 0.962\n    elif n == 13:\n        lower, upper = alpha[2], alpha[10]\n        ci = 0.978\n    elif n == 14:\n        lower, upper = alpha[3], alpha[10]\n        ci = 0.937\n    elif n == 15:\n        lower, upper = alpha[2], alpha[12]\n        ci = 0.965\n    else:\n        lower, upper = np.nan, np.nan\n\n    return (angmod(lower), angmod(upper), ci)\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_kappa","title":"<code>circ_kappa(r, n=None)</code>","text":"<p>Estimate kappa by approximation.</p> \\[ \\hat\\kappa_{ML} = \\begin{cases}  2r + r^3 + 5r^5/6, , &amp; \\text{if } r &lt; 0.53  \\\\  -0.4 + 1.39 r + 0.43 / (1 - r) , &amp; \\text{if } 0.53 \\le r &lt; 0.85\\\\     1 / (r^3 - 4r^2 + 3r), &amp; \\text{if } r \\ge 0.85 \\end{cases} \\] <p>For \\(n \\le 15\\):</p> \\[ \\hat\\kappa = \\begin{cases}     \\max\\left(\\hat\\kappa - \\frac{2}{n\\hat\\kappa}, 0\\right), &amp; \\text{if } \\hat\\kappa &lt; 2 \\\\     \\frac{(n - 1)^3 \\hat\\kappa}{n^3 + n}, &amp; \\text{if } \\hat\\kappa \\ge 2 \\end{cases} \\] <p>Parameters:</p> Name Type Description Default <code>r</code> <code>float</code> <p>Resultant vector length</p> required <code>n</code> <code>Union[int, None]</code> <p>Sample size. If n is not None, the adjustment for small sample size will be applied.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>kappa</code> <code>float</code> <p>Concentration parameter</p> Reference <p>Section 4.5.5 (P88, Fisher, 1993)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_kappa(r: float, n: Union[int, None] = None) -&gt; float:\n    r\"\"\"Estimate kappa by approximation.\n\n    $$\n    \\hat\\kappa_{ML} =\n    \\begin{cases}\n     2r + r^3 + 5r^5/6, , &amp; \\text{if } r &lt; 0.53  \\\\\n     -0.4 + 1.39 r + 0.43 / (1 - r) , &amp; \\text{if } 0.53 \\le r &lt; 0.85\\\\\n        1 / (r^3 - 4r^2 + 3r), &amp; \\text{if } r \\ge 0.85\n    \\end{cases}\n    $$\n\n    For $n \\le 15$:\n\n    $$\n    \\hat\\kappa =\n    \\begin{cases}\n        \\max\\left(\\hat\\kappa - \\frac{2}{n\\hat\\kappa}, 0\\right), &amp; \\text{if } \\hat\\kappa &lt; 2 \\\\\n        \\frac{(n - 1)^3 \\hat\\kappa}{n^3 + n}, &amp; \\text{if } \\hat\\kappa \\ge 2\n    \\end{cases}\n    $$\n\n\n    Parameters\n    ----------\n    r: float\n        Resultant vector length\n    n: int or None\n        Sample size. If n is not None, the adjustment for small sample size will be applied.\n\n    Returns\n    -------\n    kappa: float\n        Concentration parameter\n\n    Reference\n    ---------\n    Section 4.5.5 (P88, Fisher, 1993)\n    \"\"\"\n\n    # eq 4.40\n    if r &lt; 0.53:\n        kappa = 2 * r + r**3 + 5 * r**5 / 6\n    elif r &lt; 0.85:\n        kappa = -0.4 + 1.39 * r + 0.43 / (1 - r)\n    else:\n        nom = r**3 - 4 * r**2 + 3 * r\n        if nom != 0:\n            kappa = 1 / nom\n        else:\n            # not sure how to handle this...\n            kappa = 1e-16\n\n    # eq 4.41\n    if n is not None:\n        if n &lt;= 15 and r &lt; 0.7:\n            if kappa &lt; 2:\n                kappa = np.max([kappa - 2 * 1 / (n * kappa), 0])\n            else:\n                kappa = (n - 1) ** 3 * kappa / (n**3 + n)\n\n    return kappa\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_dist","title":"<code>circ_dist(x, y=None, metric='center', return_sum=False)</code>","text":"<p>Compute the element-wise circular distance between two arrays of angles.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>First sample of circular data (radians).</p> required <code>y</code> <code>array - like</code> <p>Second sample of circular data (radians). If None, computes element-wise distances within <code>x</code> itself.</p> <code>None</code> <code>metric</code> <code>str</code> <p>Distance metric to use, options: - \"center\" (default): Standard circular difference wrapped to [-\u03c0, \u03c0]. - \"geodesic\": \u03c0 - |\u03c0 - |x - y||. - \"angularseparation\": 1 - cos(x - y). - \"chord\": sqrt(2 * (1 - cos(x - y))).</p> <code>'center'</code> <code>return_sum</code> <code>bool</code> <p>If True, returns the sum of all computed distances (like R's <code>dist.circular()</code>).</p> <code>False</code> <p>Returns:</p> Type Description <code>array</code> <p>Element-wise distance values based on the chosen metric.</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_dist(\n    x: Union[np.ndarray, float],\n    y: Optional[Union[np.ndarray, float]] = None,\n    metric: str = \"center\",\n    return_sum: bool = False,\n) -&gt; Union[np.ndarray, float]:\n    r\"\"\"\n    Compute the element-wise circular distance between two arrays of angles.\n\n    Parameters\n    ----------\n    x : array-like\n        First sample of circular data (radians).\n    y : array-like, optional\n        Second sample of circular data (radians). If None, computes element-wise\n        distances within `x` itself.\n    metric : str, optional\n        Distance metric to use, options:\n        - \"center\" (default): Standard circular difference wrapped to [-\u03c0, \u03c0].\n        - \"geodesic\": \u03c0 - |\u03c0 - |x - y||.\n        - \"angularseparation\": 1 - cos(x - y).\n        - \"chord\": sqrt(2 * (1 - cos(x - y))).\n    return_sum : bool, optional\n        If True, returns the sum of all computed distances (like R's `dist.circular()`).\n\n    Returns\n    -------\n    array\n        Element-wise distance values based on the chosen metric.\n    \"\"\"\n    x = np.asarray(x)\n\n    if y is None:\n        y = x\n\n    y = np.asarray(y)\n\n    # Ensure broadcasting works without explicit shape checks\n    try:\n        np.broadcast_shapes(x.shape, y.shape)\n    except ValueError:\n        raise ValueError(\n            f\"Shapes {x.shape} and {y.shape} are incompatible for broadcasting.\"\n        )\n\n    if metric == \"center\":\n        distances = np.angle(np.exp(1j * x) / np.exp(1j * y))\n\n    elif metric == \"geodesic\":\n        distances = np.pi - np.abs(np.pi - np.abs(x - y))\n\n    elif metric == \"angularseparation\":\n        distances = 1 - np.cos(x - y)\n\n    elif metric == \"chord\":\n        distances = np.sqrt(2 * (1 - np.cos(x - y)))\n\n    else:\n        raise ValueError(f\"Unknown metric: {metric}\")\n\n    return np.sum(distances).astype(float) if return_sum else distances\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_pairdist","title":"<code>circ_pairdist(x, y=None, metric='center', return_sum=False)</code>","text":"<p>Compute the pairwise circular distance between all elements in <code>x</code> and <code>y</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>First sample of circular data (radians).</p> required <code>y</code> <code>array - like</code> <p>Second sample of circular data (radians). If None, computes pairwise distances within <code>x</code> itself.</p> <code>None</code> <code>metric</code> <code>str</code> <p>Distance metric to use (same options as <code>circ_dist</code>).</p> <code>'center'</code> <code>return_sum</code> <code>bool</code> <p>If True, returns the sum of all computed distances (like R's <code>dist.circular()</code>).</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Pairwise distance matrix where entry (i, j) is the circular distance between x[i] and y[j] based on the chosen metric.</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_pairdist(\n    x: np.ndarray,\n    y: Optional[np.ndarray] = None,\n    metric: str = \"center\",\n    return_sum: bool = False,\n) -&gt; Union[np.ndarray, float]:\n    r\"\"\"\n    Compute the pairwise circular distance between all elements in `x` and `y`.\n\n    Parameters\n    ----------\n    x : array-like\n        First sample of circular data (radians).\n    y : array-like, optional\n        Second sample of circular data (radians). If None, computes pairwise\n        distances within `x` itself.\n    metric : str, optional\n        Distance metric to use (same options as `circ_dist`).\n    return_sum : bool, optional\n        If True, returns the sum of all computed distances (like R's `dist.circular()`).\n\n    Returns\n    -------\n    ndarray\n        Pairwise distance matrix where entry (i, j) is the circular distance\n        between x[i] and y[j] based on the chosen metric.\n    \"\"\"\n    x = np.asarray(x)\n\n    # If y is not provided, compute pairwise distances within x\n    if y is None:\n        y = x\n\n    y = np.asarray(y)\n\n    # Reshape to allow broadcasting for pairwise computation\n    x_reshaped = x[:, None]  # Shape (n, 1)\n    y_reshaped = y[None, :]  # Shape (1, m)\n\n    return circ_dist(x_reshaped, y_reshaped, metric=metric, return_sum=return_sum)\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.convert_moment","title":"<code>convert_moment(mp)</code>","text":"<p>Convert complex moment to polar coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>mp</code> <code>complex</code> <p>Complex moment</p> required <p>Returns:</p> Name Type Description <code>u</code> <code>float</code> <p>Angle in radian</p> <code>r</code> <code>float</code> <p>Magnitude</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def convert_moment(\n    mp: complex,\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Convert complex moment to polar coordinates.\n\n    Parameters\n    ----------\n    mp: complex\n        Complex moment\n\n    Returns\n    -------\n    u: float\n        Angle in radian\n    r: float\n        Magnitude\n\n    \"\"\"\n\n    u = float(angmod(float(np.angle(mp))))\n    r = np.abs(mp)\n\n    return u, r\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.compute_C_and_S","title":"<code>compute_C_and_S(alpha, w, p=1, mean=0.0)</code>","text":"<p>Compute the intermediate values Cbar and Sbar.</p> \\[ \\displaylines{ \\bar{C}_{p} = \\frac{\\sum_{i=1}^{n} w_{i} \\cos(p(\\alpha_{i} - \\mu))}{n} \\\\ \\bar{S}_{p} = \\frac{\\sum_{i=1}^{n} w_{i} \\sin(p(\\alpha_{i} - \\mu))}{n} } \\] <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>ndarray</code> <p>Frequencies or weights.</p> required <code>p</code> <code>int</code> <p>Order of the moment (default is 1, for the first moment).</p> <code>1</code> <code>mean</code> <code>Union[float, ndarray]</code> <p>Mean angle (\u03bc) to center the computation (default is 0.0).</p> <code>0.0</code> <p>Returns:</p> Name Type Description <code>Cbar</code> <code>float</code> <p>Weighted mean cosine for the given moment.</p> <code>Sbar</code> <code>float</code> <p>Weighted mean sine for the given moment.</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def compute_C_and_S(\n    alpha: np.ndarray,\n    w: np.ndarray,\n    p: int = 1,\n    mean: Union[float, np.ndarray] = 0.0,\n) -&gt; Tuple[float, float]:\n    r\"\"\"\n    Compute the intermediate values Cbar and Sbar.\n\n    $$\n    \\displaylines{\n    \\bar{C}_{p} = \\frac{\\sum_{i=1}^{n} w_{i} \\cos(p(\\alpha_{i} - \\mu))}{n} \\\\\n    \\bar{S}_{p} = \\frac{\\sum_{i=1}^{n} w_{i} \\sin(p(\\alpha_{i} - \\mu))}{n}\n    }\n    $$\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        Angles in radian.\n    w: np.ndarray\n        Frequencies or weights.\n    p: int, optional\n        Order of the moment (default is 1, for the first moment).\n    mean: float, optional\n        Mean angle (\u03bc) to center the computation (default is 0.0).\n\n    Returns\n    -------\n    Cbar: float\n        Weighted mean cosine for the given moment.\n    Sbar: float\n        Weighted mean sine for the given moment.\n    \"\"\"\n    n = np.sum(w)\n    Cbar = np.sum(w * np.cos(p * (alpha - mean))) / n\n    Sbar = np.sum(w * np.sin(p * (alpha - mean))) / n\n\n    return Cbar, Sbar\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.compute_hdi","title":"<code>compute_hdi(samples, ci=0.95)</code>","text":"<p>Compute the Highest Density Interval (HDI) for circular data.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>ndarray</code> <p>Bootstrap samples of the circular mean in radians.</p> required <code>ci</code> <code>float</code> <p>Credible interval (default is 0.95 for 95% HDI).</p> <code>0.95</code> <p>Returns:</p> Name Type Description <code>hdi</code> <code>tuple</code> <p>Lower and upper bounds of the HDI in radians.</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def compute_hdi(samples: np.ndarray, ci:float=0.95)-&gt;tuple[float, float]:\n    \"\"\"\n    Compute the Highest Density Interval (HDI) for circular data.\n\n    Parameters\n    ----------\n    samples : np.ndarray\n        Bootstrap samples of the circular mean in radians.\n    ci : float, optional\n        Credible interval (default is 0.95 for 95% HDI).\n\n    Returns\n    -------\n    hdi : tuple\n        Lower and upper bounds of the HDI in radians.\n    \"\"\"\n    # Wrap samples to [0, 2\u03c0) for circular consistency\n    wrapped_samples = angmod(samples)\n\n    # Sort the samples\n    sorted_samples = np.sort(wrapped_samples)\n\n    # Number of samples in the HDI\n    n_samples = len(sorted_samples)\n    interval_idx = int(np.floor(ci * n_samples))\n    if interval_idx == 0:\n        raise ValueError(\"Insufficient data to compute HDI.\")\n\n    # Find the shortest interval\n    hdi_width = np.inf\n    for i in range(n_samples - interval_idx):\n        lower = float(sorted_samples[i])\n        upper = float(sorted_samples[i + interval_idx])\n        width = angmod(upper - lower)  # Handle wrapping for circularity\n        if width &lt; hdi_width:\n            hdi_width = width\n            hdi_bounds = (lower, upper)\n\n    return hdi_bounds\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.compute_smooth_params","title":"<code>compute_smooth_params(r, n)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>r</code> <code>float</code> <p>resultant vector length</p> required <code>n</code> <code>int</code> <p>sample size</p> required <p>Returns:</p> Name Type Description <code>h</code> <code>float</code> <p>smoothing parameter</p> Reference <p>Section 2.2 (P26, Fisher, 1993)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def compute_smooth_params(r: float, n: int) -&gt; float:\n    \"\"\"\n    Parameters\n    ----------\n    r: float\n        resultant vector length\n    n: int\n        sample size\n\n    Returns\n    -------\n    h: float\n        smoothing parameter\n\n    Reference\n    ---------\n    Section 2.2 (P26, Fisher, 1993)\n    \"\"\"\n\n    kappa = circ_kappa(r, n)\n    zeta = 1 / np.sqrt(kappa)  # eq 2.3\n    h = np.sqrt(7) * zeta / np.power(n, 0.2)  # eq 2.4\n\n    return h\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.nonparametric_density_estimation","title":"<code>nonparametric_density_estimation(alpha, h, radius=1)</code>","text":"<p>Nonparametric density estimates with a quartic kernel function.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian</p> required <code>h</code> <code>float</code> <p>Smoothing parameters</p> required <code>radius</code> <code>float</code> <p>radius of the plotted circle</p> <code>1</code> <p>Returns:</p> Name Type Description <code>x</code> <code>ndarray(100)</code> <p>grid</p> <code>f</code> <code>ndarray(100)</code> <p>density</p> Reference <p>Section 2.2 (P26, Fisher, 1993)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def nonparametric_density_estimation(\n    alpha: np.ndarray,  # angles in radian\n    h: float,  # smoothing parameters\n    radius: float = 1,  # radius of the plotted circle\n) -&gt; tuple:\n    \"\"\"Nonparametric density estimates with\n    a quartic kernel function.\n\n    Parameters\n    ----------\n    alpha: np.ndarray (n, )\n        Angles in radian\n    h: float\n        Smoothing parameters\n    radius: float\n        radius of the plotted circle\n\n    Returns\n    -------\n    x: np.ndarray (100, )\n        grid\n    f: np.ndarray (100, )\n        density\n\n    Reference\n    ---------\n    Section 2.2 (P26, Fisher, 1993)\n    \"\"\"\n\n    # vectorized version of step 3\n    a = alpha\n    n = len(a)\n    x = np.linspace(0, 2 * np.pi, 100)\n    d = np.abs(x[:, None] - a)\n    e = np.minimum(d, 2 * np.pi - d)\n    e = np.minimum(e, h)\n    sum = np.sum((1 - e**2 / h**2) ** 2, 1)\n    f = 0.9375 * sum / n / h\n\n    f = radius * np.sqrt(1 + np.pi * f) - radius\n\n    return x, f\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_range","title":"<code>circ_range(alpha)</code>","text":"<p>Compute the circular range of angular data.</p> <p>The circular range is the difference between the maximum and minimum angles in the dataset, adjusted for circular continuity.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radians.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Circular range, a measure of clustering (higher = more clustered).</p> Reference <p>P162, Section 7.2.3 of Jammalamadaka, S. Rao and SenGupta, A. (2001)</p> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_range(alpha: np.ndarray) -&gt; np.float64:\n    \"\"\"\n    Compute the circular range of angular data.\n\n    The circular range is the difference between the maximum and minimum angles\n    in the dataset, adjusted for circular continuity.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Angles in radians.\n\n    Returns\n    -------\n    float\n        Circular range, a measure of clustering (higher = more clustered).\n\n    Reference\n    ---------\n    P162, Section 7.2.3 of Jammalamadaka, S. Rao and SenGupta, A. (2001)\n    \"\"\"\n    alpha = np.sort(alpha % (2 * np.pi))  # Convert to [0, 2\u03c0) and sort\n    spacings = np.diff(alpha, prepend=alpha[-1] - 2 * np.pi)  # Compute spacings\n    return 2 * np.pi - np.max(spacings)  # Circular range\n</code></pre>"},{"location":"reference/descriptive/#pycircstat2.descriptive.circ_quantile","title":"<code>circ_quantile(alpha, probs=np.array([0, 0.25, 0.5, 0.75, 1.0]), type=7)</code>","text":"<p>Compute quantiles for circular data.</p> <p>This function computes quantiles for circular data by shifting the data to be centered around the circular median, applying a linear quantile function, and then shifting back.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of circular data (radians).</p> required <code>probs</code> <code>float or ndarray</code> <p>Probabilities at which to compute quantiles. Default is <code>[0, 0.25, 0.5, 0.75, 1.0]</code>.</p> <code>array([0, 0.25, 0.5, 0.75, 1.0])</code> <code>type</code> <code>int</code> <p>Quantile algorithm type (default <code>7</code>, matches R\u2019s default quantile type).</p> <code>7</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Circular quantiles.</p> References <ul> <li>R's <code>quantile.circular</code> from the <code>circular</code> package.</li> <li>Fisher (1993), Section 2.3.2.</li> </ul> Source code in <code>pycircstat2/descriptive.py</code> <pre><code>def circ_quantile(\n    alpha: np.ndarray,\n    probs: Union[float, np.ndarray] = np.array([0, 0.25, 0.5, 0.75, 1.0]),\n    type: int = 7,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute quantiles for circular data.\n\n    This function computes quantiles for circular data by shifting the\n    data to be centered around the circular median, applying a linear quantile function,\n    and then shifting back.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of circular data (radians).\n    probs : float or np.ndarray, optional\n        Probabilities at which to compute quantiles. Default is `[0, 0.25, 0.5, 0.75, 1.0]`.\n    type : int, optional\n        Quantile algorithm type (default `7`, matches R\u2019s default quantile type).\n\n    Returns\n    -------\n    np.ndarray\n        Circular quantiles.\n\n    References\n    ----------\n    - R's `quantile.circular` from the `circular` package.\n    - Fisher (1993), Section 2.3.2.\n    \"\"\"\n\n    # Convert to numpy array\n    alpha = np.asarray(alpha)\n    probs = np.atleast_1d(probs)\n\n    # Compute circular median\n    circular_median = circ_median(alpha)\n\n    # If the median is NaN (e.g., uniform data), return NaNs\n    if np.isnan(circular_median):\n        return np.full_like(probs, np.nan)\n\n    # Transform data relative to circular median\n    shifted_alpha = (alpha - circular_median) % (2 * np.pi)\n    shifted_alpha = np.where(\n        shifted_alpha &gt; np.pi, shifted_alpha - 2 * np.pi, shifted_alpha\n    )\n\n    # Compute linear quantiles on transformed data\n    linear_quantiles = np.quantile(\n        shifted_alpha, probs, method=\"linear\" if type == 7 else \"midpoint\"\n    )\n\n    # Transform back to original circular space\n    circular_quantiles = (linear_quantiles + circular_median) % (2 * np.pi)\n\n    return circular_quantiles\n</code></pre>"},{"location":"reference/distributions/","title":"Distributions","text":""},{"location":"reference/distributions/#pycircstat2.distributions.circularuniform_gen","title":"<code>circularuniform_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Continuous Circular Uniform Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class circularuniform_gen(rv_continuous):\n    \"\"\"Continuous Circular Uniform Distribution\n\n    ![circularuniform](../images/circ-mod-circularuniform.png)\n\n    Methods\n    -------\n    pdf(x)\n        Probability density function.\n\n    cdf(x)\n        Cumulative distribution function.\n    \"\"\"\n\n    def _pdf(self, x):\n        return 1 / np.pi\n\n    def pdf(self, x, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Circular Uniform distribution.\n\n        $$\n        f(\\theta) = \\frac{1}{\\pi}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, *args, **kwargs)\n\n    def _cdf(self, x):\n        return x / (2 * np.pi)\n\n    def cdf(self, x, *args, **kwargs):\n        r\"\"\"\n        Cumulative distribution function of the Circular Uniform distribution.\n\n        $$\n        F(\\theta) = \\frac{\\theta}{2\\pi}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the cumulative distribution function.\n\n        Returns\n        -------\n        cdf_values : array_like\n            Cumulative distribution function evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, *args, **kwargs)\n\n    def _ppf(self, q):\n        return 2 * np.pi * q\n\n    def ppf(self, q, *args, **kwargs):\n        r\"\"\"\n        Percent-point function (inverse of the CDF) of the Circular Uniform distribution.\n\n        $$\n        Q(q) = F^{-1}(q) = 2\\pi q, \\space 0 \\leq q \\leq 1\n        $$\n\n        Parameters\n        ----------\n        q : array_like\n            Quantiles to evaluate.\n\n        Returns\n        -------\n        ppf_values : array_like\n            Values at the given quantiles.\n        \"\"\"\n        return super().ppf(q, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.circularuniform_gen.pdf","title":"<code>pdf(x, *args, **kwargs)</code>","text":"<p>Probability density function of the Circular Uniform distribution.</p> \\[ f(\\theta) = \\frac{1}{\\pi} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Circular Uniform distribution.\n\n    $$\n    f(\\theta) = \\frac{1}{\\pi}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.circularuniform_gen.cdf","title":"<code>cdf(x, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Circular Uniform distribution.</p> \\[ F(\\theta) = \\frac{\\theta}{2\\pi} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the cumulative distribution function.</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>Cumulative distribution function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, *args, **kwargs):\n    r\"\"\"\n    Cumulative distribution function of the Circular Uniform distribution.\n\n    $$\n    F(\\theta) = \\frac{\\theta}{2\\pi}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the cumulative distribution function.\n\n    Returns\n    -------\n    cdf_values : array_like\n        Cumulative distribution function evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.circularuniform_gen.ppf","title":"<code>ppf(q, *args, **kwargs)</code>","text":"<p>Percent-point function (inverse of the CDF) of the Circular Uniform distribution.</p> \\[ Q(q) = F^{-1}(q) = 2\\pi q, \\space 0 \\leq q \\leq 1 \\] <p>Parameters:</p> Name Type Description Default <code>q</code> <code>array_like</code> <p>Quantiles to evaluate.</p> required <p>Returns:</p> Name Type Description <code>ppf_values</code> <code>array_like</code> <p>Values at the given quantiles.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def ppf(self, q, *args, **kwargs):\n    r\"\"\"\n    Percent-point function (inverse of the CDF) of the Circular Uniform distribution.\n\n    $$\n    Q(q) = F^{-1}(q) = 2\\pi q, \\space 0 \\leq q \\leq 1\n    $$\n\n    Parameters\n    ----------\n    q : array_like\n        Quantiles to evaluate.\n\n    Returns\n    -------\n    ppf_values : array_like\n        Values at the given quantiles.\n    \"\"\"\n    return super().ppf(q, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.triangular_gen","title":"<code>triangular_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Triangular Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Notes <p>Implementation based on Section 2.2.3 of Jammalamadaka &amp; SenGupta (2001)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class triangular_gen(rv_continuous):\n    \"\"\"Triangular Distribution\n\n    ![triangular](../images/circ-mod-triangular.png)\n\n    Methods\n    -------\n    pdf(x, rho)\n        Probability density function.\n\n    cdf(x, rho)\n        Cumulative distribution function.\n\n    Notes\n    -----\n    Implementation based on Section 2.2.3 of Jammalamadaka &amp; SenGupta (2001)\n    \"\"\"\n\n    def _argcheck(self, rho):\n        return 0 &lt;= rho &lt;= 4 / np.pi**2\n\n    def _pdf(self, x, rho):\n        return (\n            (4 - np.pi**2.0 * rho + 2.0 * np.pi * rho * np.abs(np.pi - x)) / 8.0 / np.pi\n        )\n\n    def pdf(self, x, rho, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Triangular distribution.\n\n        $$\n        f(\\theta) = \\frac{4 - \\pi^2 \\rho + 2\\pi \\rho |\\pi - \\theta|}{8\\pi}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        rho : float\n            Concentratio parameter, 0 &lt;= rho &lt;= 4/pi^2.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n\n        return super().pdf(x, rho, *args, **kwargs)\n\n    def _cdf(self, x, rho):\n        @np.vectorize\n        def _cdf_single(x, rho):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(rho))\n            return integral\n\n        return _cdf_single(x, rho)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.triangular_gen.pdf","title":"<code>pdf(x, rho, *args, **kwargs)</code>","text":"<p>Probability density function of the Triangular distribution.</p> \\[ f(\\theta) = \\frac{4 - \\pi^2 \\rho + 2\\pi \\rho |\\pi - \\theta|}{8\\pi} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>rho</code> <code>float</code> <p>Concentratio parameter, 0 &lt;= rho &lt;= 4/pi^2.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, rho, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Triangular distribution.\n\n    $$\n    f(\\theta) = \\frac{4 - \\pi^2 \\rho + 2\\pi \\rho |\\pi - \\theta|}{8\\pi}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    rho : float\n        Concentratio parameter, 0 &lt;= rho &lt;= 4/pi^2.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n\n    return super().pdf(x, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cardioid_gen","title":"<code>cardioid_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Cardioid (cosine) Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Notes <p>Implementation based on Section 4.3.4 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class cardioid_gen(rv_continuous):\n    \"\"\"Cardioid (cosine) Distribution\n\n    ![cardioid](../images/circ-mod-cardioid.png)\n\n    Methods\n    -------\n    pdf(x, mu, rho)\n        Probability density function.\n\n    cdf(x, mu, rho)\n        Cumulative distribution function.\n\n    Notes\n    -----\n    Implementation based on Section 4.3.4 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _argcheck(self, mu, rho):\n        return 0 &lt;= mu &lt;= np.pi * 2 and 0 &lt;= rho &lt;= 0.5\n\n    def _pdf(self, x, mu, rho):\n        return (1 + 2 * rho * np.cos(x - mu)) / 2.0 / np.pi\n\n    def pdf(self, x, mu, rho, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Cardioid distribution.\n\n        $$\n        f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\rho \\cos(\\theta - \\mu)\\right), \\space \\rho \\in [0, 1/2]\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Mean resultant length, 0 &lt;= rho &lt;= 0.5.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, mu, rho, *args, **kwargs)\n\n    def _cdf(self, x, mu, rho):\n        return (x + 2 * rho * (np.sin(x - mu) + np.sin(mu))) / (2 * np.pi)\n\n    def cdf(self, x, mu, rho, *args, **kwargs):\n        r\"\"\"\n        Cumulative distribution function of the Cardioid distribution.\n\n        $$\n        F(\\theta) = \\frac{\\theta + 2\\rho (\\sin(\\mu) + \\sin(\\theta - \\mu))}{2\\pi}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the cumulative distribution function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Mean resultant length, 0 &lt;= rho &lt;= 0.5.\n\n        Returns\n        -------\n        cdf_values : array_like\n            Cumulative distribution function evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cardioid_gen.pdf","title":"<code>pdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Probability density function of the Cardioid distribution.</p> \\[ f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\rho \\cos(\\theta - \\mu)\\right), \\space \\rho \\in [0, 1/2] \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Mean resultant length, 0 &lt;= rho &lt;= 0.5.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, rho, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Cardioid distribution.\n\n    $$\n    f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\rho \\cos(\\theta - \\mu)\\right), \\space \\rho \\in [0, 1/2]\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Mean resultant length, 0 &lt;= rho &lt;= 0.5.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cardioid_gen.cdf","title":"<code>cdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Cardioid distribution.</p> \\[ F(\\theta) = \\frac{\\theta + 2\\rho (\\sin(\\mu) + \\sin(\\theta - \\mu))}{2\\pi} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the cumulative distribution function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Mean resultant length, 0 &lt;= rho &lt;= 0.5.</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>Cumulative distribution function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, mu, rho, *args, **kwargs):\n    r\"\"\"\n    Cumulative distribution function of the Cardioid distribution.\n\n    $$\n    F(\\theta) = \\frac{\\theta + 2\\rho (\\sin(\\mu) + \\sin(\\theta - \\mu))}{2\\pi}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the cumulative distribution function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Mean resultant length, 0 &lt;= rho &lt;= 0.5.\n\n    Returns\n    -------\n    cdf_values : array_like\n        Cumulative distribution function evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cartwright_gen","title":"<code>cartwright_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Cartwright's Power-of-Cosine Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation based on Section 4.3.5 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class cartwright_gen(rv_continuous):\n    \"\"\"Cartwright's Power-of-Cosine Distribution\n\n    ![cartwright](../images/circ-mod-cartwright.png)\n\n\n    Methods\n    -------\n    pdf(x, mu, zeta)\n        Probability density function.\n\n    cdf(x, mu, zeta)\n        Cumulative distribution function.\n\n    Note\n    ----\n    Implementation based on Section 4.3.5 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _argcheck(self, mu, zeta):\n        return 0 &lt;= mu &lt;= 2 * np.pi and zeta &gt; 0\n\n    def _pdf(self, x, mu, zeta):\n        return (\n            (2 ** (-1 + 1 / zeta) * (gamma(1 + 1 / zeta)) ** 2)\n            * (1 + np.cos(x - mu)) ** (1 / zeta)\n            / (np.pi * gamma(1 + 2 / zeta))\n        )\n\n    def pdf(self, x, mu, zeta, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Cartwright distribution.\n\n        $$\n        f(\\theta) = \\frac{2^{- 1+1/\\zeta} \\Gamma^2(1 + 1/\\zeta)}{\\pi \\Gamma(1 + 2/\\zeta)} (1 + \\cos(\\theta - \\mu))^{1/\\zeta}\n        $$\n\n        , where $\\Gamma$ is the gamma function.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        zeta : float\n            Shape parameter, zeta &gt; 0.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n\n        return super().pdf(x, mu, zeta, *args, **kwargs)\n\n    def _cdf(self, x, mu, zeta):\n        @np.vectorize\n        def _cdf_single(x, mu, zeta):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(mu, zeta))\n            return integral\n\n        return _cdf_single(x, mu, zeta)\n\n    def cdf(self, x, mu, zeta, *args, **kwargs):\n        r\"\"\"\n        Cumulative distribution function of the Cartwright distribution.\n\n        No closed-form solution is available, so the CDF is computed numerically.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the cumulative distribution function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        zeta : float\n            Shape parameter, zeta &gt; 0.\n\n        Returns\n        -------\n        cdf_values : array_like\n            Cumulative distribution function evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, mu, zeta, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cartwright_gen.pdf","title":"<code>pdf(x, mu, zeta, *args, **kwargs)</code>","text":"<p>Probability density function of the Cartwright distribution.</p> \\[ f(\\theta) = \\frac{2^{- 1+1/\\zeta} \\Gamma^2(1 + 1/\\zeta)}{\\pi \\Gamma(1 + 2/\\zeta)} (1 + \\cos(\\theta - \\mu))^{1/\\zeta} \\] <p>, where \\(\\Gamma\\) is the gamma function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>zeta</code> <code>float</code> <p>Shape parameter, zeta &gt; 0.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, zeta, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Cartwright distribution.\n\n    $$\n    f(\\theta) = \\frac{2^{- 1+1/\\zeta} \\Gamma^2(1 + 1/\\zeta)}{\\pi \\Gamma(1 + 2/\\zeta)} (1 + \\cos(\\theta - \\mu))^{1/\\zeta}\n    $$\n\n    , where $\\Gamma$ is the gamma function.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    zeta : float\n        Shape parameter, zeta &gt; 0.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n\n    return super().pdf(x, mu, zeta, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.cartwright_gen.cdf","title":"<code>cdf(x, mu, zeta, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Cartwright distribution.</p> <p>No closed-form solution is available, so the CDF is computed numerically.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the cumulative distribution function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>zeta</code> <code>float</code> <p>Shape parameter, zeta &gt; 0.</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>Cumulative distribution function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, mu, zeta, *args, **kwargs):\n    r\"\"\"\n    Cumulative distribution function of the Cartwright distribution.\n\n    No closed-form solution is available, so the CDF is computed numerically.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the cumulative distribution function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    zeta : float\n        Shape parameter, zeta &gt; 0.\n\n    Returns\n    -------\n    cdf_values : array_like\n        Cumulative distribution function evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, mu, zeta, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapnorm_gen","title":"<code>wrapnorm_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Wrapped Normal Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> <p>Examples:</p> <pre><code>from pycircstat2.distributions import wrapnorm\n</code></pre> Notes <p>Implementation based on Section 4.3.7 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class wrapnorm_gen(rv_continuous):\n    \"\"\"Wrapped Normal Distribution\n\n    ![wrapnorm](../images/circ-mod-wrapnorm.png)\n\n    Methods\n    -------\n    pdf(x, mu, rho)\n        Probability density function.\n\n    cdf(x, mu, rho)\n        Cumulative distribution function.\n\n    Examples\n    --------\n    ```\n    from pycircstat2.distributions import wrapnorm\n    ```\n\n    Notes\n    -----\n    Implementation based on Section 4.3.7 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _argcheck(self, mu, rho):\n        return 0 &lt;= mu &lt;= np.pi * 2 and 0 &lt; rho &lt; 1\n\n    def _pdf(self, x, mu, rho):\n        return (\n            1\n            + 2\n            * np.sum([rho ** (p**2) * np.cos(p * (x - mu)) for p in range(1, 30)], 0)\n        ) / (2 * np.pi)\n\n    def pdf(self, x, mu, rho, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Wrapped Normal distribution.\n\n        $$\n        f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\sum_{p=1}^{\\infty} \\rho^{p^2} \\cos(p(\\theta - \\mu))\\right)\n        $$\n\n        , here we approximate the infinite sum by summing the first 30 terms.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Shape parameter, 0 &lt; rho &lt;= 1.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, mu, rho, *args, **kwargs)\n\n    def _cdf(self, x, mu, rho):\n        @np.vectorize\n        def _cdf_single(x, mu, rho):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(mu, rho))\n            return integral\n\n        return _cdf_single(x, mu, rho)\n\n    def cdf(self, x, mu, rho, *args, **kwargs):\n        \"\"\"\n        Cumulative distribution function of the Wrapped Normal distribution.\n\n        No closed-form solution is available, so the CDF is computed numerically.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the cumulative distribution function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Shape parameter, 0 &lt; rho &lt;= 1.\n\n        Returns\n        -------\n        cdf_values : array_like\n            Cumulative distribution function evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapnorm_gen.pdf","title":"<code>pdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Probability density function of the Wrapped Normal distribution.</p> \\[ f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\sum_{p=1}^{\\infty} \\rho^{p^2} \\cos(p(\\theta - \\mu))\\right) \\] <p>, here we approximate the infinite sum by summing the first 30 terms.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Shape parameter, 0 &lt; rho &lt;= 1.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, rho, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Wrapped Normal distribution.\n\n    $$\n    f(\\theta) = \\frac{1}{2\\pi} \\left(1 + 2\\sum_{p=1}^{\\infty} \\rho^{p^2} \\cos(p(\\theta - \\mu))\\right)\n    $$\n\n    , here we approximate the infinite sum by summing the first 30 terms.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Shape parameter, 0 &lt; rho &lt;= 1.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapnorm_gen.cdf","title":"<code>cdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Wrapped Normal distribution.</p> <p>No closed-form solution is available, so the CDF is computed numerically.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the cumulative distribution function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Shape parameter, 0 &lt; rho &lt;= 1.</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>Cumulative distribution function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, mu, rho, *args, **kwargs):\n    \"\"\"\n    Cumulative distribution function of the Wrapped Normal distribution.\n\n    No closed-form solution is available, so the CDF is computed numerically.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the cumulative distribution function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Shape parameter, 0 &lt; rho &lt;= 1.\n\n    Returns\n    -------\n    cdf_values : array_like\n        Cumulative distribution function evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapcauchy_gen","title":"<code>wrapcauchy_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Wrapped Cauchy Distribution.</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> <code>rvs</code> <p>Random variates.</p> <code>fit</code> <p>Fit the distribution to the data and return the parameters (mu, rho).</p> Notes <p>Implementation based on Section 4.3.6 of Pewsey et al. (2014).</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class wrapcauchy_gen(rv_continuous):\n    \"\"\"Wrapped Cauchy Distribution.\n\n    ![wrapcauchy](../images/circ-mod-wrapcauchy.png)\n\n    Methods\n    -------\n    pdf(x, mu, rho)\n        Probability density function.\n\n    cdf(x, mu, rho)\n        Cumulative distribution function.\n\n    rvs(mu, rho, size=None, random_state=None)\n        Random variates.\n\n    fit(data, method=\"analytical\", *args, **kwargs)\n        Fit the distribution to the data and return the parameters (mu, rho).\n\n    Notes\n    -----\n    Implementation based on Section 4.3.6 of Pewsey et al. (2014).\n    \"\"\"\n\n    def _argcheck(self, mu, rho):\n        return 0 &lt;= mu &lt;= np.pi * 2 and 0 &lt; rho &lt;= 1\n\n    def _pdf(self, x, mu, rho):\n        return (1 - rho**2) / (2 * np.pi * (1 + rho**2 - 2 * rho * np.cos(x - mu)))\n\n    def pdf(self, x, mu, rho, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Wrapped Cauchy distribution.\n\n        $$\n        f(\\theta) = \\frac{1 - \\rho^2}{2\\pi(1 + \\rho^2 - 2\\rho \\cos(\\theta - \\mu))}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Shape parameter, 0 &lt; rho &lt;= 1.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, mu, rho, *args, **kwargs)\n\n    def _logpdf(self, x, mu, rho):\n        return np.log(np.clip(self._pdf(x, mu, rho), 1e-16, None))\n\n    def logpdf(self, x, mu, rho, *args, **kwargs):\n        \"\"\"\n        Logarithm of the probability density function.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the log-PDF.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Mean resultant length, 0 &lt; rho &lt;= 1.\n\n        Returns\n        -------\n        logpdf_values : array_like\n            Logarithm of the probability density function evaluated at `x`.\n        \"\"\"\n        return super().logpdf(x, mu, rho, *args, **kwargs)\n\n    def _cdf(self, x, mu, rho):\n        @np.vectorize\n        def _cdf_single(x, mu, rho):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(mu, rho))\n            return integral\n\n        return _cdf_single(x, mu, rho)\n\n    def cdf(self, x, mu, rho, *args, **kwargs):\n        \"\"\"\n        Cumulative distribution function of the Wrapped Cauchy distribution.\n\n        No closed-form solution is available, so the CDF is computed numerically.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the CDF.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Shape parameter, 0 &lt; rho &lt;= 1.\n\n        Returns\n        -------\n        cdf_values : array_like\n            CDF evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, mu, rho, *args, **kwargs)\n\n    def _rvs(self, mu, rho, size=None, random_state=None):\n        \"\"\"\n        Random variate generation for the Wrapped Cauchy distribution.\n\n        Parameters\n        ----------\n\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        rho : float\n            Mean resultant length, 0 &lt;= rho &lt;= 1.\n        size : int or tuple, optional\n            Number of samples to generate.\n        random_state : RandomState, optional\n            Random number generator instance.\n\n        Returns\n        -------\n        samples : ndarray\n            Random variates from the Wrapped Cauchy distribution.\n        \"\"\"\n        rng = self._random_state if random_state is None else random_state\n\n        if rho == 0:\n            return rng.uniform(0, 2 * np.pi, size=size)\n        elif rho == 1:\n            return np.full(size, mu % (2 * np.pi))\n        else:\n            from scipy.stats import cauchy\n\n            scale = -np.log(rho)\n            samples = cauchy.rvs(loc=mu, scale=scale, size=size, random_state=rng)\n            return np.mod(samples, 2 * np.pi)\n\n    def fit(self, data, method=\"analytical\", *args, **kwargs):\n        \"\"\"\n        Fit the Wrapped Cauchy distribution to the data.\n\n        Parameters\n        ----------\n        data : array_like\n            Input data (angles in radians).\n        method : str, optional\n            The approach for fitting the distribution. Options are:\n            - \"analytical\": Compute `rho` and `mu` using closed-form solutions.\n            - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer.\n            Default is \"analytical\".\n\n        *args, **kwargs :\n            Additional arguments passed to the optimizer (if used).\n\n        Returns\n        -------\n        rho : float\n            Estimated shape parameter.\n        mu : float\n            Estimated mean direction.\n        \"\"\"\n\n        # Validate the fitting method\n        valid_methods = [\"analytical\", \"numerical\"]\n        if method not in valid_methods:\n            raise ValueError(\n                f\"Invalid method '{method}'. Available methods are {valid_methods}.\"\n            )\n\n        # Validate the data\n        if not np.all((0 &lt;= data) &amp; (data &lt; 2 * np.pi)):\n            raise ValueError(\"Data must be in the range [0, 2\u03c0).\")\n\n        # Analytical solution for the Von Mises distribution\n        mu, rho = circ_mean_and_r(alpha=data)\n\n        # Use analytical estimates for mu and rho\n        if method == \"analytical\":\n            return mu, rho\n        elif method == \"numerical\":\n            # Numerical optimization\n            def nll(params):\n                mu, rho = params\n                if not self._argcheck(mu, rho):\n                    return np.inf\n                return -np.sum(self._logpdf(data, mu, rho))\n\n            start_params = [mu, np.clip(rho, 1e-4, 1 - 1e-4)]\n            bounds = [(0, 2 * np.pi), (1e-6, 1)]\n            algo = kwargs.pop(\"algorithm\", \"L-BFGS-B\")\n            result = minimize(\n                nll, start_params, bounds=bounds, method=algo, *args, **kwargs\n            )\n            if not result.success:\n                raise RuntimeError(f\"Optimization failed: {result.message}\")\n            mu, rho = result.x\n            return mu, rho\n        else:\n            raise ValueError(\n                \"Invalid method. Supported methods are 'analytical' and \" \"'numerical'.\"\n            )\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapcauchy_gen.pdf","title":"<code>pdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Probability density function of the Wrapped Cauchy distribution.</p> \\[ f(\\theta) = \\frac{1 - \\rho^2}{2\\pi(1 + \\rho^2 - 2\\rho \\cos(\\theta - \\mu))} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Shape parameter, 0 &lt; rho &lt;= 1.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, rho, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Wrapped Cauchy distribution.\n\n    $$\n    f(\\theta) = \\frac{1 - \\rho^2}{2\\pi(1 + \\rho^2 - 2\\rho \\cos(\\theta - \\mu))}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Shape parameter, 0 &lt; rho &lt;= 1.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapcauchy_gen.logpdf","title":"<code>logpdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Logarithm of the probability density function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the log-PDF.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Mean resultant length, 0 &lt; rho &lt;= 1.</p> required <p>Returns:</p> Name Type Description <code>logpdf_values</code> <code>array_like</code> <p>Logarithm of the probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def logpdf(self, x, mu, rho, *args, **kwargs):\n    \"\"\"\n    Logarithm of the probability density function.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the log-PDF.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Mean resultant length, 0 &lt; rho &lt;= 1.\n\n    Returns\n    -------\n    logpdf_values : array_like\n        Logarithm of the probability density function evaluated at `x`.\n    \"\"\"\n    return super().logpdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapcauchy_gen.cdf","title":"<code>cdf(x, mu, rho, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Wrapped Cauchy distribution.</p> <p>No closed-form solution is available, so the CDF is computed numerically.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the CDF.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>rho</code> <code>float</code> <p>Shape parameter, 0 &lt; rho &lt;= 1.</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>CDF evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, mu, rho, *args, **kwargs):\n    \"\"\"\n    Cumulative distribution function of the Wrapped Cauchy distribution.\n\n    No closed-form solution is available, so the CDF is computed numerically.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the CDF.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    rho : float\n        Shape parameter, 0 &lt; rho &lt;= 1.\n\n    Returns\n    -------\n    cdf_values : array_like\n        CDF evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, mu, rho, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapcauchy_gen.fit","title":"<code>fit(data, method='analytical', *args, **kwargs)</code>","text":"<p>Fit the Wrapped Cauchy distribution to the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Input data (angles in radians).</p> required <code>method</code> <code>str</code> <p>The approach for fitting the distribution. Options are: - \"analytical\": Compute <code>rho</code> and <code>mu</code> using closed-form solutions. - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer. Default is \"analytical\".</p> <code>'analytical'</code> <code>*args</code> <p>Additional arguments passed to the optimizer (if used).</p> <code>()</code> <code>**kwargs</code> <p>Additional arguments passed to the optimizer (if used).</p> <code>()</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Estimated shape parameter.</p> <code>mu</code> <code>float</code> <p>Estimated mean direction.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def fit(self, data, method=\"analytical\", *args, **kwargs):\n    \"\"\"\n    Fit the Wrapped Cauchy distribution to the data.\n\n    Parameters\n    ----------\n    data : array_like\n        Input data (angles in radians).\n    method : str, optional\n        The approach for fitting the distribution. Options are:\n        - \"analytical\": Compute `rho` and `mu` using closed-form solutions.\n        - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer.\n        Default is \"analytical\".\n\n    *args, **kwargs :\n        Additional arguments passed to the optimizer (if used).\n\n    Returns\n    -------\n    rho : float\n        Estimated shape parameter.\n    mu : float\n        Estimated mean direction.\n    \"\"\"\n\n    # Validate the fitting method\n    valid_methods = [\"analytical\", \"numerical\"]\n    if method not in valid_methods:\n        raise ValueError(\n            f\"Invalid method '{method}'. Available methods are {valid_methods}.\"\n        )\n\n    # Validate the data\n    if not np.all((0 &lt;= data) &amp; (data &lt; 2 * np.pi)):\n        raise ValueError(\"Data must be in the range [0, 2\u03c0).\")\n\n    # Analytical solution for the Von Mises distribution\n    mu, rho = circ_mean_and_r(alpha=data)\n\n    # Use analytical estimates for mu and rho\n    if method == \"analytical\":\n        return mu, rho\n    elif method == \"numerical\":\n        # Numerical optimization\n        def nll(params):\n            mu, rho = params\n            if not self._argcheck(mu, rho):\n                return np.inf\n            return -np.sum(self._logpdf(data, mu, rho))\n\n        start_params = [mu, np.clip(rho, 1e-4, 1 - 1e-4)]\n        bounds = [(0, 2 * np.pi), (1e-6, 1)]\n        algo = kwargs.pop(\"algorithm\", \"L-BFGS-B\")\n        result = minimize(\n            nll, start_params, bounds=bounds, method=algo, *args, **kwargs\n        )\n        if not result.success:\n            raise RuntimeError(f\"Optimization failed: {result.message}\")\n        mu, rho = result.x\n        return mu, rho\n    else:\n        raise ValueError(\n            \"Invalid method. Supported methods are 'analytical' and \" \"'numerical'.\"\n        )\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen","title":"<code>vonmises_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Von Mises Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> <code>ppf</code> <p>Percent-point function (inverse of CDF).</p> <code>rvs</code> <p>Random variates.</p> <code>fit</code> <p>Fit the distribution to the data and return the parameters (mu, kappa).</p> <p>Examples:</p> <pre><code>from pycircstat2.distributions import vonmises\n</code></pre> References <ul> <li>Section 4.3.8 of Pewsey et al. (2014)</li> </ul> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class vonmises_gen(rv_continuous):\n    \"\"\"Von Mises Distribution\n\n    ![vonmises](../images/circ-mod-vonmises.png)\n\n    Methods\n    -------\n    pdf(x, mu, kappa)\n        Probability density function.\n\n    cdf(x, mu, kappa)\n        Cumulative distribution function.\n\n    ppf(q, mu, kappa)\n        Percent-point function (inverse of CDF).\n\n    rvs(mu, kappa, size=None, random_state=None)\n        Random variates.\n\n    fit(data, *args, **kwargs)\n        Fit the distribution to the data and return the parameters (mu, kappa).\n\n    Examples\n    --------\n    ```\n    from pycircstat2.distributions import vonmises\n    ```\n\n    References\n    ----------\n    - Section 4.3.8 of Pewsey et al. (2014)\n\n    \"\"\"\n\n    _freeze_doc = \"\"\"\n    Freeze the distribution with specific parameters.\n\n    Parameters\n    ----------\n    mu : float\n        The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n    kappa : float\n        The concentration parameter of the distribution (kappa &gt; 0).\n\n    Returns\n    -------\n    rv_frozen : rv_frozen instance\n        The frozen distribution instance with fixed parameters.\n    \"\"\"\n\n    def __call__(self, *args, **kwds):\n        return self.freeze(*args, **kwds)\n\n    __call__.__doc__ = _freeze_doc\n\n    def _argcheck(self, mu, kappa):\n        return 0 &lt;= mu &lt;= np.pi * 2 and kappa &gt; 0\n\n    def _pdf(self, x, mu, kappa):\n        return np.exp(kappa * np.cos(x - mu)) / (2 * np.pi * i0(kappa))\n\n    def pdf(self, x, mu, kappa, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Von Mises distribution.\n\n        $$\n        f(\\theta) = \\frac{e^{\\kappa \\cos(\\theta - \\mu)}}{2\\pi I_0(\\kappa)}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n        kappa : float\n            The concentration parameter of the distribution (kappa &gt; 0).\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, mu, kappa, *args, **kwargs)\n\n    def _logpdf(self, x, mu, kappa):\n        return kappa * np.cos(x - mu) - np.log(2 * np.pi * i0(kappa))\n\n    def logpdf(self, x, mu, kappa, *args, **kwargs):\n        \"\"\"\n        Logarithm of the probability density function of the Von Mises\n        distribution.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the logarithm of the probability density function.\n        mu : float\n            The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n        kappa : float\n            The concentration parameter of the distribution (kappa &gt; 0).\n\n        Returns\n        -------\n        logpdf_values : array_like\n            Logarithm of the probability density function evaluated at `x`.\n        \"\"\"\n        return super().logpdf(x, mu, kappa, *args, **kwargs)\n\n    def _cdf(self, x, mu, kappa):\n        @np.vectorize\n        def _cdf_single(x, mu, kappa):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(mu, kappa))\n            return integral\n\n        return _cdf_single(x, mu, kappa)\n\n    def cdf(self, x, mu, kappa, *args, **kwargs):\n        r\"\"\"\n        Cumulative distribution function of the Von Mises distribution.\n\n        $$\n        F(\\theta) = \\frac{1}{2 \\pi I_0(\\kappa)}\\int_{0}^{\\theta} e^{\\kappa \\cos(\\theta - \\mu)} dx\n        $$\n\n        No closed-form solution is available, so the CDF is computed numerically.\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the cumulative distribution function.\n        mu : float\n            The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n        kappa : float\n            The concentration parameter of the distribution (kappa &gt; 0).\n\n        Returns\n        -------\n        cdf_values : array_like\n            Cumulative distribution function evaluated at `x`.\n        \"\"\"\n        return super().cdf(x, mu, kappa, *args, **kwargs)\n\n    def ppf(self, q, mu, kappa, *args, **kwargs):\n        \"\"\"\n        Percent-point function (inverse of the CDF) of the Von Mises distribution.\n\n        Parameters\n        ----------\n        q : array_like\n            Quantiles to evaluate.\n        mu : float\n            The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n        kappa : float\n            The concentration parameter of the distribution (kappa &gt; 0).\n\n        Returns\n        -------\n        ppf_values : array_like\n            Values at the given quantiles.\n        \"\"\"\n        return super().ppf(q, mu, kappa, *args, **kwargs)\n\n    def _rvs(self, mu, kappa, size=None, random_state=None):\n        # Use the random_state attribute or a new default random generator\n        rng = self._random_state if random_state is None else random_state\n\n        # Handle size being a tuple\n        if size is None:\n            size = 1\n        num_samples = np.prod(size)  # Total number of samples\n\n        # Best-Fisher algorithm\n        a = 1 + np.sqrt(1 + 4 * kappa**2)\n        b = (a - np.sqrt(2 * a)) / (2 * kappa)\n        r = (1 + b**2) / (2 * b)\n\n        def sample():\n            while True:\n                u1 = rng.uniform()\n                z = np.cos(np.pi * u1)\n                f = (1 + r * z) / (r + z)\n                c = kappa * (r - f)\n                u2 = rng.uniform()\n                if u2 &lt; c * (2 - c) or u2 &lt;= c * np.exp(1 - c):\n                    break\n            u3 = rng.uniform()\n            theta = mu + np.sign(u3 - 0.5) * np.arccos(f)\n            return theta % (2 * np.pi)\n\n        samples = np.array([sample() for _ in range(num_samples)])\n        return samples\n\n    def rvs(self, size=None, random_state=None, *args, **kwargs):\n        \"\"\"\n        Draw random variates.\n\n        Parameters\n        ----------\n        size : int or tuple, optional\n            Number of samples to generate.\n        random_state : RandomState, optional\n            Random number generator instance.\n\n        Returns\n        -------\n        samples : ndarray\n            Random variates.\n        \"\"\"\n        # Check if instance-level parameters are set\n        mu = getattr(self, \"mu\", None)\n        kappa = getattr(self, \"kappa\", None)\n\n        # Override instance parameters if provided in args/kwargs\n        mu = kwargs.pop(\"mu\", mu)\n        kappa = kwargs.pop(\"kappa\", kappa)\n\n        # Ensure required parameters are provided\n        if mu is None or kappa is None:\n            raise ValueError(\"Both 'mu' and 'kappa' must be provided.\")\n\n        # Call the private _rvs method\n        return self._rvs(mu, kappa, size=size, random_state=random_state)\n\n    def support(self, *args, **kwargs):\n        return (0, 2 * np.pi)\n\n    def mean(self, *args, **kwargs):\n        \"\"\"\n        Circular mean of the Von Mises distribution.\n\n        Returns\n        -------\n        mean : float\n            The circular mean direction (in radians), equal to `mu`.\n        \"\"\"\n        (mu, _) = self._parse_args(*args, **kwargs)[0]\n        return mu\n\n    def median(self, *args, **kwargs):\n        \"\"\"\n        Circular median of the Von Mises distribution.\n\n        Returns\n        -------\n        median : float\n            The circular median direction (in radians), equal to `mu`.\n        \"\"\"\n        return self.mean(*args, **kwargs)\n\n    def var(self, *args, **kwargs):\n        \"\"\"\n        Circular variance of the Von Mises distribution.\n\n        Returns\n        -------\n        variance : float\n            The circular variance, derived from `kappa`.\n        \"\"\"\n        (_, kappa) = self._parse_args(*args, **kwargs)[0]\n        return 1 - i1(kappa) / i0(kappa)\n\n    def std(self, *args, **kwargs):\n        \"\"\"\n        Circular standard deviation of the Von Mises distribution.\n\n        Returns\n        -------\n        std : float\n            The circular standard deviation, derived from `kappa`.\n        \"\"\"\n        (_, kappa) = self._parse_args(*args, **kwargs)[0]\n        r = i1(kappa) / i0(kappa)\n\n        return np.sqrt(-2 * np.log(r))\n\n    def entropy(self, *args, **kwargs):\n        \"\"\"\n        Entropy of the Von Mises distribution.\n\n        Returns\n        -------\n        entropy : float\n            The entropy of the distribution.\n        \"\"\"\n        (_, kappa) = self._parse_args(*args, **kwargs)[0]\n        return -np.log(i0(kappa)) + (kappa * i1(kappa)) / i0(kappa)\n\n    def _nnlf(self, theta, data):\n        \"\"\"\n        Custom negative log-likelihood function for the Von Mises distribution.\n        \"\"\"\n        mu, kappa = theta\n\n        if not self._argcheck(mu, kappa):  # Validate parameter range\n            return np.inf\n\n        # Compute log-likelihood robustly\n        log_likelihood = self._logpdf(data, mu, kappa)\n\n        # Negative log-likelihood\n        return -np.sum(log_likelihood)\n\n    def fit(self, data, method=\"analytical\", *args, **kwargs):\n        \"\"\"\n        Fit the Von Mises distribution to the given data.\n\n        Parameters\n        ----------\n        data : array_like\n            The data to fit the distribution to. Assumes values are in radians.\n        method : str, optional\n            The approach for fitting the distribution. Options are:\n            - \"analytical\": Compute `mu` and `kappa` using closed-form solutions.\n            - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer.\n            Default is \"analytical\".\n\n            When `method=\"numerical\"`, the optimization algorithm can be specified via `algorithm` in `kwargs`.\n            Supported algorithms include any method from `scipy.optimize.minimize`, such as \"L-BFGS-B\" (default) or \"Nelder-Mead\".\n\n        *args : tuple, optional\n            Additional positional arguments passed to the optimizer (if used).\n        **kwargs : dict, optional\n            Additional keyword arguments passed to the optimizer (if used).\n\n        Returns\n        -------\n        kappa : float\n            The estimated concentration parameter of the Von Mises distribution.\n        mu : float\n            The estimated mean direction of the Von Mises distribution.\n\n        Notes\n        -----\n        - The \"analytical\" method directly computes the parameters using the circular mean\n        and resultant vector length (`r`) for `mu` and `kappa`, respectively.\n        - For numerical methods, the negative log-likelihood (NLL) is minimized using `_nnlf` as the objective function.\n\n\n        Examples\n        --------\n        ```python\n        # MLE fitting using analytical solution\n        mu, kappa = vonmises.fit(data, method=\"analytical\")\n\n        # MLE fitting with numerical method using L-BFGS-B\n        mu, kappa = vonmises.fit(data, method=\"L-BFGS-B\")\n        ```\n        \"\"\"\n\n        # Validate the fitting method\n        valid_methods = [\"analytical\", \"numerical\"]\n        if method not in valid_methods:\n            raise ValueError(\n                f\"Invalid method '{method}'. Available methods are {valid_methods}.\"\n            )\n\n        # Validate the data\n        if not np.all((0 &lt;= data) &amp; (data &lt; 2 * np.pi)):\n            raise ValueError(\"Data must be in the range [0, 2\u03c0).\")\n\n        # Analytical solution for the Von Mises distribution\n        mu, r = circ_mean_and_r(alpha=data)\n        kappa = circ_kappa(r=r, n=len(data))\n\n        if method == \"analytical\":\n            if np.isclose(r, 0):\n                raise ValueError(\n                    \"Resultant vector length (r) is zero, e.g. uniform data or low directional bias.\"\n                )\n            return mu, kappa\n        elif method == \"numerical\":\n            # Use analytical solution as initial guess\n            start_params = [mu, kappa]\n            bounds = [(0, 2 * np.pi), (0, None)]  # 0 &lt;= mu &lt; 2*pi, kappa &gt; 0,\n\n            algo = kwargs.pop(\"algorithm\", \"L-BFGS-B\")\n\n            # Define the objective function (NLL) using `_nnlf`\n            def nll(params):\n                return self._nnlf(params, data)\n\n            # Use the optimizer to minimize NLL\n            result = minimize(\n                nll, start_params, bounds=bounds, method=algo, *args, **kwargs\n            )\n\n            # Extract parameters from optimization result\n            if not result.success:\n                raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n            mu, kappa = result.x\n            return mu, kappa\n        else:\n            raise ValueError(\n                f\"Invalid method '{method}'. Supported methods are 'analytical' and 'numerical'.\"\n            )\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.pdf","title":"<code>pdf(x, mu, kappa, *args, **kwargs)</code>","text":"<p>Probability density function of the Von Mises distribution.</p> \\[ f(\\theta) = \\frac{e^{\\kappa \\cos(\\theta - \\mu)}}{2\\pi I_0(\\kappa)} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).</p> required <code>kappa</code> <code>float</code> <p>The concentration parameter of the distribution (kappa &gt; 0).</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, kappa, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Von Mises distribution.\n\n    $$\n    f(\\theta) = \\frac{e^{\\kappa \\cos(\\theta - \\mu)}}{2\\pi I_0(\\kappa)}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n    kappa : float\n        The concentration parameter of the distribution (kappa &gt; 0).\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, mu, kappa, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.logpdf","title":"<code>logpdf(x, mu, kappa, *args, **kwargs)</code>","text":"<p>Logarithm of the probability density function of the Von Mises distribution.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the logarithm of the probability density function.</p> required <code>mu</code> <code>float</code> <p>The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).</p> required <code>kappa</code> <code>float</code> <p>The concentration parameter of the distribution (kappa &gt; 0).</p> required <p>Returns:</p> Name Type Description <code>logpdf_values</code> <code>array_like</code> <p>Logarithm of the probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def logpdf(self, x, mu, kappa, *args, **kwargs):\n    \"\"\"\n    Logarithm of the probability density function of the Von Mises\n    distribution.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the logarithm of the probability density function.\n    mu : float\n        The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n    kappa : float\n        The concentration parameter of the distribution (kappa &gt; 0).\n\n    Returns\n    -------\n    logpdf_values : array_like\n        Logarithm of the probability density function evaluated at `x`.\n    \"\"\"\n    return super().logpdf(x, mu, kappa, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.cdf","title":"<code>cdf(x, mu, kappa, *args, **kwargs)</code>","text":"<p>Cumulative distribution function of the Von Mises distribution.</p> \\[ F(\\theta) = \\frac{1}{2 \\pi I_0(\\kappa)}\\int_{0}^{\\theta} e^{\\kappa \\cos(\\theta - \\mu)} dx \\] <p>No closed-form solution is available, so the CDF is computed numerically.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the cumulative distribution function.</p> required <code>mu</code> <code>float</code> <p>The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).</p> required <code>kappa</code> <code>float</code> <p>The concentration parameter of the distribution (kappa &gt; 0).</p> required <p>Returns:</p> Name Type Description <code>cdf_values</code> <code>array_like</code> <p>Cumulative distribution function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def cdf(self, x, mu, kappa, *args, **kwargs):\n    r\"\"\"\n    Cumulative distribution function of the Von Mises distribution.\n\n    $$\n    F(\\theta) = \\frac{1}{2 \\pi I_0(\\kappa)}\\int_{0}^{\\theta} e^{\\kappa \\cos(\\theta - \\mu)} dx\n    $$\n\n    No closed-form solution is available, so the CDF is computed numerically.\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the cumulative distribution function.\n    mu : float\n        The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n    kappa : float\n        The concentration parameter of the distribution (kappa &gt; 0).\n\n    Returns\n    -------\n    cdf_values : array_like\n        Cumulative distribution function evaluated at `x`.\n    \"\"\"\n    return super().cdf(x, mu, kappa, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.ppf","title":"<code>ppf(q, mu, kappa, *args, **kwargs)</code>","text":"<p>Percent-point function (inverse of the CDF) of the Von Mises distribution.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>array_like</code> <p>Quantiles to evaluate.</p> required <code>mu</code> <code>float</code> <p>The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).</p> required <code>kappa</code> <code>float</code> <p>The concentration parameter of the distribution (kappa &gt; 0).</p> required <p>Returns:</p> Name Type Description <code>ppf_values</code> <code>array_like</code> <p>Values at the given quantiles.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def ppf(self, q, mu, kappa, *args, **kwargs):\n    \"\"\"\n    Percent-point function (inverse of the CDF) of the Von Mises distribution.\n\n    Parameters\n    ----------\n    q : array_like\n        Quantiles to evaluate.\n    mu : float\n        The mean direction of the distribution (0 &lt;= mu &lt;= 2*pi).\n    kappa : float\n        The concentration parameter of the distribution (kappa &gt; 0).\n\n    Returns\n    -------\n    ppf_values : array_like\n        Values at the given quantiles.\n    \"\"\"\n    return super().ppf(q, mu, kappa, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.rvs","title":"<code>rvs(size=None, random_state=None, *args, **kwargs)</code>","text":"<p>Draw random variates.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int or tuple</code> <p>Number of samples to generate.</p> <code>None</code> <code>random_state</code> <code>RandomState</code> <p>Random number generator instance.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>samples</code> <code>ndarray</code> <p>Random variates.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def rvs(self, size=None, random_state=None, *args, **kwargs):\n    \"\"\"\n    Draw random variates.\n\n    Parameters\n    ----------\n    size : int or tuple, optional\n        Number of samples to generate.\n    random_state : RandomState, optional\n        Random number generator instance.\n\n    Returns\n    -------\n    samples : ndarray\n        Random variates.\n    \"\"\"\n    # Check if instance-level parameters are set\n    mu = getattr(self, \"mu\", None)\n    kappa = getattr(self, \"kappa\", None)\n\n    # Override instance parameters if provided in args/kwargs\n    mu = kwargs.pop(\"mu\", mu)\n    kappa = kwargs.pop(\"kappa\", kappa)\n\n    # Ensure required parameters are provided\n    if mu is None or kappa is None:\n        raise ValueError(\"Both 'mu' and 'kappa' must be provided.\")\n\n    # Call the private _rvs method\n    return self._rvs(mu, kappa, size=size, random_state=random_state)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.mean","title":"<code>mean(*args, **kwargs)</code>","text":"<p>Circular mean of the Von Mises distribution.</p> <p>Returns:</p> Name Type Description <code>mean</code> <code>float</code> <p>The circular mean direction (in radians), equal to <code>mu</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def mean(self, *args, **kwargs):\n    \"\"\"\n    Circular mean of the Von Mises distribution.\n\n    Returns\n    -------\n    mean : float\n        The circular mean direction (in radians), equal to `mu`.\n    \"\"\"\n    (mu, _) = self._parse_args(*args, **kwargs)[0]\n    return mu\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.median","title":"<code>median(*args, **kwargs)</code>","text":"<p>Circular median of the Von Mises distribution.</p> <p>Returns:</p> Name Type Description <code>median</code> <code>float</code> <p>The circular median direction (in radians), equal to <code>mu</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def median(self, *args, **kwargs):\n    \"\"\"\n    Circular median of the Von Mises distribution.\n\n    Returns\n    -------\n    median : float\n        The circular median direction (in radians), equal to `mu`.\n    \"\"\"\n    return self.mean(*args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.var","title":"<code>var(*args, **kwargs)</code>","text":"<p>Circular variance of the Von Mises distribution.</p> <p>Returns:</p> Name Type Description <code>variance</code> <code>float</code> <p>The circular variance, derived from <code>kappa</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def var(self, *args, **kwargs):\n    \"\"\"\n    Circular variance of the Von Mises distribution.\n\n    Returns\n    -------\n    variance : float\n        The circular variance, derived from `kappa`.\n    \"\"\"\n    (_, kappa) = self._parse_args(*args, **kwargs)[0]\n    return 1 - i1(kappa) / i0(kappa)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.std","title":"<code>std(*args, **kwargs)</code>","text":"<p>Circular standard deviation of the Von Mises distribution.</p> <p>Returns:</p> Name Type Description <code>std</code> <code>float</code> <p>The circular standard deviation, derived from <code>kappa</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def std(self, *args, **kwargs):\n    \"\"\"\n    Circular standard deviation of the Von Mises distribution.\n\n    Returns\n    -------\n    std : float\n        The circular standard deviation, derived from `kappa`.\n    \"\"\"\n    (_, kappa) = self._parse_args(*args, **kwargs)[0]\n    r = i1(kappa) / i0(kappa)\n\n    return np.sqrt(-2 * np.log(r))\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.entropy","title":"<code>entropy(*args, **kwargs)</code>","text":"<p>Entropy of the Von Mises distribution.</p> <p>Returns:</p> Name Type Description <code>entropy</code> <code>float</code> <p>The entropy of the distribution.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def entropy(self, *args, **kwargs):\n    \"\"\"\n    Entropy of the Von Mises distribution.\n\n    Returns\n    -------\n    entropy : float\n        The entropy of the distribution.\n    \"\"\"\n    (_, kappa) = self._parse_args(*args, **kwargs)[0]\n    return -np.log(i0(kappa)) + (kappa * i1(kappa)) / i0(kappa)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_gen.fit","title":"<code>fit(data, method='analytical', *args, **kwargs)</code>","text":"<p>Fit the Von Mises distribution to the given data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>The data to fit the distribution to. Assumes values are in radians.</p> required <code>method</code> <code>str</code> <p>The approach for fitting the distribution. Options are: - \"analytical\": Compute <code>mu</code> and <code>kappa</code> using closed-form solutions. - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer. Default is \"analytical\".</p> <p>When <code>method=\"numerical\"</code>, the optimization algorithm can be specified via <code>algorithm</code> in <code>kwargs</code>. Supported algorithms include any method from <code>scipy.optimize.minimize</code>, such as \"L-BFGS-B\" (default) or \"Nelder-Mead\".</p> <code>'analytical'</code> <code>*args</code> <code>tuple</code> <p>Additional positional arguments passed to the optimizer (if used).</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments passed to the optimizer (if used).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>kappa</code> <code>float</code> <p>The estimated concentration parameter of the Von Mises distribution.</p> <code>mu</code> <code>float</code> <p>The estimated mean direction of the Von Mises distribution.</p> Notes <ul> <li>The \"analytical\" method directly computes the parameters using the circular mean and resultant vector length (<code>r</code>) for <code>mu</code> and <code>kappa</code>, respectively.</li> <li>For numerical methods, the negative log-likelihood (NLL) is minimized using <code>_nnlf</code> as the objective function.</li> </ul> <p>Examples:</p> <pre><code># MLE fitting using analytical solution\nmu, kappa = vonmises.fit(data, method=\"analytical\")\n\n# MLE fitting with numerical method using L-BFGS-B\nmu, kappa = vonmises.fit(data, method=\"L-BFGS-B\")\n</code></pre> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def fit(self, data, method=\"analytical\", *args, **kwargs):\n    \"\"\"\n    Fit the Von Mises distribution to the given data.\n\n    Parameters\n    ----------\n    data : array_like\n        The data to fit the distribution to. Assumes values are in radians.\n    method : str, optional\n        The approach for fitting the distribution. Options are:\n        - \"analytical\": Compute `mu` and `kappa` using closed-form solutions.\n        - \"numerical\": Fit the parameters by minimizing the negative log-likelihood using an optimizer.\n        Default is \"analytical\".\n\n        When `method=\"numerical\"`, the optimization algorithm can be specified via `algorithm` in `kwargs`.\n        Supported algorithms include any method from `scipy.optimize.minimize`, such as \"L-BFGS-B\" (default) or \"Nelder-Mead\".\n\n    *args : tuple, optional\n        Additional positional arguments passed to the optimizer (if used).\n    **kwargs : dict, optional\n        Additional keyword arguments passed to the optimizer (if used).\n\n    Returns\n    -------\n    kappa : float\n        The estimated concentration parameter of the Von Mises distribution.\n    mu : float\n        The estimated mean direction of the Von Mises distribution.\n\n    Notes\n    -----\n    - The \"analytical\" method directly computes the parameters using the circular mean\n    and resultant vector length (`r`) for `mu` and `kappa`, respectively.\n    - For numerical methods, the negative log-likelihood (NLL) is minimized using `_nnlf` as the objective function.\n\n\n    Examples\n    --------\n    ```python\n    # MLE fitting using analytical solution\n    mu, kappa = vonmises.fit(data, method=\"analytical\")\n\n    # MLE fitting with numerical method using L-BFGS-B\n    mu, kappa = vonmises.fit(data, method=\"L-BFGS-B\")\n    ```\n    \"\"\"\n\n    # Validate the fitting method\n    valid_methods = [\"analytical\", \"numerical\"]\n    if method not in valid_methods:\n        raise ValueError(\n            f\"Invalid method '{method}'. Available methods are {valid_methods}.\"\n        )\n\n    # Validate the data\n    if not np.all((0 &lt;= data) &amp; (data &lt; 2 * np.pi)):\n        raise ValueError(\"Data must be in the range [0, 2\u03c0).\")\n\n    # Analytical solution for the Von Mises distribution\n    mu, r = circ_mean_and_r(alpha=data)\n    kappa = circ_kappa(r=r, n=len(data))\n\n    if method == \"analytical\":\n        if np.isclose(r, 0):\n            raise ValueError(\n                \"Resultant vector length (r) is zero, e.g. uniform data or low directional bias.\"\n            )\n        return mu, kappa\n    elif method == \"numerical\":\n        # Use analytical solution as initial guess\n        start_params = [mu, kappa]\n        bounds = [(0, 2 * np.pi), (0, None)]  # 0 &lt;= mu &lt; 2*pi, kappa &gt; 0,\n\n        algo = kwargs.pop(\"algorithm\", \"L-BFGS-B\")\n\n        # Define the objective function (NLL) using `_nnlf`\n        def nll(params):\n            return self._nnlf(params, data)\n\n        # Use the optimizer to minimize NLL\n        result = minimize(\n            nll, start_params, bounds=bounds, method=algo, *args, **kwargs\n        )\n\n        # Extract parameters from optimization result\n        if not result.success:\n            raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n        mu, kappa = result.x\n        return mu, kappa\n    else:\n        raise ValueError(\n            f\"Invalid method '{method}'. Supported methods are 'analytical' and 'numerical'.\"\n        )\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_flattopped_gen","title":"<code>vonmises_flattopped_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Flat-topped von Mises Distribution</p> <p>The Flat-topped von Mises distribution is a modification of the von Mises distribution that allows for more flexible peak shapes, including flattened or sharper tops, depending on the value of the shape parameter \\(\\nu\\).</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation based on Section 4.3.10 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class vonmises_flattopped_gen(rv_continuous):\n    r\"\"\"Flat-topped von Mises Distribution\n\n    The Flat-topped von Mises distribution is a modification of the von Mises distribution\n    that allows for more flexible peak shapes, including flattened or sharper tops, depending\n    on the value of the shape parameter $\\nu$.\n\n    ![vonmises-ext](../images/circ-mod-vonmises-flat-topped.png)\n\n    Methods\n    -------\n    pdf(x, mu, kappa, nu)\n        Probability density function.\n\n    cdf(x, mu, kappa, nu)\n        Cumulative distribution function.\n\n    Note\n    ----\n    Implementation based on Section 4.3.10 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _validate_params(self, mu, kappa, nu):\n        return (0 &lt;= mu &lt;= np.pi * 2) and (kappa &gt;= 0) and (-1 &lt;= nu &lt;= 1)\n\n    def _argcheck(self, mu, kappa, nu):\n        if self._validate_params(mu, kappa, nu):\n            self._c = _c_vmft(mu, kappa, nu)\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, mu, kappa, nu):\n        return self._c * _kernel_vmft(x, mu, kappa, nu)\n\n    def pdf(self, x, mu, kappa, nu, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Flat-topped von Mises distribution.\n\n        $$\n        f(\\theta) = c \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu)))\n        $$\n\n        , where `c` is the normalizing constant:\n\n        $$\n        c = \\frac{1}{\\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu))) d\\theta}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n        mu : float\n            Location parameter, $0 \\leq \\mu \\leq 2\\pi$. This is the mean direction when $\\nu = 0$.\n        kappa : float\n            Concentration parameter, $\\kappa \\geq 0$. Higher values indicate a sharper peak around $\\mu$.\n        nu : float\n            Shape parameter, $-1 \\leq \\nu \\leq 1$. Controls the flattening or sharpening of the peak:\n            - $\\nu &gt; 0$: sharper peaks.\n            - $\\nu &lt; 0$: flatter peaks.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Values of the probability density function at the specified points.\n\n\n        Notes\n        -----\n        - The normalization constant $c$ is computed numerically, as the integral generally\n        does not have a closed-form solution.\n        - Special cases:\n            - When $\\nu = 0$, the distribution reduces to the standard von Mises distribution.\n            - When $\\kappa = 0$, the distribution becomes uniform on $[0, 2\\pi)$.\n        \"\"\"\n        return super().pdf(x, mu, kappa, nu, *args, **kwargs)\n\n    def _cdf(self, x, mu, kappa, nu):\n        @np.vectorize\n        def _cdf_single(x, mu, kappa, nu):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(mu, kappa, nu))\n            return integral\n\n        return _cdf_single(x, mu, kappa, nu)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.vonmises_flattopped_gen.pdf","title":"<code>pdf(x, mu, kappa, nu, *args, **kwargs)</code>","text":"<p>Probability density function of the Flat-topped von Mises distribution.</p> \\[ f(\\theta) = c \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu))) \\] <p>, where <code>c</code> is the normalizing constant:</p> \\[ c = \\frac{1}{\\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu))) d\\theta} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the PDF, defined on the interval \\([0, 2\\pi)\\).</p> required <code>mu</code> <code>float</code> <p>Location parameter, \\(0 \\leq \\mu \\leq 2\\pi\\). This is the mean direction when \\(\\nu = 0\\).</p> required <code>kappa</code> <code>float</code> <p>Concentration parameter, \\(\\kappa \\geq 0\\). Higher values indicate a sharper peak around \\(\\mu\\).</p> required <code>nu</code> <code>float</code> <p>Shape parameter, \\(-1 \\leq \\nu \\leq 1\\). Controls the flattening or sharpening of the peak: - \\(\\nu &gt; 0\\): sharper peaks. - \\(\\nu &lt; 0\\): flatter peaks.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Values of the probability density function at the specified points.</p> Notes <ul> <li>The normalization constant \\(c\\) is computed numerically, as the integral generally does not have a closed-form solution.</li> <li>Special cases:<ul> <li>When \\(\\nu = 0\\), the distribution reduces to the standard von Mises distribution.</li> <li>When \\(\\kappa = 0\\), the distribution becomes uniform on \\([0, 2\\pi)\\).</li> </ul> </li> </ul> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, kappa, nu, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Flat-topped von Mises distribution.\n\n    $$\n    f(\\theta) = c \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu)))\n    $$\n\n    , where `c` is the normalizing constant:\n\n    $$\n    c = \\frac{1}{\\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cos(\\theta - \\mu + \\nu \\sin(\\theta - \\mu))) d\\theta}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n    mu : float\n        Location parameter, $0 \\leq \\mu \\leq 2\\pi$. This is the mean direction when $\\nu = 0$.\n    kappa : float\n        Concentration parameter, $\\kappa \\geq 0$. Higher values indicate a sharper peak around $\\mu$.\n    nu : float\n        Shape parameter, $-1 \\leq \\nu \\leq 1$. Controls the flattening or sharpening of the peak:\n        - $\\nu &gt; 0$: sharper peaks.\n        - $\\nu &lt; 0$: flatter peaks.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Values of the probability density function at the specified points.\n\n\n    Notes\n    -----\n    - The normalization constant $c$ is computed numerically, as the integral generally\n    does not have a closed-form solution.\n    - Special cases:\n        - When $\\nu = 0$, the distribution reduces to the standard von Mises distribution.\n        - When $\\kappa = 0$, the distribution becomes uniform on $[0, 2\\pi)$.\n    \"\"\"\n    return super().pdf(x, mu, kappa, nu, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_gen","title":"<code>jonespewsey_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Jones-Pewsey Distribution</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation based on Section 4.3.9 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class jonespewsey_gen(rv_continuous):\n    \"\"\"Jones-Pewsey Distribution\n\n    ![jonespewsey](../images/circ-mod-jonespewsey.png)\n\n    Methods\n    -------\n    pdf(x, mu, kappa, psi)\n        Probability density function.\n\n    cdf(x, mu, kappa, psi)\n        Cumulative distribution function.\n\n\n    Note\n    ----\n    Implementation based on Section 4.3.9 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _validate_params(self, mu, kappa, psi):\n        return (0 &lt;= mu &lt;= np.pi * 2) and (kappa &gt;= 0) and (-np.inf &lt;= psi &lt;= np.inf)\n\n    def _argcheck(self, mu, kappa, psi):\n        if self._validate_params(mu, kappa, psi):\n            self._c = _c_jonespewsey(\n                mu, kappa, psi\n            )  # Precompute the normalizing constant\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, mu, kappa, psi):\n\n        if np.all(kappa &lt; 0.001):\n            return 1 / (2 * np.pi)\n        else:\n            if np.isclose(np.abs(psi), 0).all():\n                return 1 / (2 * np.pi * i0(kappa)) * np.exp(kappa * np.cos(x - mu))\n            else:\n                return _kernel_jonespewsey(x, mu, kappa, psi) / self._c\n\n    def pdf(self, x, mu, kappa, psi, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Jones-Pewsey distribution.\n\n        $$\n        f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\mu))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        mu : float\n            Mean direction, 0 &lt;= mu &lt;= 2*pi.\n        kappa : float\n            Concentration parameter, kappa &gt;= 0.\n        psi : float\n            Shape parameter, -\u221e &lt;= psi &lt;= \u221e.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Probability density function evaluated at `x`.\n        \"\"\"\n        return super().pdf(x, mu, kappa, psi, *args, **kwargs)\n\n    def _cdf(self, x, mu, kappa, psi):\n        def vonmises_pdf(x, mu, kappa, psi, c):\n            return c * np.exp(kappa * np.cos(x - mu))\n\n        if np.isclose(np.abs(psi), 0).all():\n            c = self._c\n\n            @np.vectorize\n            def _cdf_single(x, mu, kappa, psi, c):\n                integral, _ = quad(vonmises_pdf, a=0, b=x, args=(mu, kappa, psi, c))\n                return integral\n\n            return _cdf_single(x, mu, kappa, psi, c)\n        else:\n\n            @np.vectorize\n            def _cdf_single(x, mu, kappa, psi):\n                integral, _ = quad(self._pdf, a=0, b=x, args=(mu, kappa, psi))\n                return integral\n\n            return _cdf_single(x, mu, kappa, psi)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_gen.pdf","title":"<code>pdf(x, mu, kappa, psi, *args, **kwargs)</code>","text":"<p>Probability density function of the Jones-Pewsey distribution.</p> \\[ f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\mu))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>mu</code> <code>float</code> <p>Mean direction, 0 &lt;= mu &lt;= 2*pi.</p> required <code>kappa</code> <code>float</code> <p>Concentration parameter, kappa &gt;= 0.</p> required <code>psi</code> <code>float</code> <p>Shape parameter, -\u221e &lt;= psi &lt;= \u221e.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Probability density function evaluated at <code>x</code>.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, mu, kappa, psi, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Jones-Pewsey distribution.\n\n    $$\n    f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\mu))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    mu : float\n        Mean direction, 0 &lt;= mu &lt;= 2*pi.\n    kappa : float\n        Concentration parameter, kappa &gt;= 0.\n    psi : float\n        Shape parameter, -\u221e &lt;= psi &lt;= \u221e.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Probability density function evaluated at `x`.\n    \"\"\"\n    return super().pdf(x, mu, kappa, psi, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_sineskewed_gen","title":"<code>jonespewsey_sineskewed_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Sine-Skewed Jones-Pewsey Distribution</p> <p>The Sine-Skewed Jones-Pewsey distribution is a circular distribution defined on \\([0, 2\\pi)\\) that extends the Jones-Pewsey family by incorporating a sine-based skewness adjustment.</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation based on Section 4.3.11 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class jonespewsey_sineskewed_gen(rv_continuous):\n    r\"\"\"Sine-Skewed Jones-Pewsey Distribution\n\n    The Sine-Skewed Jones-Pewsey distribution is a circular distribution defined on $[0, 2\\pi)$\n    that extends the Jones-Pewsey family by incorporating a sine-based skewness adjustment.\n\n    ![jonespewsey-sineskewed](../images/circ-mod-jonespewsey-sineskewed.png)\n\n    Methods\n    -------\n    pdf(x, xi, kappa, psi, lmbd)\n        Probability density function.\n\n    cdf(x, xi, kappa, psi, lmbd)\n        Cumulative distribution function.\n\n\n    Note\n    ----\n    Implementation based on Section 4.3.11 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _validate_params(self, xi, kappa, psi, lmbd):\n        return (\n            (0 &lt;= xi &lt;= np.pi * 2)\n            and (kappa &gt;= 0)\n            and (-np.inf &lt;= psi &lt;= np.inf)\n            and (-1 &lt;= lmbd &lt;= 1)\n        )\n\n    def _argcheck(self, xi, kappa, psi, lmbd):\n        if self._validate_params(xi, kappa, psi, lmbd):\n            self._c = _c_jonespewsey(xi, kappa, psi)\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, xi, kappa, psi, lmbd):\n\n        if np.all(kappa &lt; 0.001):\n            return 1 / (2 * np.pi) * (1 + lmbd * np.sin(x - xi))\n        else:\n            if np.isclose(np.abs(psi), 0).all():\n                return (\n                    1\n                    / (2 * np.pi * i0(kappa))\n                    * np.exp(kappa * np.cos(x - xi))\n                    * (1 + lmbd * np.sin(x - xi))\n                )\n            else:\n                return (\n                    (1 + lmbd * np.sin(x - xi))\n                    * _kernel_jonespewsey(x, xi, kappa, psi)\n                    / self._c\n                )\n\n    def pdf(self, x, xi, kappa, psi, lmbd, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Sine-Skewed Jones-Pewsey distribution.\n\n        $$\n        f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the probability density function.\n        xi : float\n            Direction parameter (generally not the mean), 0 &lt;= \u03be &lt;= 2*pi.\n        kappa : float\n            Concentration parameter, \u03ba &gt;= 0. Higher values indicate a sharper peak.\n        psi : float\n            Shape parameter, -\u221e &lt;= \u03c8 &lt;= \u221e. When \u03c8=-1, the distribution reduces to the wrapped Cauchy,\n            when \u03c8=0, von Mises, and when \u03c8=1, cardioid.\n        lmbd : float\n            Skewness parameter, -1 &lt; \u03bb &lt; 1. Controls the asymmetry introduced by the sine-skewing.\n\n        Returns\n        -------\n        pdf_values: float\n            Values of the probability density function at the specified points.\n        \"\"\"\n\n        return super().pdf(x, xi, kappa, psi, lmbd, *args, **kwargs)\n\n    def _cdf(self, x, xi, kappa, psi, lmbd):\n        @np.vectorize\n        def _cdf_single(x, xi, kappa, psi, lmbd):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(xi, kappa, psi, lmbd))\n            return integral\n\n        return _cdf_single(x, xi, kappa, psi, lmbd)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_sineskewed_gen.pdf","title":"<code>pdf(x, xi, kappa, psi, lmbd, *args, **kwargs)</code>","text":"<p>Probability density function of the Sine-Skewed Jones-Pewsey distribution.</p> \\[ f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the probability density function.</p> required <code>xi</code> <code>float</code> <p>Direction parameter (generally not the mean), 0 &lt;= \u03be &lt;= 2*pi.</p> required <code>kappa</code> <code>float</code> <p>Concentration parameter, \u03ba &gt;= 0. Higher values indicate a sharper peak.</p> required <code>psi</code> <code>float</code> <p>Shape parameter, -\u221e &lt;= \u03c8 &lt;= \u221e. When \u03c8=-1, the distribution reduces to the wrapped Cauchy, when \u03c8=0, von Mises, and when \u03c8=1, cardioid.</p> required <code>lmbd</code> <code>float</code> <p>Skewness parameter, -1 &lt; \u03bb &lt; 1. Controls the asymmetry introduced by the sine-skewing.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>float</code> <p>Values of the probability density function at the specified points.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, xi, kappa, psi, lmbd, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Sine-Skewed Jones-Pewsey distribution.\n\n    $$\n    f(\\theta) = \\frac{(\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi))^{1/\\psi}}{2\\pi \\cosh(\\kappa \\pi)}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the probability density function.\n    xi : float\n        Direction parameter (generally not the mean), 0 &lt;= \u03be &lt;= 2*pi.\n    kappa : float\n        Concentration parameter, \u03ba &gt;= 0. Higher values indicate a sharper peak.\n    psi : float\n        Shape parameter, -\u221e &lt;= \u03c8 &lt;= \u221e. When \u03c8=-1, the distribution reduces to the wrapped Cauchy,\n        when \u03c8=0, von Mises, and when \u03c8=1, cardioid.\n    lmbd : float\n        Skewness parameter, -1 &lt; \u03bb &lt; 1. Controls the asymmetry introduced by the sine-skewing.\n\n    Returns\n    -------\n    pdf_values: float\n        Values of the probability density function at the specified points.\n    \"\"\"\n\n    return super().pdf(x, xi, kappa, psi, lmbd, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_asym_gen","title":"<code>jonespewsey_asym_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Asymmetric Extended Jones-Pewsey Distribution</p> <p>This distribution is an extension of the Jones-Pewsey family, incorporating asymmetry through a secondary parameter \\(\\nu\\). It is defined on the circular domain \\([0, 2\\pi)\\).</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation from 4.3.12 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class jonespewsey_asym_gen(rv_continuous):\n    r\"\"\"Asymmetric Extended Jones-Pewsey Distribution\n\n    This distribution is an extension of the Jones-Pewsey family, incorporating asymmetry\n    through a secondary parameter $\\nu$. It is defined on the circular domain $[0, 2\\pi)$.\n\n    ![jonespewsey-asymext](../images/circ-mod-jonespewsey-asym.png)\n\n    Methods\n    -------\n    pdf(x, xi, kappa, psi, nu)\n        Probability density function.\n\n    cdf(x, xi, kappa, psi, nu)\n        Cumulative distribution function.\n\n\n    Note\n    ----\n    Implementation from 4.3.12 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _validate_params(self, xi, kappa, psi, nu):\n        return (\n            (0 &lt;= xi &lt;= np.pi * 2)\n            and (kappa &gt;= 0)\n            and (-np.inf &lt;= psi &lt;= np.inf)\n            and (0 &lt;= nu &lt; 1)\n        )\n\n    def _argcheck(self, xi, kappa, psi, nu):\n        if self._validate_params(xi, kappa, psi, nu):\n            self._c = _c_jonespewsey_asym(xi, kappa, psi, nu)\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, xi, kappa, psi, nu):\n        return _kernel_jonespewsey_asym(x, xi, kappa, psi, nu) / self._c\n\n    def pdf(self, x, xi, kappa, psi, nu, *args, **kwargs):\n        r\"\"\"\n        Probability density function (PDF) of the Asymmetric Extended Jones-Pewsey distribution.\n\n        The PDF is given by:\n\n        $$\n        f(\\theta) = \\frac{k(\\theta; \\xi, \\kappa, \\psi, \\nu)}{c}\n        $$\n\n        where $k(\\theta; \\xi, \\kappa, \\psi, \\nu)$ is the kernel function defined as:\n\n        $$\n        k(\\theta; \\xi, \\kappa, \\psi, \\nu) =\n        \\begin{cases}\n        \\exp\\left(\\kappa \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right) &amp; \\text{if } \\psi = 0 \\\\\n        \\left[\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right]^{1/\\psi} &amp; \\text{if } \\psi \\neq 0\n        \\end{cases}\n        $$\n\n        and $c$ is the normalization constant:\n\n        $$\n        c = \\int_{-\\pi}^{\\pi} k(\\theta; \\xi, \\kappa, \\psi, \\nu) \\, d\\theta\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n        xi : float\n            Direction parameter, $0 \\leq \\xi \\leq 2\\pi$. This typically represents the mode of the distribution.\n        kappa : float\n            Concentration parameter, $\\kappa \\geq 0$. Higher values result in a sharper peak around $\\xi$.\n        psi : float\n            Shape parameter, $-\\infty \\leq \\psi \\leq \\infty$. When $\\psi = 0$, the distribution reduces to a simpler von Mises-like form.\n        nu : float\n            Asymmetry parameter, $0 \\leq \\nu &lt; 1$. Introduces skewness in the circular distribution.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Values of the probability density function at the specified points.\n\n        Notes\n        -----\n        - The normalization constant $c$ is computed numerically using integration.\n        - Special cases:\n            - When $\\psi = 0$, the kernel simplifies to the von Mises-like asymmetric form.\n            - When $\\kappa = 0$, the distribution becomes uniform on $[0, 2\\pi)$.\n        \"\"\"\n        return super().pdf(x, xi, kappa, psi, nu, *args, **kwargs)\n\n    def _cdf(self, x, xi, kappa, psi, nu):\n        @np.vectorize\n        def _cdf_single(x, xi, kappa, psi, nu):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(xi, kappa, psi, nu))\n            return integral\n\n        return _cdf_single(x, xi, kappa, psi, nu)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.jonespewsey_asym_gen.pdf","title":"<code>pdf(x, xi, kappa, psi, nu, *args, **kwargs)</code>","text":"<p>Probability density function (PDF) of the Asymmetric Extended Jones-Pewsey distribution.</p> <p>The PDF is given by:</p> \\[ f(\\theta) = \\frac{k(\\theta; \\xi, \\kappa, \\psi, \\nu)}{c} \\] <p>where \\(k(\\theta; \\xi, \\kappa, \\psi, \\nu)\\) is the kernel function defined as:</p> \\[ k(\\theta; \\xi, \\kappa, \\psi, \\nu) = \\begin{cases} \\exp\\left(\\kappa \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right) &amp; \\text{if } \\psi = 0 \\\\ \\left[\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right]^{1/\\psi} &amp; \\text{if } \\psi \\neq 0 \\end{cases} \\] <p>and \\(c\\) is the normalization constant:</p> \\[ c = \\int_{-\\pi}^{\\pi} k(\\theta; \\xi, \\kappa, \\psi, \\nu) \\, d\\theta \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the PDF, defined on the interval \\([0, 2\\pi)\\).</p> required <code>xi</code> <code>float</code> <p>Direction parameter, \\(0 \\leq \\xi \\leq 2\\pi\\). This typically represents the mode of the distribution.</p> required <code>kappa</code> <code>float</code> <p>Concentration parameter, \\(\\kappa \\geq 0\\). Higher values result in a sharper peak around \\(\\xi\\).</p> required <code>psi</code> <code>float</code> <p>Shape parameter, \\(-\\infty \\leq \\psi \\leq \\infty\\). When \\(\\psi = 0\\), the distribution reduces to a simpler von Mises-like form.</p> required <code>nu</code> <code>float</code> <p>Asymmetry parameter, \\(0 \\leq \\nu &lt; 1\\). Introduces skewness in the circular distribution.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Values of the probability density function at the specified points.</p> Notes <ul> <li>The normalization constant \\(c\\) is computed numerically using integration.</li> <li>Special cases:<ul> <li>When \\(\\psi = 0\\), the kernel simplifies to the von Mises-like asymmetric form.</li> <li>When \\(\\kappa = 0\\), the distribution becomes uniform on \\([0, 2\\pi)\\).</li> </ul> </li> </ul> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, xi, kappa, psi, nu, *args, **kwargs):\n    r\"\"\"\n    Probability density function (PDF) of the Asymmetric Extended Jones-Pewsey distribution.\n\n    The PDF is given by:\n\n    $$\n    f(\\theta) = \\frac{k(\\theta; \\xi, \\kappa, \\psi, \\nu)}{c}\n    $$\n\n    where $k(\\theta; \\xi, \\kappa, \\psi, \\nu)$ is the kernel function defined as:\n\n    $$\n    k(\\theta; \\xi, \\kappa, \\psi, \\nu) =\n    \\begin{cases}\n    \\exp\\left(\\kappa \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right) &amp; \\text{if } \\psi = 0 \\\\\n    \\left[\\cosh(\\kappa \\psi) + \\sinh(\\kappa \\psi) \\cos(\\theta - \\xi + \\nu \\cos(\\theta - \\xi))\\right]^{1/\\psi} &amp; \\text{if } \\psi \\neq 0\n    \\end{cases}\n    $$\n\n    and $c$ is the normalization constant:\n\n    $$\n    c = \\int_{-\\pi}^{\\pi} k(\\theta; \\xi, \\kappa, \\psi, \\nu) \\, d\\theta\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n    xi : float\n        Direction parameter, $0 \\leq \\xi \\leq 2\\pi$. This typically represents the mode of the distribution.\n    kappa : float\n        Concentration parameter, $\\kappa \\geq 0$. Higher values result in a sharper peak around $\\xi$.\n    psi : float\n        Shape parameter, $-\\infty \\leq \\psi \\leq \\infty$. When $\\psi = 0$, the distribution reduces to a simpler von Mises-like form.\n    nu : float\n        Asymmetry parameter, $0 \\leq \\nu &lt; 1$. Introduces skewness in the circular distribution.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Values of the probability density function at the specified points.\n\n    Notes\n    -----\n    - The normalization constant $c$ is computed numerically using integration.\n    - Special cases:\n        - When $\\psi = 0$, the kernel simplifies to the von Mises-like asymmetric form.\n        - When $\\kappa = 0$, the distribution becomes uniform on $[0, 2\\pi)$.\n    \"\"\"\n    return super().pdf(x, xi, kappa, psi, nu, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.inverse_batschelet_gen","title":"<code>inverse_batschelet_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Inverse Batschelet distribution.</p> <p>The inverse Batschelet distribution is a flexible circular distribution that allows for modeling asymmetric and peaked data. It is defined on the interval \\([0, 2\\pi)\\).</p> <p></p> <p>Methods:</p> Name Description <code>pdf</code> <p>Probability density function.</p> <code>cdf</code> <p>Cumulative distribution function.</p> Note <p>Implementation from 4.3.13 of Pewsey et al. (2014)</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class inverse_batschelet_gen(rv_continuous):\n    r\"\"\"Inverse Batschelet distribution.\n\n    The inverse Batschelet distribution is a flexible circular distribution that allows for\n    modeling asymmetric and peaked data. It is defined on the interval $[0, 2\\pi)$.\n\n    ![inverse-batschelet](../images/circ-mod-inverse-batschelet.png)\n\n    Methods\n    -------\n    pdf(x, xi, kappa, psi, nu, lmbd)\n        Probability density function.\n\n    cdf(x, xi, kappa, psi, nu, lmbd)\n        Cumulative distribution function.\n\n\n    Note\n    ----\n    Implementation from 4.3.13 of Pewsey et al. (2014)\n    \"\"\"\n\n    def _validate_params(self, xi, kappa, nu, lmbd):\n        return (\n            (0 &lt;= xi &lt;= np.pi * 2)\n            and (kappa &gt;= 0)\n            and (-1 &lt;= nu &lt;= 1)\n            and (-1 &lt;= lmbd &lt;= 1)\n        )\n\n    def _argcheck(self, xi, kappa, nu, lmbd):\n        if self._validate_params(xi, kappa, nu, lmbd):\n            self._c = _c_invbatschelet(kappa, lmbd)\n            if np.isclose(lmbd, -1).all():\n                self.con1, self.con2 = 0, 0\n            else:\n                self.con1 = (1 - lmbd) / (1 + lmbd)\n                self.con2 = (2 * lmbd) / (1 + lmbd)\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, xi, kappa, nu, lmbd):\n\n        arg1 = _tnu(x, nu, xi)\n        arg2 = _slmbdinv(arg1, lmbd)\n\n        if np.isclose(lmbd, -1).all():\n            return self._c * np.exp(kappa * np.cos(arg1 - np.sin(arg1)))\n        else:\n            return self._c * np.exp(kappa * np.cos(self.con1 * arg1 + self.con2 * arg2))\n\n    def pdf(self, x, xi, kappa, nu, lmbd, *args, **kwargs):\n        r\"\"\"\n        Probability density function (PDF) of the inverse Batschelet distribution.\n\n        The PDF is defined as:\n\n        $$\n        f(\\theta) = c \\exp\\left(\\kappa \\cos\\left(a \\cdot g(\\theta, \\nu, \\xi) + b \\cdot s\\left(g(\\theta, \\nu, \\xi), \\lambda\\right)\\right)\\right)\n        $$\n\n        where:\n\n        - $a$: Weight for the angular transformation, defined as:\n\n        $$\n        a = \\frac{1 - \\lambda}{1 + \\lambda}\n        $$\n\n        - $b$: Weight for the skewness transformation, defined as:\n\n        $$\n        b = \\frac{2 \\lambda}{1 + \\lambda}\n        $$\n\n        - $g(\\theta, \\nu, \\xi)$: Angular transformation function, which incorporates $\\nu$ and the location parameter $\\xi$:\n\n        $$\n        g(\\theta, \\nu, \\xi) = \\theta - \\xi - \\nu \\cdot (1 + \\cos(\\theta - \\xi))\n        $$\n\n        - $s(z, \\lambda)$: Skewness transformation function, defined as the root of the equation:\n\n        $$\n        s(z, \\lambda) - 0.5 \\cdot (1 + \\lambda) \\cdot \\sin(s(z, \\lambda)) = z\n        $$\n\n        - $c$: Normalization constant ensuring the PDF integrates to 1, computed as:\n\n        $$\n        c = \\frac{1}{2\\pi \\cdot I_0(\\kappa) \\cdot \\left(a - b \\cdot \\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cdot \\cos(z - (1 - \\lambda) \\cdot \\sin(z) / 2)) dz\\right)}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n        xi : float\n            Direction parameter, $0 \\leq \\xi \\leq 2\\pi$. This typically represents the mode.\n        kappa : float\n            Concentration parameter, $\\kappa \\geq 0$. Higher values result in sharper peaks around $\\xi$.\n        nu : float\n            Shape parameter, $-1 \\leq \\nu \\leq 1$. Controls asymmetry through angular transformation.\n        lmbd : float\n            Skewness parameter, $-1 \\leq \\lambda \\leq 1$. Controls the degree of skewness in the distribution.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Values of the probability density function at the specified points.\n        \"\"\"\n        return super().pdf(x, xi, kappa, nu, lmbd, *args, **kwargs)\n\n    def _cdf(self, x, xi, kappa, nu, lmbd):\n        @np.vectorize\n        def _cdf_single(x, xi, kappa, nu, lmbd):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(xi, kappa, nu, lmbd))\n            return integral\n\n        return _cdf_single(x, xi, kappa, nu, lmbd)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.inverse_batschelet_gen.pdf","title":"<code>pdf(x, xi, kappa, nu, lmbd, *args, **kwargs)</code>","text":"<p>Probability density function (PDF) of the inverse Batschelet distribution.</p> <p>The PDF is defined as:</p> \\[ f(\\theta) = c \\exp\\left(\\kappa \\cos\\left(a \\cdot g(\\theta, \\nu, \\xi) + b \\cdot s\\left(g(\\theta, \\nu, \\xi), \\lambda\\right)\\right)\\right) \\] <p>where:</p> <ul> <li>\\(a\\): Weight for the angular transformation, defined as:</li> </ul> \\[ a = \\frac{1 - \\lambda}{1 + \\lambda} \\] <ul> <li>\\(b\\): Weight for the skewness transformation, defined as:</li> </ul> \\[ b = \\frac{2 \\lambda}{1 + \\lambda} \\] <ul> <li>\\(g(\\theta, \\nu, \\xi)\\): Angular transformation function, which incorporates \\(\\nu\\) and the location parameter \\(\\xi\\):</li> </ul> \\[ g(\\theta, \\nu, \\xi) = \\theta - \\xi - \\nu \\cdot (1 + \\cos(\\theta - \\xi)) \\] <ul> <li>\\(s(z, \\lambda)\\): Skewness transformation function, defined as the root of the equation:</li> </ul> \\[ s(z, \\lambda) - 0.5 \\cdot (1 + \\lambda) \\cdot \\sin(s(z, \\lambda)) = z \\] <ul> <li>\\(c\\): Normalization constant ensuring the PDF integrates to 1, computed as:</li> </ul> \\[ c = \\frac{1}{2\\pi \\cdot I_0(\\kappa) \\cdot \\left(a - b \\cdot \\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cdot \\cos(z - (1 - \\lambda) \\cdot \\sin(z) / 2)) dz\\right)} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the PDF, defined on the interval \\([0, 2\\pi)\\).</p> required <code>xi</code> <code>float</code> <p>Direction parameter, \\(0 \\leq \\xi \\leq 2\\pi\\). This typically represents the mode.</p> required <code>kappa</code> <code>float</code> <p>Concentration parameter, \\(\\kappa \\geq 0\\). Higher values result in sharper peaks around \\(\\xi\\).</p> required <code>nu</code> <code>float</code> <p>Shape parameter, \\(-1 \\leq \\nu \\leq 1\\). Controls asymmetry through angular transformation.</p> required <code>lmbd</code> <code>float</code> <p>Skewness parameter, \\(-1 \\leq \\lambda \\leq 1\\). Controls the degree of skewness in the distribution.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Values of the probability density function at the specified points.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, xi, kappa, nu, lmbd, *args, **kwargs):\n    r\"\"\"\n    Probability density function (PDF) of the inverse Batschelet distribution.\n\n    The PDF is defined as:\n\n    $$\n    f(\\theta) = c \\exp\\left(\\kappa \\cos\\left(a \\cdot g(\\theta, \\nu, \\xi) + b \\cdot s\\left(g(\\theta, \\nu, \\xi), \\lambda\\right)\\right)\\right)\n    $$\n\n    where:\n\n    - $a$: Weight for the angular transformation, defined as:\n\n    $$\n    a = \\frac{1 - \\lambda}{1 + \\lambda}\n    $$\n\n    - $b$: Weight for the skewness transformation, defined as:\n\n    $$\n    b = \\frac{2 \\lambda}{1 + \\lambda}\n    $$\n\n    - $g(\\theta, \\nu, \\xi)$: Angular transformation function, which incorporates $\\nu$ and the location parameter $\\xi$:\n\n    $$\n    g(\\theta, \\nu, \\xi) = \\theta - \\xi - \\nu \\cdot (1 + \\cos(\\theta - \\xi))\n    $$\n\n    - $s(z, \\lambda)$: Skewness transformation function, defined as the root of the equation:\n\n    $$\n    s(z, \\lambda) - 0.5 \\cdot (1 + \\lambda) \\cdot \\sin(s(z, \\lambda)) = z\n    $$\n\n    - $c$: Normalization constant ensuring the PDF integrates to 1, computed as:\n\n    $$\n    c = \\frac{1}{2\\pi \\cdot I_0(\\kappa) \\cdot \\left(a - b \\cdot \\int_{-\\pi}^{\\pi} \\exp(\\kappa \\cdot \\cos(z - (1 - \\lambda) \\cdot \\sin(z) / 2)) dz\\right)}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n    xi : float\n        Direction parameter, $0 \\leq \\xi \\leq 2\\pi$. This typically represents the mode.\n    kappa : float\n        Concentration parameter, $\\kappa \\geq 0$. Higher values result in sharper peaks around $\\xi$.\n    nu : float\n        Shape parameter, $-1 \\leq \\nu \\leq 1$. Controls asymmetry through angular transformation.\n    lmbd : float\n        Skewness parameter, $-1 \\leq \\lambda \\leq 1$. Controls the degree of skewness in the distribution.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Values of the probability density function at the specified points.\n    \"\"\"\n    return super().pdf(x, xi, kappa, nu, lmbd, *args, **kwargs)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapstable_gen","title":"<code>wrapstable_gen</code>","text":"<p>               Bases: <code>rv_continuous</code></p> <p>Wrapped Stable Distribution</p> <ul> <li>is symmetric around \\(\\delta\\) when \\(\\beta = 0\\), and to be skewed to the right (left) if \\(\\beta &gt; 0\\) (\\(\\beta &lt; 0\\)).</li> <li>can be reduced to<ul> <li>the wrapped normal distribution when \\(\\alpha = 2, \\beta = 0\\).</li> <li>the wrapped Cauchy distribution when \\(\\alpha = 1, \\beta = 0\\).</li> <li>the wrappd L\u00e9vy distribution when \\(\\alpha = 1/2, \\beta = 1\\)</li> </ul> </li> </ul> <p></p> References <ul> <li>Pewsey, A. (2008). The wrapped stable family of distributions as a flexible model for circular data. Computational Statistics &amp; Data Analysis, 52(3), 1516-1523.</li> </ul> Source code in <code>pycircstat2/distributions.py</code> <pre><code>class wrapstable_gen(rv_continuous):\n    r\"\"\"\n    Wrapped Stable Distribution\n\n    - is symmetric around $\\delta$ when $\\beta = 0$, and to be skewed to the right (left) if $\\beta &gt; 0$ ($\\beta &lt; 0$).\n    - can be reduced to\n        - the wrapped normal distribution when $\\alpha = 2, \\beta = 0$.\n        - the wrapped Cauchy distribution when $\\alpha = 1, \\beta = 0$.\n        - the wrappd L\u00e9vy distribution when $\\alpha = 1/2, \\beta = 1$\n\n    ![wrapstable](../images/circ-mod-wrapstable.png)\n\n    References\n    ----------\n    - Pewsey, A. (2008). The wrapped stable family of distributions as a flexible model for circular data. Computational Statistics &amp; Data Analysis, 52(3), 1516-1523.\n    \"\"\"\n\n    def _validate_params(self, delta, alpha, beta, gamma):\n        return (\n            (0 &lt;= delta &lt;= np.pi * 2)\n            and (0 &lt; alpha &lt;= 2)\n            and (-1 &lt; beta &lt; 1)\n            and (gamma &gt; 0)\n        )\n\n    def _argcheck(self, delta, alpha, beta, gamma):\n        if self._validate_params(delta, alpha, beta, gamma):\n            return True\n        else:\n            return False\n\n    def _pdf(self, x, delta, alpha, beta, gamma):\n\n        def rho_p(p, alpha, gamma):\n            return np.exp(-((gamma * p) ** alpha))\n\n        def mu_p(p, alpha, beta, gamma, delta):\n            if np.all(alpha == 1):\n                mu = delta * p - 2 * beta * gamma * p * np.log(gamma * p) / np.pi\n            else:\n                mu = delta * p + beta * np.tan(np.pi * alpha / 2) * (\n                    (gamma * p) ** alpha - gamma * p\n                )\n            return mu\n\n        series_sum = 0\n        for p in np.arange(1, 150):\n            rho = rho_p(p, alpha, gamma)\n            mu = mu_p(p, alpha, beta, gamma, delta)\n            series_sum += rho * np.cos(p * x - mu)\n\n        pdf_values = 1 / (2 * np.pi) * (1 + 2 * series_sum)\n\n        return pdf_values\n\n    def pdf(self, x, delta, alpha, beta, gamma, *args, **kwargs):\n        r\"\"\"\n        Probability density function of the Wrapped Stable distribution.\n\n        $$\n        f(\\theta) = \\frac{1}{2\\pi} \\left[1 + 2 \\sum_{p=1}^{\\infty} \\rho_p \\cos\\left(p(\\theta - \\mu_p)\\right)\\right]\n        $$\n\n        , where $\\rho_p$ is the $p$th mean resultant length and $\\mu_p$ is the $p$th mean direction:\n\n        $$\n        \\rho_p = \\exp\\left(-(\\gamma p)^\\alpha\\right)\n        $$\n\n        $$\n        \\mu_p = \n        \\begin{cases}\n            \\delta p + \\beta \\tan\\left(\\frac{\\pi \\alpha}{2}\\right) \\left((\\gamma p)^\\alpha - \\gamma p\\right), &amp; \\alpha \\neq 1 \\\\\n            \\delta p - \\beta \\frac{2}{\\pi} \\log(\\gamma p), &amp; \\text{if } \\alpha = 1\n        \\end{cases}\n        $$\n\n        Parameters\n        ----------\n        x : array_like\n            Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n        delta : float\n            Location parameter, $0 \\leq \\delta \\leq 2\\pi$. This is the mean direction of the distribution.\n        alpha : float\n            Stability parameter, $0 &lt; \\alpha \\leq 2$. Higher values indicate heavier tails.\n        beta : float\n            Skewness parameter, $-1 &lt; \\beta &lt; 1$. Controls the asymmetry of the distribution.\n        gamma : float\n            Scale parameter, $\\gamma &gt; 0$. Scales the distribution.\n\n        Returns\n        -------\n        pdf_values : array_like\n            Values of the probability density function at the specified points.\n        \"\"\"\n        return super().pdf(x, delta, alpha, beta, gamma, *args, **kwargs)\n\n    def _cdf(self, x, delta, alpha, beta, gamma):\n\n        @np.vectorize\n        def _cdf_single(x, delta, alpha, beta, gamma):\n            integral, _ = quad(self._pdf, a=0, b=x, args=(delta, alpha, beta, gamma))\n            return integral\n\n        return _cdf_single(x, delta, alpha, beta, gamma)\n</code></pre>"},{"location":"reference/distributions/#pycircstat2.distributions.wrapstable_gen.pdf","title":"<code>pdf(x, delta, alpha, beta, gamma, *args, **kwargs)</code>","text":"<p>Probability density function of the Wrapped Stable distribution.</p> \\[ f(\\theta) = \\frac{1}{2\\pi} \\left[1 + 2 \\sum_{p=1}^{\\infty} \\rho_p \\cos\\left(p(\\theta - \\mu_p)\\right)\\right] \\] <p>, where \\(\\rho_p\\) is the \\(p\\)th mean resultant length and \\(\\mu_p\\) is the \\(p\\)th mean direction:</p> \\[ \\rho_p = \\exp\\left(-(\\gamma p)^\\alpha\\right) \\] \\[ \\mu_p =  \\begin{cases}     \\delta p + \\beta \\tan\\left(\\frac{\\pi \\alpha}{2}\\right) \\left((\\gamma p)^\\alpha - \\gamma p\\right), &amp; \\alpha \\neq 1 \\\\     \\delta p - \\beta \\frac{2}{\\pi} \\log(\\gamma p), &amp; \\text{if } \\alpha = 1 \\end{cases} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>Points at which to evaluate the PDF, defined on the interval \\([0, 2\\pi)\\).</p> required <code>delta</code> <code>float</code> <p>Location parameter, \\(0 \\leq \\delta \\leq 2\\pi\\). This is the mean direction of the distribution.</p> required <code>alpha</code> <code>float</code> <p>Stability parameter, \\(0 &lt; \\alpha \\leq 2\\). Higher values indicate heavier tails.</p> required <code>beta</code> <code>float</code> <p>Skewness parameter, \\(-1 &lt; \\beta &lt; 1\\). Controls the asymmetry of the distribution.</p> required <code>gamma</code> <code>float</code> <p>Scale parameter, \\(\\gamma &gt; 0\\). Scales the distribution.</p> required <p>Returns:</p> Name Type Description <code>pdf_values</code> <code>array_like</code> <p>Values of the probability density function at the specified points.</p> Source code in <code>pycircstat2/distributions.py</code> <pre><code>def pdf(self, x, delta, alpha, beta, gamma, *args, **kwargs):\n    r\"\"\"\n    Probability density function of the Wrapped Stable distribution.\n\n    $$\n    f(\\theta) = \\frac{1}{2\\pi} \\left[1 + 2 \\sum_{p=1}^{\\infty} \\rho_p \\cos\\left(p(\\theta - \\mu_p)\\right)\\right]\n    $$\n\n    , where $\\rho_p$ is the $p$th mean resultant length and $\\mu_p$ is the $p$th mean direction:\n\n    $$\n    \\rho_p = \\exp\\left(-(\\gamma p)^\\alpha\\right)\n    $$\n\n    $$\n    \\mu_p = \n    \\begin{cases}\n        \\delta p + \\beta \\tan\\left(\\frac{\\pi \\alpha}{2}\\right) \\left((\\gamma p)^\\alpha - \\gamma p\\right), &amp; \\alpha \\neq 1 \\\\\n        \\delta p - \\beta \\frac{2}{\\pi} \\log(\\gamma p), &amp; \\text{if } \\alpha = 1\n    \\end{cases}\n    $$\n\n    Parameters\n    ----------\n    x : array_like\n        Points at which to evaluate the PDF, defined on the interval $[0, 2\\pi)$.\n    delta : float\n        Location parameter, $0 \\leq \\delta \\leq 2\\pi$. This is the mean direction of the distribution.\n    alpha : float\n        Stability parameter, $0 &lt; \\alpha \\leq 2$. Higher values indicate heavier tails.\n    beta : float\n        Skewness parameter, $-1 &lt; \\beta &lt; 1$. Controls the asymmetry of the distribution.\n    gamma : float\n        Scale parameter, $\\gamma &gt; 0$. Scales the distribution.\n\n    Returns\n    -------\n    pdf_values : array_like\n        Values of the probability density function at the specified points.\n    \"\"\"\n    return super().pdf(x, delta, alpha, beta, gamma, *args, **kwargs)\n</code></pre>"},{"location":"reference/hypothesis/","title":"Hypothesis Testing","text":""},{"location":"reference/hypothesis/#pycircstat2.hypothesis.rayleigh_test","title":"<code>rayleigh_test(alpha=None, w=None, r=None, n=None, B=1, verbose=False)</code>","text":"<p>Rayleigh's Test for Circular Uniformity.</p> <ul> <li>H0: The data in the population are distributed uniformly around the circle.</li> <li>H1: The data in the population are not disbutrited uniformly around the circle.</li> </ul> \\[ z = n \\cdot r^2 \\] <p>and</p> \\[ p = \\exp(\\sqrt{1 + 4n + 4(n^2 - R^2)} - (1 + 2n)) \\] <p>This method is for ungrouped data. For testing uniformity with grouped data, use <code>chisquare_test()</code> or <code>scipy.stats.chisquare()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies of angles.</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length from <code>descriptive.circ_mean()</code>.</p> <code>None</code> <code>n</code> <code>Optional[int]</code> <p>Sample size.</p> <code>None</code> <code>B</code> <code>int</code> <p>Number of bootstrap samples for p-value estimation.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Type Description <code>RayleighTestResult</code> <p>A dataclass containing:</p> <ul> <li>r: float<ul> <li>Resultant vector length.</li> </ul> </li> <li>z: float<ul> <li>Test statistic (Rayleigh's Z).</li> </ul> </li> <li>pval: float<ul> <li>Classical p-value based on the asymptotic formula.</li> </ul> </li> <li>bootstrap_pval: float or None<ul> <li>Bootstrap p-value (if computed, i.e., B &gt; 1); otherwise, None.</li> </ul> </li> </ul> Reference <p>P625, Section 27.1, Example 27.1 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def rayleigh_test(\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    r: Optional[float] = None,\n    n: Optional[int] = None,\n    B: int = 1,\n    verbose: bool = False,\n) -&gt; RayleighTestResult:\n    r\"\"\"\n    Rayleigh's Test for Circular Uniformity.\n\n    - H0: The data in the population are distributed uniformly around the circle.\n    - H1: The data in the population are not disbutrited uniformly around the circle.\n\n    $$ z = n \\cdot r^2 $$\n\n    and\n\n    $$ p = \\exp(\\sqrt{1 + 4n + 4(n^2 - R^2)} - (1 + 2n)) $$\n\n    This method is for ungrouped data. For testing uniformity with\n    grouped data, use `chisquare_test()` or `scipy.stats.chisquare()`.\n\n    Parameters\n    ----------\n\n    alpha: np.array or None\n        Angles in radian.\n\n    w: np.array or None.\n        Frequencies of angles.\n\n    r: float or None\n        Resultant vector length from `descriptive.circ_mean()`.\n\n    n: int or None\n        Sample size.\n\n    B: int\n        Number of bootstrap samples for p-value estimation.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    RayleighTestResult\n        A dataclass containing:\n\n        - r: float\n            - Resultant vector length.\n        - z: float\n            - Test statistic (Rayleigh's Z).\n        - pval: float\n            - Classical p-value based on the asymptotic formula.\n        - bootstrap_pval: float or None\n            - Bootstrap p-value (if computed, i.e., B &gt; 1); otherwise, None.\n\n    Reference\n    ---------\n    P625, Section 27.1, Example 27.1 of Zar, 2010\n    \"\"\"\n\n    if r is None:\n        assert isinstance(alpha, np.ndarray), (\n            \"If `r` is None, then `alpha` (and `w`) is needed.\"\n        )\n        if w is None:\n            w = np.ones_like(alpha)\n        n = np.sum(w, dtype=int)\n        r = circ_r(alpha, w)\n\n    if n is None:\n        raise ValueError(\"Sample size `n` is missing.\")\n\n    R = n * r\n    z = n * r**2  # eq(27.2)\n\n    pval = np.exp(np.sqrt(1 + 4 * n + 4 * (n**2 - R**2)) - (1 + 2 * n))  # eq(27.4)\n\n    if B &gt; 1:\n        tb = np.zeros(B)\n        for i in range(B):\n            x = np.random.normal(size=(n, 1))\n            x /= np.linalg.norm(x, axis=1, keepdims=True)  # Normalize to unit sphere\n            mb = np.sum(x, axis=0)\n            tb[i] = np.sum(mb**2) / n\n\n        bootstrap_pval = float((np.sum(tb &gt; z) + 1) / (B + 1))\n    else:\n        bootstrap_pval = None\n\n    if verbose:\n        print(\"Rayleigh's Test of Uniformity\")\n        print(\"-----------------------------\")\n        print(\"H0: \u03c1 = 0\")\n        print(\"HA: \u03c1 \u2260 0\")\n        print(\"\")\n        print(f\"Test Statistics  (\u03c1 | z-score): {r:.5f} | {z:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n        if B &gt; 1 and bootstrap_pval is not None:\n            print(\n                f\"Bootstrap P-value: {bootstrap_pval:.5f} {significance_code(bootstrap_pval)}\"\n            )\n\n    return RayleighTestResult(r=r, z=z, pval=pval, bootstrap_pval=bootstrap_pval)\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.chisquare_test","title":"<code>chisquare_test(w, verbose=False)</code>","text":"<p>Chi-Square Goodness of Fit for Circular data.</p> <ul> <li>H0: The data in the population are distributed uniformly around the circle.</li> <li>H1: THe data in the population are not disbutrited uniformly around the circle.</li> </ul> <p>For method is for grouped data.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>ndarray</code> <p>Frequencies of angles</p> required <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Type Description <code>ChiSquareTestResult</code> <p>A dataclass containing:</p> <ul> <li>chi2: float<ul> <li>The chi-squared test statistic.</li> </ul> </li> <li>pval: float<ul> <li>The p-value of the test.</li> </ul> </li> </ul> Note <p>It's a wrapper of scipy.stats.chisquare()</p> Reference <p>P662-663, Section 27.17, Example 27.23 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def chisquare_test(w: np.ndarray, verbose: bool = False) -&gt; ChiSquareTestResult:\n    \"\"\"Chi-Square Goodness of Fit for Circular data.\n\n    - H0: The data in the population are distributed uniformly around the circle.\n    - H1: THe data in the population are not disbutrited uniformly around the circle.\n\n    For method is for grouped data.\n\n    Parameters\n    ----------\n    w: np.ndarray\n        Frequencies of angles\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    ChiSquareTestResult\n        A dataclass containing:\n\n        - chi2: float\n            - The chi-squared test statistic.\n        - pval: float\n            - The p-value of the test.\n\n    Note\n    ----\n    It's a wrapper of scipy.stats.chisquare()\n\n    Reference\n    ---------\n    P662-663, Section 27.17, Example 27.23 of Zar, 2010\n    \"\"\"\n    from scipy.stats import chisquare\n\n    res = chisquare(w)\n    chi2 = res.statistic\n    pval = res.pvalue\n\n    if verbose:\n        print(\"Chi-Square Test of Uniformity\")\n        print(\"-----------------------------\")\n        print(\"H0: uniform\")\n        print(\"HA: not uniform\")\n        print(\"\")\n        print(f\"Test Statistics (\u03c7\u00b2): {chi2:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return ChiSquareTestResult(chi2=chi2, pval=pval)\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.V_test","title":"<code>V_test(angle, alpha=None, w=None, mean=None, r=None, n=None, verbose=False)</code>","text":"<p>Modified Rayleigh Test for Uniformity versus a Specified Angle.</p> <ul> <li>H0: The population is uniformly distributed around the circle (i.e., H0: \u03c1=0)</li> <li>H1: The population is not uniformly distributed around the circle (i.e., H1: \u03c1!=0),     but has a mean of certain degree.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>Union[int, float]</code> <p>Angle in radian to be compared with mean angle.</p> required <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies of angles.</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Circular mean from <code>descriptive.circ_mean()</code>. Needed if <code>alpha</code> is None.</p> <code>None</code> <code>r</code> <code>Optional[float]</code> <p>Resultant vector length from <code>descriptive.circ_mean()</code>. Needed if <code>alpha</code> is None.</p> <code>None</code> <code>n</code> <code>Optional[int]</code> <p>Sample size. Needed if <code>alpha</code> is None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>V</code> <code>float</code> <p>Test Statistics.</p> <code>u</code> <code>float</code> <p>circular mean.</p> <code>p</code> <code>float</code> <p>P-value.</p> Reference <p>P627, Section 27.1, Example 27.2 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def V_test(\n    angle: Union[int, float],\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    mean: Optional[float] = None,\n    r: Optional[float] = None,\n    n: Optional[int] = None,\n    verbose: bool = False,\n) -&gt; tuple[float, float, float]:\n    \"\"\"\n    Modified Rayleigh Test for Uniformity versus a Specified Angle.\n\n    - H0: The population is uniformly distributed around the circle (i.e., H0: \u03c1=0)\n    - H1: The population is not uniformly distributed around the circle (i.e., H1: \u03c1!=0),\n        but has a mean of certain degree.\n\n    Parameters\n    ----------\n    angle: float or int\n        Angle in radian to be compared with mean angle.\n\n    alpha: np.array or None\n        Angles in radian.\n\n    w: np.array or None.\n        Frequencies of angles.\n\n    mean: float or None\n        Circular mean from `descriptive.circ_mean()`. Needed if `alpha` is None.\n\n    r: float or None\n        Resultant vector length from `descriptive.circ_mean()`. Needed if `alpha` is None.\n\n    n: int or None\n        Sample size. Needed if `alpha` is None.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n\n    V: float\n        Test Statistics.\n    u: float\n        circular mean.\n    p: float\n        P-value.\n\n    Reference\n    ---------\n    P627, Section 27.1, Example 27.2 of Zar, 2010\n    \"\"\"\n\n    if mean is None or r is None or n is None:\n        if alpha is None:\n            raise ValueError(\"If `mean`, `r` or `n` is None, then `alpha` (and `w`) is needed.\")\n        if w is None:\n            w = np.ones_like(alpha)\n        n = int(np.sum(w))\n        mean, r = circ_mean_and_r(alpha, w)\n\n    R = n * r\n    V = R * np.cos(mean - angle)  # eq(27.5)\n    u = V * np.sqrt(2 / n)  # eq(27.6)\n    pval = 1 - norm().cdf(u)\n\n    if verbose:\n        print(\"Modified Rayleigh's Test of Uniformity\")\n        print(\"--------------------------------------\")\n        print(\"H0: \u03c1 = 0\")\n        print(\"HA: \u03c1 \u2260 0 and \u03bc = {angle:.5f} rad\")\n        print(\"\")\n        print(f\"Test Statistics: {V:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return V, u, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.one_sample_test","title":"<code>one_sample_test(angle, alpha=None, w=None, lb=None, ub=None, verbose=False)</code>","text":"<p>To test whether the population mean angle is equal to a specified value, which is achieved by observing whether the angle lies within the 95% CI.</p> <ul> <li>H0: The population has a mean of \u03bc (\u03bc_a = \u03bc_0)</li> <li>H1: The population mean is not \u03bc (\u03bc_a \u2260 \u03bc_0)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>Union[int, float]</code> <p>Angle in radian to be compared with mean angle.</p> required <code>alpha</code> <code>Optional[ndarray]</code> <p>Angles in radian.</p> <code>None</code> <code>w</code> <code>Optional[ndarray]</code> <p>Frequencies of angles</p> <code>None</code> <code>lb</code> <code>Optional[float]</code> <p>Lower bound of circular mean from <code>descriptive.circ_mean_ci()</code>.</p> <code>None</code> <code>ub</code> <code>Optional[float]</code> <p>Upper bound of circular mean from <code>descriptive.circ_mean_ci()</code>.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>reject</code> <code>bool</code> <p>Reject or not reject the null hypothesis.</p> Reference <p>P628, Section 27.1, Example 27.3 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def one_sample_test(\n    angle: Union[int, float],\n    alpha: Optional[np.ndarray] = None,\n    w: Optional[np.ndarray] = None,\n    lb: Optional[float] = None,\n    ub: Optional[float] = None,\n    verbose: bool = False,\n) -&gt; bool:\n    \"\"\"\n    To test whether the population mean angle is equal to a specified value,\n    which is achieved by observing whether the angle lies within the 95% CI.\n\n    - H0: The population has a mean of \u03bc (\u03bc_a = \u03bc_0)\n    - H1: The population mean is not \u03bc (\u03bc_a \u2260 \u03bc_0)\n\n    Parameters\n    ----------\n\n    angle: float or int\n        Angle in radian to be compared with mean angle.\n\n    alpha: np.array or None\n        Angles in radian.\n\n    w: np.array or None.\n        Frequencies of angles\n\n    lb: float\n        Lower bound of circular mean from `descriptive.circ_mean_ci()`.\n\n    ub: float\n        Upper bound of circular mean from `descriptive.circ_mean_ci()`.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    reject: bool\n        Reject or not reject the null hypothesis.\n\n    Reference\n    ---------\n    P628, Section 27.1, Example 27.3 of Zar, 2010\n    \"\"\"\n\n    if lb is None or ub is None:\n        assert isinstance(alpha, np.ndarray), (\n            \"If `ub` or `lb` is None, then `alpha` (and `w`) is needed.\"\n        )\n        if w is None:\n            w = np.ones_like(alpha)\n        lb, ub = circ_mean_ci(alpha=alpha, w=w)\n\n    if lb &lt; angle &lt; ub:\n        reject = False  # not able reject null (mean angle == angle)\n    else:\n        reject = True  # reject null (mean angle == angle)\n\n    if verbose:\n        print(\"One-Sample Test for the Mean Angle\")\n        print(\"----------------------------------\")\n        print(\"H0: \u03bc = \u03bc0\")\n        print(f\"HA: \u03bc \u2260 \u03bc0 and \u03bc0 = {angle:.5f} rad\")\n        print(\"\")\n        if reject:\n            print(\n                f\"Reject H0:\\n\u03bc0 = {angle:.5f} lies outside the 95% CI of \u03bc ({np.array([lb, ub]).round(5)})\"\n            )\n        else:\n            print(\n                f\"Failed to reject H0:\\n\u03bc0 = {angle:.5f} lies within the 95% CI of \u03bc ({np.array([lb, ub]).round(5)})\"\n            )\n\n    return reject\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.omnibus_test","title":"<code>omnibus_test(alpha, scale=1, verbose=False)</code>","text":"<p>Hodges\u2013Ajne omnibus test for circular uniformity.</p> <ul> <li>H0: The population is uniformly distributed around the circle</li> <li>H1: The population is not uniformly distributed.</li> </ul> <p>This test is distribution-free and handles uni-, bi-, and multimodal alternatives.  The classical p-value involves factorials and overflows for large n.  We therefore compute it in log-space (<code>math.lgamma</code>) and exponentiate at the very end.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>scale</code> <code>int</code> <p>Scale factor for the number of lines to be tested.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>A</code> <code>float</code> <p>Test statistics</p> <code>pval</code> <code>float</code> <p>p-value.</p> Reference <p>P629-630, Section 27.2, Example 27.4 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def omnibus_test(\n    alpha: np.ndarray,\n    scale: int = 1,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Hodges\u2013Ajne omnibus test for circular uniformity.\n\n    - H0: The population is uniformly distributed around the circle\n    - H1: The population is not uniformly distributed.\n\n    This test is distribution-free and handles uni-, bi-, and multimodal\n    alternatives.  The classical p-value involves factorials and\n    overflows for large *n*.  We therefore compute it in log-space\n    (``math.lgamma``) and exponentiate at the very end.\n\n    Parameters\n    ----------\n    alpha: np.array or None\n        Angles in radian.\n\n    scale: int\n        Scale factor for the number of lines to be tested.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    A: float\n        Test statistics\n\n    pval: float\n        p-value.\n\n    Reference\n    ---------\n    P629-630, Section 27.2, Example 27.4 of Zar, 2010\n    \"\"\"\n\n    lines = np.linspace(0, np.pi, scale * 360)\n    n = len(alpha)\n\n    lines_rotated = np.round(angmod((lines[:, None] - alpha)), 5)\n\n    # # count number of points on the right half circle, excluding the boundaries\n    right = n - np.logical_and(\n        lines_rotated &gt; 0.0, lines_rotated &lt; np.round(np.pi, 5)\n    ).sum(1)\n    m = int(np.min(right))\n\n    # ------------------------------------------------------------------\n    # 2. p-value   \u2014\u2014\u2014  analytical formula and its log form\n    # ------------------------------------------------------------------\n    #     Classical (Zar 2010, eq. 27-4):\n    #\n    #         p  =  (n \u2212 2m) \u00b7 n! / [ m! \u00b7 (n \u2212 m)! \u00b7 2^(n\u22121) ]            \u2026(1)\n    #       # pval = (\n    #       #    (n - 2 * m)\n    #       #    * math.factorial(n)\n    #       #    / (math.factorial(m) * math.factorial(n - m))\n    #       #    / 2 ** (n - 1)\n    #       # ) # eq(27.7)\n\n    #     Taking natural logs and using  \u0393(k+1) = k!  with  log \u0393 = lgamma:\n    #\n    #         ln p  =  ln(n \u2212 2m)\n    #                 + lgamma(n + 1)\n    #                 \u2212 lgamma(m + 1)\n    #                 \u2212 lgamma(n \u2212 m + 1)\n    #                 \u2212 (n \u2212 1)\u00b7ln 2                                        \u2026(2)\n    #\n    #     Eq. (2) is numerically safe for very large n; we exponentiate at\n    #     the end, knowing the result may under-flow to 0.0 in double precision.\n    # ------------------------------------------------------------------\n\n    logp = (\n        math.log(n - 2*m)                     \n        + math.lgamma(n + 1)                 \n        - math.lgamma(m + 1)                  \n        - math.lgamma(n - m + 1)              \n        - (n - 1)*math.log(2.0)               \n    )\n    pval = np.exp(logp)\n\n    A = np.pi * np.sqrt(n) / (2 * (n - 2 * m))\n\n    if verbose:\n        print('Hodges-Ajne (\"omnibus\") Test for Uniformity')\n        print(\"-------------------------------------------\")\n        print(\"H0: uniform\")\n        print(\"HA: not unifrom\")\n        print(\"\")\n        print(f\"Test Statistics: {A:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n    return A, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.batschelet_test","title":"<code>batschelet_test(angle, alpha, verbose=False)</code>","text":"<p>Modified Hodges-Ajne Test for Uniformity versus a specified Angle (for ungrouped data).</p> <ul> <li>H0: The population is uniformly distributed around the circle.</li> <li>H1: The population is not uniformly distributed around the circle, but     is concentrated around a specified angle.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>Union[int, float]</code> <p>A specified angle.</p> required <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>pval</code> <code>float</code> <p>p-value</p> Reference <p>P630-631, Section 27.2, Example 27.5 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def batschelet_test(\n    angle: Union[int, float],\n    alpha: np.ndarray,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"Modified Hodges-Ajne Test for Uniformity versus a specified Angle\n    (for ungrouped data).\n\n    - H0: The population is uniformly distributed around the circle.\n    - H1: The population is not uniformly distributed around the circle, but\n        is concentrated around a specified angle.\n\n    Parameters\n    ----------\n    angle: np.array\n        A specified angle.\n\n    alpha: np.array or None\n        Angles in radian.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    pval: float\n        p-value\n\n    Reference\n    ---------\n    P630-631, Section 27.2, Example 27.5 of Zar, 2010\n    \"\"\"\n\n    from scipy.stats import binomtest\n\n    n = len(alpha)\n    angle_diff = np.round(angmod(((angle + 0.5 * np.pi) - alpha)), 5)\n    m = np.logical_and(angle_diff &gt; 0.0, angle_diff &lt; np.round(np.pi, 5)).sum()\n    C = n - m\n    pval = float(binomtest(C, n=n, p=0.5).pvalue)\n\n    if verbose:\n        print(\"Batschelet Test for Uniformity\")\n        print(\"------------------------------\")\n        print(\"H0: uniform\")\n        print(f\"HA: not unifrom but concentrated around \u03b8 = {angle:.5f} rad\")\n        print(\"\")\n        print(f\"Test Statistics: {C}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return C, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.symmetry_test","title":"<code>symmetry_test(alpha, median=None, verbose=False)</code>","text":"<p>Non-parametric test for symmetry around the median. Works by performing a Wilcoxon sign rank test on the differences to the median. Also known as Wilcoxon paired-sample test.</p> <ul> <li>H0: the population is symmetrical around the median</li> <li>HA: the population is not symmetrical around the median</li> </ul> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>median</code> <code>Optional[float]</code> <p>Median computed by <code>descriptive.median()</code>.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>test_statistic</code> <code>float</code> <p>Test statistic</p> <code>pval</code> <code>float</code> <p>p-value</p> Reference <p>P631-632, Section 27.3, Example 27.6 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def symmetry_test(\n    alpha: np.ndarray,\n    median: Optional[float] = None,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"Non-parametric test for symmetry around the median. Works by performing a\n    Wilcoxon sign rank test on the differences to the median. Also known as\n    Wilcoxon paired-sample test.\n\n    - H0: the population is symmetrical around the median\n    - HA: the population is not symmetrical around the median\n\n    Parameters\n    ----------\n    alpha: np.array\n        Angles in radian.\n\n    median: float or None.\n        Median computed by `descriptive.median()`.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    test_statistic: float\n        Test statistic\n    pval: float\n        p-value\n\n    Reference\n    ---------\n    P631-632, Section 27.3, Example 27.6 of Zar, 2010\n    \"\"\"\n\n    if median is None:\n        median = float(circ_median(alpha=alpha))\n\n    d = (alpha - median).round(5)\n\n    res = wilcoxon(d, alternative=\"two-sided\")\n    test_statistic = float(res.statistic)\n    pval = float(res.pvalue)\n\n    if verbose:\n        print(\"Symmetry Test\")\n        print(\"------------------------------\")\n        print(\"H0: symmetrical around median\")\n        print(\"HA: not symmetrical around median\")\n        print(\"\")\n        print(f\"Test Statistics: {test_statistic:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return test_statistic, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.watson_williams_test","title":"<code>watson_williams_test(circs, verbose=False)</code>","text":"<p>The Watson-Williams Test for multiple samples.</p> <ul> <li>H0: All samples are from populations with the same mean angle</li> <li>H1: All samples are not from populations with the same mean angle</li> </ul> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>list</code> <p>A list of Circular objects.</p> required <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>F</code> <code>float</code> <p>F value</p> <code>pval</code> <code>float</code> <p>p-value</p> Reference <p>P632-636, Section 27.4, Example 27.7/8 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def watson_williams_test(circs: list, verbose: bool = False) -&gt; tuple[float, float]:\n    \"\"\"The Watson-Williams Test for multiple samples.\n\n    - H0: All samples are from populations with the same mean angle\n    - H1: All samples are not from populations with the same mean angle\n\n    Parameters\n    ----------\n    circs: list (k, )\n        A list of Circular objects.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    F: float\n        F value\n\n    pval: float\n        p-value\n\n    Reference\n    ---------\n    P632-636, Section 27.4, Example 27.7/8 of Zar, 2010\n    \"\"\"\n\n    k = len(circs)\n    N = np.sum([circ.n for circ in circs])\n    rw = np.mean([circ.r for circ in circs]).astype(float)\n\n    K = 1 + 3 / 8 / circ_kappa(rw)\n\n    Rs = [circ.R for circ in circs]\n    R = N * circ_r(\n        alpha=np.hstack([circ.alpha for circ in circs]),\n        w=np.hstack([circ.w for circ in circs]),\n    )\n    F = K * (N - k) * (np.sum(Rs) - R) / (N - np.sum(Rs)) / (k - 1)\n    pval = float(f.sf(F, k - 1, N - k))\n\n    if verbose:\n        print(\"The Watson-Williams Test for multiple samples\")\n        print(\"---------------------------------------------\")\n        print(\"H0: all samples are from populations with the same angle.\")\n        print(\"HA: all samples are not from populations with the same angle.\")\n        print(\"\")\n        print(f\"Test Statistics: {F:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return F, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.watson_u2_test","title":"<code>watson_u2_test(circs, verbose=False)</code>","text":"<p>Watson's U2 Test for nonparametric two-sample testing (with or without ties).</p> <ul> <li>H0: The two samples came from the same population,     or from two populations having the same direction.</li> <li>H1: The two samples did not come from the same population,     or from two populations having the same directions.</li> </ul> <p>Use this instead of Watson-Williams two-sample test when at least one of the sampled populations is not unimodal or when there are other considerable departures from the assumptions of the latter test. It may be used on grouped data if the grouping interval is no greater than 5 degree.</p> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>list</code> <p>A list of Circular objects.</p> required <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>U2</code> <code>float</code> <p>U2 value</p> <code>pval</code> <code>float</code> <p>p value</p> Reference <p>P637-638, Section 27.5, Example 27.9 of Zar, 2010 P639-640, Section 27.5, Example 27.10 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def watson_u2_test(circs: list, verbose: bool = False) -&gt; tuple[float, float]:\n    \"\"\"Watson's U2 Test for nonparametric two-sample testing\n    (with or without ties).\n\n    - H0: The two samples came from the same population,\n        or from two populations having the same direction.\n    - H1: The two samples did not come from the same population,\n        or from two populations having the same directions.\n\n    Use this instead of Watson-Williams two-sample test when at\n    least one of the sampled populations is not unimodal or when\n    there are other considerable departures from the assumptions\n    of the latter test. It may be used on grouped data if the\n    grouping interval is no greater than 5 degree.\n\n    Parameters\n    ----------\n    circs: list\n        A list of Circular objects.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    U2: float\n        U2 value\n    pval: float\n        p value\n\n    Reference\n    ---------\n    P637-638, Section 27.5, Example 27.9 of Zar, 2010\n    P639-640, Section 27.5, Example 27.10 of Zar, 2010\n    \"\"\"\n\n    from scipy.stats import rankdata\n\n    def cumfreq(alpha, circ):\n        indices = np.squeeze(\n            [np.where(alpha == a)[0] for a in np.repeat(circ.alpha, circ.w)]\n        )\n        indices = np.hstack([0, indices, len(alpha)])\n        freq_cumsum = rankdata(np.repeat(circ.alpha, circ.w), method=\"max\") / circ.n\n        freq_cumsum = np.hstack([0, freq_cumsum])\n\n        tiles = np.diff(indices)\n        cf = np.repeat(freq_cumsum, tiles)\n\n        return cf\n\n    a, t = np.unique(\n        np.hstack([np.repeat(c.alpha, c.w) for c in circs]), return_counts=True\n    )\n    cfs = [cumfreq(a, c) for c in circs]\n    d = np.diff(cfs, axis=0)\n\n    N = np.sum([c.n for c in circs])\n    U2 = (\n        np.prod([c.n for c in circs])\n        / N**2\n        * (np.sum(t * d**2) - np.sum(t * d) ** 2 / N)\n    )\n    pval = 2 * np.exp(-19.74 * U2)\n    # Approximated P-value from Watson (1961)\n    # https://github.com/pierremegevand/watsons_u2/blob/master/watsons_U2_approx_p.m\n\n    if verbose:\n        print(\"Watson's U2 Test for two samples\")\n        print(\"---------------------------------------------\")\n        print(\"H0: The two samples are from populations with the same angle.\")\n        print(\"HA: The two samples are not from populations with the same angle.\")\n        print(\"\")\n        print(f\"Test Statistics: {U2:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return U2, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.wheeler_watson_test","title":"<code>wheeler_watson_test(circs, verbose=False)</code>","text":"<p>The Wheeler and Watson Two/Multi-Sample Test.</p> <ul> <li>H0: The two samples came from the same population,     or from two populations having the same direction.</li> <li>H1: The two samples did not come from the same population,     or not from two populations having the same directions.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>list</code> <p>A list of Circular objects.</p> required <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>W</code> <code>float</code> <p>W value</p> <code>pval</code> <code>float</code> <p>p value</p> Reference <p>P640-642, Section 27.5, Example 27.11 of Zar, 2010</p> Note <p>The current implementation doesn't consider ties in the data. Can be improved with P144, Pewsey et al. (2013)</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def wheeler_watson_test(circs: list, verbose: bool = False) -&gt; tuple[float, float]:\n    \"\"\"The Wheeler and Watson Two/Multi-Sample Test.\n\n    - H0: The two samples came from the same population,\n        or from two populations having the same direction.\n    - H1: The two samples did not come from the same population,\n        or not from two populations having the same directions.\n\n    Parameters\n    ----------\n    circs: list\n        A list of Circular objects.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    W: float\n        W value\n    pval: float\n        p value\n\n    Reference\n    ---------\n    P640-642, Section 27.5, Example 27.11 of Zar, 2010\n\n    Note\n    ----\n    The current implementation doesn't consider ties in the data.\n    Can be improved with P144, Pewsey et al. (2013)\n    \"\"\"\n    from scipy.stats import chi2\n\n    def get_circrank(alpha, circ, N):\n        rank_of_direction = (\n            np.squeeze([np.where(alpha == a)[0] for a in np.repeat(circ.alpha, circ.w)])\n            + 1\n        )\n        circ_rank = 2 * np.pi / N * rank_of_direction\n        return circ_rank\n\n    N = np.sum([c.n for c in circs])\n    a, _ = np.unique(\n        np.hstack([np.repeat(c.alpha, c.w) for c in circs]), return_counts=True\n    )\n\n    circ_ranks = [get_circrank(a, c, N) for c in circs]\n\n    k = len(circ_ranks)\n\n    if k == 2:\n        C = np.sum(np.cos(circ_ranks[0]))\n        S = np.sum(np.sin(circ_ranks[0]))\n        W = 2 * (N - 1) * (C**2 + S**2) / np.prod([c.n for c in circs])\n\n    elif k &gt; 3:\n        W = 0\n        for i in range(k):\n            circ_rank = circ_ranks[i]\n            C = np.sum(np.cos(circ_rank))\n            S = np.sum(np.sin(circ_rank))\n            W += (C**2 + S**2) / circs[i].n\n        W *= 2\n\n    pval = float(chi2.sf(W, df=2 * (k - 1)))\n\n    if verbose:\n        print(\"The Wheeler and Watson Two/Multi-Sample Test\")\n        print(\"---------------------------------------------\")\n        print(\"H0: All samples are from populations with the same angle.\")\n        print(\"HA: All samples are not from populations with the same angle.\")\n        print(\"\")\n        print(f\"Test Statistics: {W:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return W, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.wallraff_test","title":"<code>wallraff_test(circs, angle=float, verbose=False)</code>","text":"<p>Wallraff test of angular distances / dispersion against a specified angle.</p> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>list</code> <p>A list of circular object</p> required <code>angle</code> <p>A specified angle in radian.</p> <code>float</code> <code>verbose</code> <code>bool</code> <p>Print formatted results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>U</code> <code>float</code> <p>Test Statistics</p> <code>pval</code> <code>float</code> <p>P-value.</p> Reference <p>P637-638, Section 27.8, Example 27.13 of Zar, 2010</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def wallraff_test(\n    circs: list, angle=float, verbose: bool = False\n) -&gt; tuple[float, float]:\n    \"\"\"Wallraff test of angular distances / dispersion against a specified angle.\n\n    Parameters\n    ----------\n    circs: list\n        A list of circular object\n\n    angle: float\n        A specified angle in radian.\n\n    verbose: bool\n        Print formatted results.\n\n    Returns\n    -------\n    U: float\n        Test Statistics\n\n    pval: float\n        P-value.\n\n    Reference\n    ---------\n    P637-638, Section 27.8, Example 27.13 of Zar, 2010\n    \"\"\"\n\n    if len(circs) != 2:\n        raise ValueError(\"Current implementation only supports two-sample comparision.\")\n\n    angles = np.ones_like(circs) * angle\n\n    ns = [c.n for c in circs]\n    ad = [angular_distance(a=c.alpha, b=angles[i]) for (i, c) in enumerate(circs)]\n\n    rs = rankdata(np.hstack(ad))\n\n    N = np.sum(ns)\n\n    # mann-whitney\n    R1 = np.sum(rs[: ns[0]])\n    U1 = np.prod(ns) + ns[0] * (ns[0] + 1) / 2 - R1\n    U2 = np.prod(ns) - U1\n    U = np.min([U1, U2])\n\n    z = (U - np.prod(ns) / 2 + 0.5) / np.sqrt(np.prod(ns) * (N + 1) / 12)\n    pval = float(2 * norm.cdf(z))\n\n    if verbose:\n        print(\"Wallraff test of angular distances / dispersion\")\n        print(\"-----------------------------------------------\")\n        print(\"\")\n        print(f\"Test Statistics: {U:.5f}\")\n        print(f\"P-value: {pval:.5f} {significance_code(pval)}\")\n\n    return U, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.circ_anova","title":"<code>circ_anova(samples, method='F-test', kappa=None, f_mod=True, verbose=False)</code>","text":"<p>Circular Analysis of Variance (ANOVA) for multi-sample comparison of mean directions.</p> <ul> <li>H\u2080: All groups have the same mean direction.</li> <li>H\u2081: At least one group has a different mean direction.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>list of np.ndarray</code> <p>List of arrays, where each array contains circular data (angles in radians) for a group.</p> required <code>method</code> <code>str</code> <p>The test statistic to use. Options: - <code>\"F-test\"</code> (default): High-concentration F-test (Stephens 1972). - <code>\"LRT\"</code>: Likelihood Ratio Test (Cordeiro et al. 1994).</p> <code>'F-test'</code> <code>kappa</code> <code>float</code> <p>The common concentration parameter (\u03ba). If not specified, it is estimated using MLE.</p> <code>None</code> <code>f_mod</code> <code>bool</code> <p>If <code>True</code>, applies a correction factor <code>(1 + 3/8\u03ba)</code> to the F-statistic.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, prints the test summary.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>A dictionary with: - <code>'method'</code>: <code>\"F-test\"</code> or <code>\"LRT\"</code> - <code>'mu'</code>: Mean directions of each group (radians) - <code>'mu_all'</code>: Mean direction of all samples combined - <code>'kappa'</code>: Estimated concentration parameters for each group - <code>'kappa_all'</code>: Estimated concentration parameter for all samples combined - <code>'rho'</code>: Resultant vector lengths for each group - <code>'rho_all'</code>: Resultant vector length for all samples combined - <code>'df'</code>: Degrees of freedom - <code>'statistic'</code>: Test statistic (F-value or Chi-Square) - <code>'p_value'</code>: p-value - <code>'SS'</code>: Sum of squares (for F-test) - <code>'MS'</code>: Mean squares (for F-test)</p> References <ul> <li>Stephens (1972). Multi-sample tests for the von Mises distribution.</li> <li>Cordeiro, Paula, &amp; Botter (1994). Improved likelihood ratio tests for dispersion models.</li> <li>Jammalamadaka &amp; SenGupta (2001). Topics in Circular Statistics, Section 5.3.</li> </ul> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def circ_anova(\n    samples: list[np.ndarray],\n    method: str = \"F-test\",\n    kappa: Optional[float] = None,\n    f_mod: bool = True,\n    verbose: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Circular Analysis of Variance (ANOVA) for multi-sample comparison of mean directions.\n\n    - **H\u2080**: All groups have the same mean direction.\n    - **H\u2081**: At least one group has a different mean direction.\n\n    Parameters\n    ----------\n    samples : list of np.ndarray\n        List of arrays, where each array contains circular data (angles in radians) for a group.\n    method : str, optional\n        The test statistic to use. Options:\n        - `\"F-test\"` (default): High-concentration F-test (Stephens 1972).\n        - `\"LRT\"`: Likelihood Ratio Test (Cordeiro et al. 1994).\n    kappa : float, optional\n        The common concentration parameter (\u03ba). If not specified, it is estimated using MLE.\n    f_mod : bool, optional\n        If `True`, applies a correction factor `(1 + 3/8\u03ba)` to the F-statistic.\n    verbose : bool, optional\n        If `True`, prints the test summary.\n\n    Returns\n    -------\n    result : dict\n        A dictionary with:\n        - `'method'`: `\"F-test\"` or `\"LRT\"`\n        - `'mu'`: Mean directions of each group (radians)\n        - `'mu_all'`: Mean direction of all samples combined\n        - `'kappa'`: Estimated concentration parameters for each group\n        - `'kappa_all'`: Estimated concentration parameter for all samples combined\n        - `'rho'`: Resultant vector lengths for each group\n        - `'rho_all'`: Resultant vector length for all samples combined\n        - `'df'`: Degrees of freedom\n        - `'statistic'`: Test statistic (F-value or Chi-Square)\n        - `'p_value'`: p-value\n        - `'SS'`: Sum of squares (for F-test)\n        - `'MS'`: Mean squares (for F-test)\n\n    References\n    ----------\n    - Stephens (1972). Multi-sample tests for the von Mises distribution.\n    - Cordeiro, Paula, &amp; Botter (1994). Improved likelihood ratio tests for dispersion models.\n    - Jammalamadaka &amp; SenGupta (2001). Topics in Circular Statistics, Section 5.3.\n    \"\"\"\n\n    # Number of groups\n    k = len(samples)\n    if k &lt; 2:\n        raise ValueError(\"At least two groups are required for ANOVA.\")\n\n    # Sample sizes, mean directions, and resultants\n    ns = np.array([len(group) for group in samples])\n    Rs = np.array(\n        [circ_r(group) * len(group) for group in samples]\n    )  # Sum of resultant vectors\n    mus = np.array([circ_mean(group) for group in samples])  # Mean directions\n\n    # Overall resultant and mean direction\n    all_samples = np.hstack(samples)\n    N = len(all_samples)\n    R_all = circ_r(all_samples) * N\n    mu_all = circ_mean(all_samples)\n\n    # Estimate \u03ba if not provided\n    if kappa is None:\n        kappa = circ_kappa(R_all / N)\n\n    # **F-test**\n    if method == \"F-test\":\n        # Between-group and within-group sum of squares\n        SS_between = np.sum(Rs) - R_all\n        SS_within = N - np.sum(Rs)\n        SS_total = N - R_all\n\n        df_between = k - 1\n        df_within = N - k\n        df_total = N - 1\n\n        MS_between = SS_between / df_between\n        MS_within = SS_within / df_within\n\n        # Apply correction factor (Stephens 1972)\n        if f_mod:\n            F_stat = (1 + 3 / (8 * kappa)) * (MS_between / MS_within)\n        else:\n            F_stat = MS_between / MS_within\n\n        p_value = 1 - f.cdf(F_stat, df_between, df_within)\n\n        result = {\n            \"method\": \"F-test\",\n            \"mu\": mus,\n            \"mu_all\": mu_all,\n            \"kappa\": kappa,\n            \"kappa_all\": kappa,\n            \"rho\": Rs,\n            \"rho_all\": R_all,\n            \"df\": (df_between, df_within, df_total),\n            \"statistic\": F_stat,\n            \"p_value\": p_value,\n            \"SS\": (SS_between, SS_within, SS_total),\n            \"MS\": (MS_between, MS_within),\n        }\n\n    # **Likelihood Ratio Test (LRT)**\n    elif method == \"LRT\":\n        # Compute test statistic\n        term1 = 1 - (1 / (4 * kappa)) * (sum(1 / ns) - 1 / N)\n        term2 = 2 * kappa * np.sum(Rs * (1 - np.cos(mus - mu_all)))\n        chi_square_stat = term1 * term2\n\n        df = k - 1\n        p_value = 1 - chi2.cdf(chi_square_stat, df)\n\n        result = {\n            \"method\": \"LRT\",\n            \"mu\": mus,\n            \"mu_all\": mu_all,\n            \"kappa\": kappa,\n            \"kappa_all\": kappa,\n            \"rho\": Rs,\n            \"rho_all\": R_all,\n            \"df\": df,\n            \"statistic\": chi_square_stat,\n            \"p_value\": p_value,\n        }\n\n    else:\n        raise ValueError(\"Invalid method. Choose 'F-test' or 'LRT'.\")\n\n    # Print results if verbose is enabled\n    if verbose:\n        print(\"\\nCircular Analysis of Variance (ANOVA)\")\n        print(\"--------------------------------------\")\n        print(f\"Method: {result['method']}\")\n        print(f\"Mean Directions (radians): {result['mu']}\")\n        print(f\"Overall Mean Direction (radians): {result['mu_all']}\")\n        print(f\"Kappa: {result['kappa']}\")\n        print(f\"Kappa (overall): {result['kappa_all']}\")\n        print(f\"Degrees of Freedom: {result['df']}\")\n        print(f\"Test Statistic: {result['statistic']:.5f}\")\n        print(f\"P-value: {result['p_value']:.5f}\")\n        if method == \"F-test\":\n            print(f\"Sum of Squares (Between, Within, Total): {result['SS']}\")\n            print(f\"Mean Squares (Between, Within): {result['MS']}\")\n        print(\"--------------------------------------\\n\")\n\n    return result\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.angular_randomisation_test","title":"<code>angular_randomisation_test(circs, n_simulation=1000, verbose=False)</code>","text":"<p>The Angular Randomization Test (ART) for homogeneity.</p> <ul> <li>H0: The two samples come from the same population.</li> <li>H1: The two samples do not come from the same population.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>circs</code> <code>list</code> <p>A list of Circular objects.</p> required <code>n_simulation</code> <code>int</code> <p>Number of permutations for the test. Defaults to 1000.</p> <code>1000</code> <p>Returns:</p> Name Type Description <code>T_obs</code> <code>float</code> <p>Observed value of the ART test statistic.</p> <code>p_value</code> <code>float</code> <p>p-value of the test.</p> Reference <p>Jebur, A. J., &amp; Abushilah, S. F. (2022). Distribution-free two-sample homogeneity test for circular data based on geodesic distance. International Journal of Nonlinear Analysis and Applications, 13(1), 2703-2711.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def angular_randomisation_test(\n    circs: list,\n    n_simulation: int = 1000,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"The Angular Randomization Test (ART) for homogeneity.\n\n    - H0: The two samples come from the same population.\n    - H1: The two samples do not come from the same population.\n\n    Parameters\n    ----------\n    circs: list\n        A list of Circular objects.\n    n_simulation: int, optional\n        Number of permutations for the test. Defaults to 1000.\n\n    Returns\n    -------\n    T_obs: float\n        Observed value of the ART test statistic.\n    p_value: float\n        p-value of the test.\n\n    Reference\n    ---------\n    Jebur, A. J., &amp; Abushilah, S. F. (2022).\n    Distribution-free two-sample homogeneity test for circular data based on geodesic distance.\n    International Journal of Nonlinear Analysis and Applications, 13(1), 2703-2711.\n    \"\"\"\n\n    def art_statistic(S1: np.ndarray, S2: np.ndarray) -&gt; float:\n        \"\"\"\n        Compute the Angular Randomisation Test (ART) statistic for two groups of circular data.\n        Following equations (3.1) and (4.2) from Jebur &amp; Abushilah (2022) .\n\n        Args:\n            S1 (np.ndarray): First group of angles in radians (\u03c6 values)\n            S2 (np.ndarray): Second group of angles in radians (\u03c8 values)\n\n        Returns:\n            float: The ART test statistic\n        \"\"\"\n        n = len(S1)\n        m = len(S2)\n\n        # Compute the scaling factor ((n+m)/(nm))^(-1/2)\n        scaling_factor = np.sqrt(n * m / (n + m))\n\n        # Compute sum of all pairwise geodesic distances\n        total_distance = circ_pairdist(S1, S2, metric=\"geodesic\", return_sum=True)\n\n        # Scale the total distance and return\n        return scaling_factor * total_distance\n\n    # number of samples\n    k = len(circs)\n    if k != 2:\n        raise ValueError(\"The Angular Randomization Test requires exactly two samples.\")\n\n    # 1. Compute observed test statistic T*\u2080\n    observed_stat = art_statistic(circs[0].alpha, circs[1].alpha)\n\n    # Initialize counter for permutations more extreme than observed\n    n_extreme = 1  # Start at 1 to count the observed statistic\n\n    # Combine samples for permutation\n    combined_data = np.concatenate([circs[0].alpha, circs[1].alpha])\n    n1 = len(circs[0].alpha)\n\n    # Perform permutation test\n\n    for _ in range(n_simulation):\n        # Randomly permute the combined data\n        permuted_data = np.random.permutation(combined_data)\n\n        # Split into two groups of original sizes\n        perm_S1 = permuted_data[:n1]\n        perm_S2 = permuted_data[n1:]\n\n        # Compute test statistic for this permutation\n        perm_stat = art_statistic(perm_S1, perm_S2)\n\n        # Count if permuted statistic is &gt;= observed (one-sided test)\n        if perm_stat &gt;= observed_stat:\n            n_extreme += 1\n\n    # Compute p-value as in equation (4.3)\n    p_value = n_extreme / (n_simulation + 1)\n\n    if verbose:\n        print(\"Angular Randomization Test (ART) for Homogeneity\")\n        print(\"-------------------------------------------------\")\n        print(\"H0: The two samples come from the same population.\")\n        print(\"HA: The two samples do not come from the same population.\")\n        print(\"\")\n        print(f\"Observed Test Statistic: {observed_stat:.5f}\")\n        print(f\"P-value: {p_value:.5f} {significance_code(p_value)}\")\n\n    return observed_stat, p_value\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.kuiper_test","title":"<code>kuiper_test(alpha, n_simulation=9999, seed=2046, verbose=False)</code>","text":"<p>Kuiper's test for Circular Uniformity.</p> <ul> <li>H0: The data in the population are distributed uniformly around the circle.</li> <li>H1: THe data in the population are not disbutrited uniformly around the circle.</li> </ul> <p>This method is for ungrouped data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>n_simulation</code> <code>int</code> <p>Number of simulation for the p-value. If n_simulation=1, the p-value is asymptotically approximated. If n_simulation&gt;1, the p-value is simulated. Default is 9999.</p> <code>9999</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>2046</code> <p>Returns:</p> Name Type Description <code>V</code> <code>float</code> <p>Test Statistics</p> <code>pval</code> <code>flaot</code> <p>Asymptotic p-value</p> Note <p>Implementation from R package <code>Directional</code> https://rdrr.io/cran/Directional/src/R/kuiper.R</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def kuiper_test(\n    alpha: np.ndarray,\n    n_simulation: int = 9999,\n    seed: int = 2046,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Kuiper's test for Circular Uniformity.\n\n    - H0: The data in the population are distributed uniformly around the circle.\n    - H1: THe data in the population are not disbutrited uniformly around the circle.\n\n    This method is for ungrouped data.\n\n    Parameters\n    ----------\n\n    alpha: np.array\n        Angles in radian.\n\n    n_simulation: int\n        Number of simulation for the p-value.\n        If n_simulation=1, the p-value is asymptotically approximated.\n        If n_simulation&gt;1, the p-value is simulated.\n        Default is 9999.\n\n    seed: int\n        Random seed.\n\n    Returns\n    -------\n    V: float\n        Test Statistics\n    pval: flaot\n        Asymptotic p-value\n\n    Note\n    ----\n    Implementation from R package `Directional`\n    https://rdrr.io/cran/Directional/src/R/kuiper.R\n    \"\"\"\n\n    def compute_V(alpha):\n        alpha = np.sort(alpha) / (2 * np.pi)  #\n        n = len(alpha)\n        i = np.arange(1, n + 1)\n\n        D_plus = np.max(i / n - alpha)\n        D_minus = np.max(alpha - (i - 1) / n)\n        f = np.sqrt(n) + 0.155 + 0.24 / np.sqrt(n)\n        V = f * (D_plus + D_minus)\n        return V, f\n\n    n = n = len(alpha)\n    Vo, f = compute_V(alpha)\n\n    if n_simulation == 1:\n        # asymptotic p-value\n        m = np.arange(1, 50) ** 2\n        a1 = 4 * m * Vo**2\n        a2 = np.exp(-2 * m * Vo**2)\n        b1 = 2 * (a1 - 1) * a2\n        b2 = 8 * Vo / (3 * f) * m * (a1 - 3) * a2\n        pval = np.sum(b1 - b2)\n    else:\n        np.random.seed(seed)\n        x = np.sort(np.random.uniform(low=0, high=2 * np.pi, size=[n, n_simulation]), 0)\n        Vs = np.array(([compute_V(x[:, i])[0] for i in range(n_simulation)]))\n        pval = (np.sum(Vs &gt; Vo) + 1) / (n_simulation + 1)\n\n    if verbose:\n        print(\"Kuiper's Test of Circular Uniformity\")\n        print(\"------------------------------------\")\n        print(\"\")\n        print(f\"Test Statistic: {Vo:.4f}\")\n        print(f\"P-value = {pval} {significance_code(pval)}\")\n\n    return Vo, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.watson_test","title":"<code>watson_test(alpha, n_simulation=9999, seed=2046, verbose=False)</code>","text":"<p>Watson's Goodness-of-Fit Testing, aka Watson one-sample U2 test.</p> <ul> <li>H0: The sample data come from a population distributed uniformly around the circle.</li> <li>H1: The sample data do not come from a population distributed uniformly around the circle.</li> </ul> <p>This method is for ungrouped data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>n_simulation</code> <code>int</code> <p>Number of simulation for the p-value. If n_simulation=1, the p-value is asymptotically approximated. If n_simulation&gt;1, the p-value is simulated.</p> <code>9999</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>2046</code> <p>Returns:</p> Name Type Description <code>U2o</code> <code>float</code> <p>Test Statistics</p> <code>pval</code> <code>flaot</code> <p>Asymptotic p-value</p> Note <p>Implementation from R package <code>Directional</code> https://rdrr.io/cran/Directional/src/R/watson.R</p> <p>The code for simulated p-value in Directional (v5.7) seems to be just copied from kuiper(), thus yield in wrong results.</p> See Also <p>kuiper_test(); rao_spacing_test()</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def watson_test(\n    alpha: np.ndarray,\n    n_simulation: int = 9999,\n    seed: int = 2046,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Watson's Goodness-of-Fit Testing, aka Watson one-sample U2 test.\n\n    - H0: The sample data come from a population distributed uniformly around the circle.\n    - H1: The sample data do not come from a population distributed uniformly around the circle.\n\n    This method is for ungrouped data.\n\n    Parameters\n    ----------\n\n    alpha: np.array\n        Angles in radian.\n\n    n_simulation: int\n        Number of simulation for the p-value.\n        If n_simulation=1, the p-value is asymptotically approximated.\n        If n_simulation&gt;1, the p-value is simulated.\n\n    seed: int\n        Random seed.\n\n    Returns\n    -------\n    U2o: float\n        Test Statistics\n    pval: flaot\n        Asymptotic p-value\n\n    Note\n    ----\n    Implementation from R package `Directional`\n    https://rdrr.io/cran/Directional/src/R/watson.R\n\n    The code for simulated p-value in Directional (v5.7) seems to be just copied from\n    kuiper(), thus yield in wrong results.\n\n    See Also\n    --------\n    kuiper_test(); rao_spacing_test()\n    \"\"\"\n\n    def compute_U2(alpha):\n        alpha = np.sort(alpha)\n        n = len(alpha)\n        i = np.arange(1, n + 1)\n\n        u = alpha / 2 / np.pi\n        # u2 = u**2\n        # iu = i * u\n\n        U2 = np.sum(((u - (i - 0.5) / n) - (np.sum(u) / n - 0.5)) ** 2) + 1 / (12 * n)\n        return U2\n\n    n = len(alpha)\n    U2o = float(compute_U2(alpha))\n\n    if n_simulation == 1:\n        m = np.arange(1, 51)\n        pval = float(2 * sum((-1) ** (m - 1) * np.exp(-2 * m**2 * np.pi**2 * U2o)))\n    else:\n        np.random.seed(seed)\n        x = np.sort(np.random.uniform(low=0, high=2 * np.pi, size=[n, n_simulation]), 0)\n        U2s = np.array(([compute_U2(x[:, i]) for i in range(n_simulation)]))\n        pval = float((np.sum(U2s &gt; U2o) + 1) / (n_simulation + 1))\n\n    if verbose:\n        print(\"Watson's One-Sample U2 Test of Circular Uniformity\")\n        print(\"--------------------------------------------------\")\n        print(\"\")\n        print(f\"Test Statistic: {U2o:.4f}\")\n        print(f\"P-value = {pval} {significance_code(pval)}\")\n\n    return U2o, pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.rao_spacing_test","title":"<code>rao_spacing_test(alpha, w=None, kappa=1000.0, n_simulation=9999, seed=2046, verbose=False)</code>","text":"<p>Simulation based Rao's spacing test.</p> <ul> <li>H0: The sample data come from a population distributed uniformly around the circle.</li> <li>H1: The sample data do not come from a population distributed uniformly around the circle.</li> </ul> <p>This method is for both grouped and ungrouped data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radian.</p> required <code>w</code> <code>Union[ndarray, None]</code> <p>Frequencies</p> <code>None</code> <code>kappa</code> <code>float</code> <p>Concentration parameter. Only use for grouped data.</p> <code>1000.0</code> <code>n_simulation</code> <code>int</code> <p>Number of simulations.</p> <code>9999</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>2046</code> <p>Returns:</p> Name Type Description <code>Uo</code> <code>float</code> <p>Test statistics</p> <code>pval</code> <code>float</code> <p>Simulation-based p-value</p> Reference <p>Landler et al. (2019) https://movementecologyjournal.biomedcentral.com/articles/10.1186/s40462-019-0160-x</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def rao_spacing_test(\n    alpha: np.ndarray,\n    w: Union[np.ndarray, None] = None,\n    kappa: float = 1000.0,\n    n_simulation: int = 9999,\n    seed: int = 2046,\n    verbose: bool = False,\n) -&gt; tuple[float, float]:\n    \"\"\"Simulation based Rao's spacing test.\n\n    - H0: The sample data come from a population distributed uniformly around the circle.\n    - H1: The sample data do not come from a population distributed uniformly around the circle.\n\n    This method is for both grouped and ungrouped data.\n\n    Parameters\n    ----------\n    alpha: np.ndarray\n        Angles in radian.\n\n    w: np.ndarray or None\n        Frequencies\n\n    kappa: float\n        Concentration parameter. Only use for grouped data.\n\n    n_simulation: int\n        Number of simulations.\n\n    seed: int\n        Random seed.\n\n    Returns\n    -------\n    Uo: float\n        Test statistics\n\n    pval: float\n        Simulation-based p-value\n\n    Reference\n    ---------\n    Landler et al. (2019)\n    https://movementecologyjournal.biomedcentral.com/articles/10.1186/s40462-019-0160-x\n    \"\"\"\n\n    def compute_U(alpha):\n        n = len(alpha)\n        f = np.sort(alpha)\n        T = np.hstack([f[1:] - f[:-1], 2 * np.pi - f[-1] + f[0]])\n        U = 0.5 * np.sum(np.abs(T - (2 * np.pi / n)))\n        return U\n\n    if w is not None:\n        n = np.sum(w)\n        m = len(alpha)\n        alpha = np.repeat(alpha, w)\n    else:\n        n = len(alpha)\n\n    # p-value\n    np.random.seed(seed)\n    Uo = compute_U(alpha)\n    if w is not None:  # noncontinous / grouped data\n        Us = np.array(\n            [\n                compute_U(\n                    angmod(\n                        np.floor(np.random.uniform(low=0, high=2 * np.pi, size=n))\n                        * m\n                        / (2 * np.pi)\n                        * 2\n                        * np.pi\n                        / m\n                        + vonmises(kappa=kappa).rvs(n)\n                    )\n                )\n                for i in range(n_simulation)\n            ]\n        )\n    else:  # continous / ungrouped data\n        Us = np.array(\n            [\n                compute_U(np.random.uniform(low=0, high=2 * np.pi, size=n))\n                for i in range(n_simulation)\n            ]\n        )\n\n    counter = np.sum(Us &gt; Uo)\n    pval = counter / (n_simulation + 1)\n\n    if verbose:\n        print(\"Rao's Spacing Test of Circular Uniformity\")\n        print(\"-----------------------------------------\")\n        print(\"\")\n        print(f\"Test Statistic: {Uo:.4f}\")\n        print(f\"P-value = {pval}\\n\")\n\n    return np.rad2deg(Uo), pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.circ_range_test","title":"<code>circ_range_test(alpha)</code>","text":"<p>Perform the Circular Range Test for uniformity.</p> <ul> <li>H0: The data is uniformly distributed around the circle.</li> <li>H1: The data is non-uniformly distributed (clustered).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in radians.</p> required <p>Returns:</p> Name Type Description <code>range_stat</code> <code>float</code> <p>The circular range test statistic.</p> <code>p_value</code> <code>float</code> <p>The p-value indicating significance of non-uniformity.</p> Reference <p>P162, Section 7.2.3 of Jammalamadaka, S. Rao and SenGupta, A. (2001)</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def circ_range_test(alpha: np.ndarray) -&gt; tuple[float, float]:\n    \"\"\"\n    Perform the Circular Range Test for uniformity.\n\n    - **H0**: The data is uniformly distributed around the circle.\n    - **H1**: The data is non-uniformly distributed (clustered).\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Angles in radians.\n\n    Returns\n    -------\n    range_stat : float\n        The circular range test statistic.\n    p_value : float\n        The p-value indicating significance of non-uniformity.\n\n    Reference\n    ---------\n    P162, Section 7.2.3 of Jammalamadaka, S. Rao and SenGupta, A. (2001)\n    \"\"\"\n    range_stat = circ_range(alpha)  # Compute test statistic\n\n    # Compute p-value using approximation formula from CircStats (if available)\n    n = len(alpha)\n    stop = int(np.floor(1 / (1 - range_stat / (2 * np.pi))))\n    index = np.arange(1, stop + 1)\n\n    # Compute p-value using series expansion\n    sequence = (\n        ((-1) ** (index - 1))\n        * comb(n, index)\n        * (1 - index * (1 - range_stat / (2 * np.pi))) ** (n - 1)\n    )\n    p_value = float(np.sum(sequence))\n\n    return range_stat, p_value\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.binomial_test","title":"<code>binomial_test(alpha, md)</code>","text":"<p>Perform the binomial test for the median direction of circular data.</p> <p>This test evaluates whether the population median angle is equal to a specified value.</p> <ul> <li>H0: The population has median angle <code>md</code>.</li> <li>H1: The population does not have median angle <code>md</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>md</code> <code>float</code> <p>Hypothesized median angle.</p> required <p>Returns:</p> Name Type Description <code>pval</code> <code>float</code> <p>p-value of the test (small values suggest rejecting H0).</p> References <p>Zar, J. H. (2010). Biostatistical Analysis. Section 27.4.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def binomial_test(alpha: np.ndarray, md: float) -&gt; float:\n    \"\"\"\n    Perform the binomial test for the median direction of circular data.\n\n    This test evaluates whether the population median angle is equal to a specified value.\n\n    - **H0**: The population has median angle `md`.\n    - **H1**: The population does not have median angle `md`.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of angles in radians.\n    md : float\n        Hypothesized median angle.\n\n    Returns\n    -------\n    pval : float\n        p-value of the test (small values suggest rejecting H0).\n\n    References\n    ----------\n    Zar, J. H. (2010). Biostatistical Analysis. Section 27.4.\n    \"\"\"\n    from scipy.stats import binom\n\n    alpha = np.asarray(alpha)\n\n    if np.ndim(md) != 0:\n        raise ValueError(\"The median (md) must be a single scalar value.\")\n\n    n = len(alpha)\n\n    # Compute circular differences from hypothesized median\n    d = circ_dist(alpha, md)\n\n    # Count the number of angles on each side of the hypothesized median\n    n1 = np.sum(d &lt; 0)\n    n2 = np.sum(d &gt; 0)\n\n    # Compute p-value using binomial test\n    n_min = min(n1, n2)\n    n_max = max(n1, n2)\n\n    # Binomial p-value\n    pval = float(binom.cdf(n_min, n, 0.5) + (1 - binom.cdf(n_max - 1, n, 0.5)))\n\n    return pval\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.concentration_test","title":"<code>concentration_test(alpha1, alpha2)</code>","text":"<p>Parametric two-sample test for concentration equality in circular data.</p> <p>This test determines whether two von Mises-type samples have different concentration parameters (i.e., different dispersions).</p> <ul> <li>H0: The two samples have the same concentration parameter.</li> <li>H1: The two samples have different concentration parameters.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>alpha1</code> <code>ndarray</code> <p>First sample of circular data (radians).</p> required <code>alpha2</code> <code>ndarray</code> <p>Second sample of circular data (radians).</p> required <p>Returns:</p> Name Type Description <code>f_stat</code> <code>float</code> <p>The F-statistic for the test.</p> <code>pval</code> <code>float</code> <p>The p-value indicating whether the samples have significantly different concentrations.</p> Notes <ul> <li>This test assumes that both samples follow von Mises distributions.</li> <li>The resultant vector length of the combined samples should be greater than 0.7 for validity.</li> <li>Based on Batschelet (1980), Section 6.9, p. 122-124.</li> </ul> References <p>Batschelet, E. (1980). Circular Statistics in Biology. Academic Press.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def concentration_test(alpha1: np.ndarray, alpha2: np.ndarray) -&gt; tuple[float, float]:\n    \"\"\"\n    Parametric two-sample test for concentration equality in circular data.\n\n    This test determines whether two von Mises-type samples have different\n    concentration parameters (i.e., different dispersions).\n\n    - **H0**: The two samples have the same concentration parameter.\n    - **H1**: The two samples have different concentration parameters.\n\n    Parameters\n    ----------\n    alpha1 : np.ndarray\n        First sample of circular data (radians).\n    alpha2 : np.ndarray\n        Second sample of circular data (radians).\n\n    Returns\n    -------\n    f_stat : float\n        The F-statistic for the test.\n    pval : float\n        The p-value indicating whether the samples have significantly different concentrations.\n\n    Notes\n    -----\n    - This test assumes that both samples follow von Mises distributions.\n    - The **resultant vector length** of the combined samples should be greater than 0.7 for validity.\n    - Based on Batschelet (1980), Section 6.9, p. 122-124.\n\n    References\n    ----------\n    Batschelet, E. (1980). Circular Statistics in Biology. Academic Press.\n    \"\"\"\n    # Ensure inputs are numpy arrays\n    alpha1, alpha2 = np.asarray(alpha1), np.asarray(alpha2)\n\n    # Sample sizes\n    n1, n2 = len(alpha1), len(alpha2)\n\n    # Compute resultant vector lengths\n    R1 = n1 * circ_r(alpha1)\n    R2 = n2 * circ_r(alpha2)\n\n    # Compute mean resultant length of combined samples\n    rbar = (R1 + R2) / (n1 + n2)\n\n    # Warn if rbar is too low\n    if rbar &lt; 0.7:\n        print(\"Warning: The resultant vector length should be &gt; 0.7 for valid results.\")\n\n    # Compute F-statistic\n    f_stat = ((n2 - 1) * (n1 - R1)) / ((n1 - 1) * (n2 - R2))\n\n    # Compute p-value (adjusting for F-stat symmetry)\n    if f_stat &gt; 1:\n        pval = 2 * (1 - f.cdf(f_stat, n1, n2))\n    else:\n        f_stat = 1 / f_stat\n        pval = 2 * (1 - f.cdf(f_stat, n2, n1))\n\n\n    return f_stat, float(pval)\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.rao_homogeneity_test","title":"<code>rao_homogeneity_test(samples, alpha=0.05)</code>","text":"<p>Perform Rao's test for homogeneity on multiple samples of angular data.</p> <ul> <li>Test 1: Equality of Mean Directions (Polar Vectors)</li> <li>Test 2: Equality of Dispersions</li> </ul> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>list of np.ndarray</code> <p>A list where each entry is a vector of angular values (in radians).</p> required <code>alpha</code> <code>float</code> <p>Significance level for the hypothesis test. Default is 0.05.</p> <code>0.05</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with test statistics and p-values for both tests.</p> References <p>Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, Section 7.6.1. Rao, J.S. (1967). Large sample tests for the homogeneity of angular data, Sankhya, Ser, B., 28.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def rao_homogeneity_test(samples: list, alpha: float = 0.05) -&gt; dict:\n    \"\"\"\n    Perform Rao's test for homogeneity on multiple samples of angular data.\n\n    - **Test 1**: Equality of Mean Directions (Polar Vectors)\n    - **Test 2**: Equality of Dispersions\n\n    Parameters\n    ----------\n    samples : list of np.ndarray\n        A list where each entry is a vector of angular values (in radians).\n    alpha : float, optional\n        Significance level for the hypothesis test. Default is 0.05.\n\n    Returns\n    -------\n    dict\n        A dictionary with test statistics and p-values for both tests.\n\n    References\n    ----------\n    Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, Section 7.6.1.\n    Rao, J.S. (1967). Large sample tests for the homogeneity of angular data, Sankhya, Ser, B., 28.\n    \"\"\"\n    if not isinstance(samples, list) or not all(\n        isinstance(s, np.ndarray) for s in samples\n    ):\n        raise ValueError(\"Input must be a list of numpy arrays.\")\n\n    k = len(samples)  # Number of samples\n    n = np.array([len(s) for s in samples])  # Sample sizes\n\n    # Compute mean cosine and sine values for each sample\n    cos_means = np.array([np.mean(np.cos(s)) for s in samples])\n    sin_means = np.array([np.mean(np.sin(s)) for s in samples])\n\n    # Compute variances\n    # Compute sample variances (use ddof=1 to match R)\n    var_cos = np.array([np.var(np.cos(s), ddof=1) for s in samples])\n    var_sin = np.array([np.var(np.sin(s), ddof=1) for s in samples])\n\n    # Compute covariance (use ddof=1 to match R's var(x, y))\n    cov_cos_sin = np.array(\n        [np.cov(np.cos(s), np.sin(s), ddof=1)[0, 1] for s in samples]\n    )\n\n    # Compute test statistics\n    s_polar = (\n        1\n        / n\n        * (\n            var_sin / cos_means**2\n            + (sin_means**2 * var_cos) / cos_means**4\n            - (2 * sin_means * cov_cos_sin) / cos_means**3\n        )\n    )\n    tan_means = sin_means / cos_means\n    H_polar = np.sum(tan_means**2 / s_polar) - (\n        np.sum(tan_means / s_polar) ** 2\n    ) / np.sum(1 / s_polar)\n\n    U = cos_means**2 + sin_means**2\n    s_disp = (\n        4\n        / n\n        * (\n            cos_means**2 * var_cos\n            + sin_means**2 * var_sin\n            + 2 * cos_means * sin_means * cov_cos_sin\n        )\n    )\n    H_disp = np.sum(U**2 / s_disp) - (np.sum(U / s_disp) ** 2) / np.sum(1 / s_disp)\n\n    # Compute p-values\n    df = k - 1  # Degrees of freedom\n    pval_polar = 1 - chi2.cdf(H_polar, df)\n    pval_disp = 1 - chi2.cdf(H_disp, df)\n\n    # Determine critical values\n    crit_polar = chi2.ppf(1 - alpha, df)\n    crit_disp = chi2.ppf(1 - alpha, df)\n\n    # Test decisions\n    reject_polar = H_polar &gt; crit_polar\n    reject_disp = H_disp &gt; crit_disp\n\n    return {\n        \"H_polar\": H_polar,\n        \"pval_polar\": pval_polar,\n        \"reject_polar\": reject_polar,\n        \"H_disp\": H_disp,\n        \"pval_disp\": pval_disp,\n        \"reject_disp\": reject_disp,\n    }\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.change_point_test","title":"<code>change_point_test(alpha)</code>","text":"<p>Perform a change point test for mean direction, concentration, or both.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Vector of angular measurements in radians.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing test statistics and estimated change point locations.</p> References <p>Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, Chapter 11.</p> Notes <p>Ported from <code>change.pt()</code> function in the <code>CircStats</code> package for R.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def change_point_test(alpha):\n    \"\"\"\n    Perform a change point test for mean direction, concentration, or both.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Vector of angular measurements in radians.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing test statistics and estimated change point locations.\n\n    References\n    ----------\n    Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, Chapter 11.\n\n    Notes\n    -----\n    Ported from `change.pt()` function in the `CircStats` package for R.\n    \"\"\"\n\n    def phi(x):\n        \"\"\"Helper function for phi computation.\"\"\"\n        arg = A1inv(x)\n        if i0(arg) != np.inf:\n            return x * A1inv(x) - np.log(i0(arg))\n        else:\n            return x * A1inv(x) - (\n                arg\n                + np.log(\n                    1\n                    / np.sqrt(2 * np.pi * arg)\n                    * (1 + 1 / (8 * arg) + 9 / (128 * arg**2) + 225 / (1024 * arg**3))\n                )\n            )\n\n    def est_rho(alpha):\n        \"\"\"Estimate mean resultant length (rho).\"\"\"\n        return np.linalg.norm(np.sum(np.exp(1j * alpha))) / len(alpha)\n\n    n = len(alpha)\n    if n &lt; 4:\n        raise ValueError(\"Sample size must be at least 4 for change point test.\")\n\n    rho = est_rho(alpha)\n\n    R1, R2, V = np.zeros(n), np.zeros(n), np.zeros(n)\n\n    for k in range(1, n):\n        R1[k - 1] = est_rho(alpha[:k]) * k\n        R2[k - 1] = est_rho(alpha[k:]) * (n - k)\n\n        if 2 &lt;= k &lt;= (n - 2):\n            V[k - 1] = (k / n) * phi(R1[k - 1] / k) + ((n - k) / n) * phi(\n                R2[k - 1] / (n - k)\n            )\n\n    R1[-1] = rho * n\n    R2[-1] = 0\n\n    R_diff = R1 + R2 - rho * n\n    rmax = np.max(R_diff)\n    k_r = np.argmax(R_diff)\n    rave = np.mean(R_diff)\n\n    if n &gt; 3:\n        V = V[1 : n - 2]\n        print(f\"V sliced: {V}\")\n        tmax = np.max(V)\n        k_t = np.argmax(V) + 1\n        tave = np.mean(V)\n    else:\n        raise ValueError(\"Sample size must be at least 4.\")\n\n    return pd.DataFrame(\n        {\n            \"n\": [n],\n            \"rho\": [rho],\n            \"rmax\": [rmax],\n            \"k.r\": [k_r],\n            \"rave\": [rave],\n            \"tmax\": [tmax],\n            \"k.t\": [k_t],\n            \"tave\": [tave],\n        }\n    )\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.harrison_kanji_test","title":"<code>harrison_kanji_test(alpha, idp, idq, inter=True, fn=None)</code>","text":"<p>Harrison-Kanji Test (Two-Way ANOVA) for Circular Data.</p> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def harrison_kanji_test(\n    alpha: np.ndarray,\n    idp: np.ndarray,\n    idq: np.ndarray,\n    inter: bool = True,\n    fn: Optional[list] = None,\n) -&gt; tuple[tuple[float, float, float], pd.DataFrame]:\n    \"\"\"\n    Harrison-Kanji Test (Two-Way ANOVA) for Circular Data.\n    \"\"\"\n\n    if fn is None:\n        fn = [\"A\", \"B\"]\n\n    # Ensure data is in column format\n    alpha = np.asarray(alpha).flatten()\n    idp = np.asarray(idp).flatten()\n    idq = np.asarray(idq).flatten()\n\n    # Number of factor levels\n    p = len(np.unique(idp))\n    q = len(np.unique(idq))\n\n    # Data frame for aggregation\n    df = pd.DataFrame({fn[0]: idp, fn[1]: idq, \"dependent\": alpha})\n    n = len(df)\n\n    # Total resultant vector length\n    tr = n * circ_r(np.array(df[\"dependent\"].values))\n    kk = circ_kappa(tr / n)\n\n    # Compute mean resultants per group\n    gr = df.groupby(fn)\n    cn = gr.count()\n    cr = gr.agg(circ_r) * cn\n    cn = cn.unstack(fn[1])\n    cr = cr.unstack(fn[1])\n\n    # Factor A\n    gr = df.groupby(fn[0])\n    pn = gr.count()[\"dependent\"]\n    pr = gr.agg(circ_r)[\"dependent\"] * pn\n\n    # Factor B\n    gr = df.groupby(fn[1])\n    qn = gr.count()[\"dependent\"]\n    qr = gr.agg(circ_r)[\"dependent\"] * qn\n\n    if kk &gt; 2:  # Large kappa approximation\n        eff_1 = sum(pr**2 / np.sum(cn, axis=1)) - tr**2 / n\n        df_1 = p - 1\n        ms_1 = eff_1 / df_1\n\n        eff_2 = sum(qr**2 / np.sum(cn, axis=0)) - tr**2 / n\n        df_2 = q - 1\n        ms_2 = eff_2 / df_2\n\n        eff_t = n - tr**2 / n\n        df_t = n - 1\n        m = np.asarray(cn.values).mean()\n\n        if inter:\n            beta = 1 / (1 - 1 / (5 * kk) - 1 / (10 * (kk**2)))\n\n            eff_r = n - np.asarray((cr**2.0 / cn).values).sum()\n            df_r = p * q * (m - 1)\n            ms_r = eff_r / df_r\n\n            eff_i = (\n                np.asarray((cr**2.0 / cn).values).sum()\n                - sum(qr**2.0 / qn)\n                - sum(pr**2.0 / pn)\n                + tr**2 / n\n            )\n            df_i = (p - 1) * (q - 1)\n            ms_i = eff_i / df_i\n\n            FI = ms_i / ms_r\n            pI = 1 - f.cdf(FI, df_i, df_r)  # `f.cdf` is now unambiguous\n        else:\n            eff_r = n - sum(qr**2.0 / qn) - sum(pr**2.0 / pn) + tr**2 / n\n            df_r = (p - 1) * (q - 1)\n            ms_r = eff_r / df_r\n\n            eff_i, df_i, ms_i, FI, pI = None, None, None, None, np.nan\n            beta = 1\n\n        F1 = beta * ms_1 / ms_r\n        p1 = 1 - f.cdf(F1, df_1, df_r)\n\n        F2 = beta * ms_2 / ms_r\n        p2 = 1 - f.cdf(F2, df_2, df_r)\n\n    else:  # Small kappa approximation\n        rr = iv(1, kk) / iv(0, kk)\n        kappa_factor = 2 / (1 - rr**2)  # Renamed `f` to `kappa_factor`\n\n        chi1 = kappa_factor * (sum(pr**2.0 / pn) - tr**2 / n)\n        df_1 = 2 * (p - 1)\n        p1 = 1 - chi2.cdf(chi1, df=df_1)\n\n        chi2_val = kappa_factor * (sum(qr**2.0 / qn) - tr**2 / n)\n        df_2 = 2 * (q - 1)\n        p2 = 1 - chi2.cdf(chi2_val, df=df_2)\n\n        chiI = kappa_factor * (\n            np.asarray((cr**2.0 / cn).values).sum()\n            - sum(pr**2.0 / pn)\n            - sum(qr**2.0 / qn)\n            + tr**2 / n\n        )\n        df_i = (p - 1) * (q - 1)\n        pI = chi2.sf(chiI, df=df_i)\n\n    pval = float(p1.squeeze()), float(p2.squeeze()), float(np.squeeze(pI))\n\n    # Construct ANOVA Table\n    if kk &gt; 2:\n        table = pd.DataFrame(\n            {\n                \"Source\": fn + [\"Interaction\", \"Residual\", \"Total\"],\n                \"DoF\": [df_1, df_2, df_i, df_r, df_t],\n                \"SS\": [eff_1, eff_2, eff_i, eff_r, eff_t],\n                \"MS\": [ms_1, ms_2, ms_i, ms_r, np.nan],\n                \"F\": [np.squeeze(F1), np.squeeze(F2), FI, np.nan, np.nan],\n                \"p\": list(pval) + [np.nan, np.nan],\n            }\n        ).set_index(\"Source\")\n    else:\n        table = pd.DataFrame(\n            {\n                \"Source\": fn + [\"Interaction\"],\n                \"DoF\": [df_1, df_2, df_i],\n                \"chi2\": [chi1.squeeze(), chi2_val.squeeze(), chiI.squeeze()],\n                \"p\": pval,\n            }\n        ).set_index(\"Source\")\n\n    return pval, table\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.equal_kappa_test","title":"<code>equal_kappa_test(samples, verbose=False)</code>","text":"<p>Test for Homogeneity of Concentration Parameters (\u03ba) in Circular Data.</p> <ul> <li>H\u2080: All groups have the same concentration parameter (\u03ba).</li> <li>H\u2081: At least one group has a different \u03ba.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>list of np.ndarray</code> <p>List of circular data arrays (angles in radians) for different groups.</p> required <code>verbose</code> <code>bool</code> <p>If <code>True</code>, prints the test summary.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>A dictionary containing: - <code>'kappa'</code>: Estimated concentration parameters for each group. - <code>'kappa_all'</code>: Estimated common \u03ba for all samples combined. - <code>'rho'</code>: Mean resultant lengths for each group. - <code>'rho_all'</code>: Mean resultant length for all samples combined. - <code>'df'</code>: Degrees of freedom. - <code>'statistic'</code>: Test statistic (Chi-Square). - <code>'p_value'</code>: p-value.</p> Notes <ul> <li>Uses different approximations based on mean resultant length (<code>r\u0304</code>):</li> <li>Small <code>r\u0304</code> (&lt; 0.45): Uses <code>arcsin</code> transformation.</li> <li>Moderate <code>r\u0304</code> (0.45 - 0.7): Uses <code>asinh</code> transformation.</li> <li>Large <code>r\u0304</code> (&gt; 0.7): Uses Bartlett-type test (log-likelihood method).</li> </ul> References <ul> <li>Jammalamadaka &amp; SenGupta (2001), Section 5.4.</li> <li>Fisher (1993), Section 4.3.</li> <li><code>equal.kappa.test</code> from R's <code>circular</code> package.</li> </ul> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def equal_kappa_test(samples: list[np.ndarray], verbose: bool = False) -&gt; dict:\n    \"\"\"\n    Test for Homogeneity of Concentration Parameters (\u03ba) in Circular Data.\n\n    - **H\u2080**: All groups have the same concentration parameter (\u03ba).\n    - **H\u2081**: At least one group has a different \u03ba.\n\n    Parameters\n    ----------\n    samples : list of np.ndarray\n        List of circular data arrays (angles in radians) for different groups.\n    verbose : bool, optional\n        If `True`, prints the test summary.\n\n    Returns\n    -------\n    result : dict\n        A dictionary containing:\n        - `'kappa'`: Estimated concentration parameters for each group.\n        - `'kappa_all'`: Estimated common \u03ba for all samples combined.\n        - `'rho'`: Mean resultant lengths for each group.\n        - `'rho_all'`: Mean resultant length for all samples combined.\n        - `'df'`: Degrees of freedom.\n        - `'statistic'`: Test statistic (Chi-Square).\n        - `'p_value'`: p-value.\n\n    Notes\n    -----\n    - Uses **different approximations based on mean resultant length** (`r\u0304`):\n      - **Small `r\u0304` (&lt; 0.45)**: Uses `arcsin` transformation.\n      - **Moderate `r\u0304` (0.45 - 0.7)**: Uses `asinh` transformation.\n      - **Large `r\u0304` (&gt; 0.7)**: Uses Bartlett-type test (log-likelihood method).\n\n    References\n    ----------\n    - Jammalamadaka &amp; SenGupta (2001), Section 5.4.\n    - Fisher (1993), Section 4.3.\n    - `equal.kappa.test` from R's `circular` package.\n    \"\"\"\n\n    # Number of groups\n    k = len(samples)\n    if k &lt; 2:\n        raise ValueError(\"At least two groups are required for the test.\")\n\n    # Sample sizes\n    ns = np.array([len(group) for group in samples])\n\n    # Mean resultant lengths\n    r_bars = np.array([circ_r(group) for group in samples])\n    Rs = r_bars * ns  # Unnormalized resultants\n\n    # Overall resultant and mean resultant length\n    all_samples = np.hstack(samples)\n    N = len(all_samples)\n    r_bar_all = circ_r(all_samples)\n\n    # Estimate kappa values\n    kappas = np.array([circ_kappa(r) for r in r_bars])\n    kappa_all = circ_kappa(r_bar_all)\n\n    # Choose test statistic based on `r\u0304`\n    if r_bar_all &lt; 0.45:\n        # Small `r\u0304`: arcsin transformation\n        ws = 4 * (ns - 4) / 3\n        g1s = np.arcsin(np.sqrt(3 / 8) * 2 * r_bars)\n        chi_square_stat = np.sum(ws * g1s**2) - (np.sum(ws * g1s) ** 2 / np.sum(ws))\n\n    elif 0.45 &lt;= r_bar_all &lt;= 0.7:\n        # Moderate `r\u0304`: asinh transformation\n        ws = (ns - 3) / 0.798\n        g2s = np.arcsinh((r_bars - 1.089) / 0.258)\n        chi_square_stat = np.sum(ws * g2s**2) - (np.sum(ws * g2s) ** 2 / np.sum(ws))\n\n    else:\n        # Large `r\u0304`: Bartlett-type test\n        vs = ns - 1\n        v = N - k\n        d = 1 / (3 * (k - 1)) * (np.sum(1 / vs) - 1 / v)\n        chi_square_stat = (1 / (1 + d)) * (\n            v * np.log((N - np.sum(Rs)) / v) - np.sum(vs * np.log((ns - Rs) / vs))\n        )\n\n    # Compute p-value\n    df = k - 1\n    p_value = 1 - chi2.cdf(chi_square_stat, df)\n\n    result = {\n        \"kappa\": kappas,\n        \"kappa_all\": kappa_all,\n        \"rho\": r_bars,\n        \"rho_all\": r_bar_all,\n        \"df\": df,\n        \"statistic\": chi_square_stat,\n        \"p_value\": p_value,\n    }\n\n    # Print results if verbose is enabled\n    if verbose:\n        print(\"\\nTest for Homogeneity of Concentration Parameters (\u03ba)\")\n        print(\"------------------------------------------------------\")\n        print(f\"Mean Resultant Lengths: {r_bars}\")\n        print(f\"Overall Mean Resultant Length: {r_bar_all:.5f}\")\n        print(f\"Estimated Kappa Values: {kappas}\")\n        print(f\"Overall Estimated Kappa: {kappa_all:.5f}\")\n        print(f\"Degrees of Freedom: {df}\")\n        print(f\"Chi-Square Statistic: {chi_square_stat:.5f}\")\n        print(f\"P-value: {p_value:.5f}\")\n        print(\"------------------------------------------------------\\n\")\n\n    return result\n</code></pre>"},{"location":"reference/hypothesis/#pycircstat2.hypothesis.common_median_test","title":"<code>common_median_test(samples, verbose=False)</code>","text":"<p>Common Median Test (Equal Median Test) for Multiple Circular Samples.</p> <ul> <li>H\u2080: All groups have the same circular median.</li> <li>H\u2081: At least one group has a different circular median.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>list of np.ndarray</code> <p>List of circular data arrays (angles in radians) for different groups.</p> required <code>verbose</code> <code>bool</code> <p>If <code>True</code>, prints the test summary.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>A dictionary containing: - <code>'common_median'</code>: Estimated shared median if H\u2080 is not rejected; otherwise, <code>NaN</code>. - <code>'test_statistic'</code>: Test statistic (Chi-Square). - <code>'p_value'</code>: p-value. - <code>'reject'</code>: Boolean indicating whether to reject H\u2080.</p> References <ul> <li>Fisher, N. I. (1995). Statistical Analysis of Circular Data.</li> <li><code>circ_cmtest</code> from MATLAB's Circular Statistics Toolbox.</li> </ul> Source code in <code>pycircstat2/hypothesis.py</code> <pre><code>def common_median_test(samples: list[np.ndarray], verbose: bool = False) -&gt; dict:\n    \"\"\"\n    Common Median Test (Equal Median Test) for Multiple Circular Samples.\n\n    - **H\u2080**: All groups have the same circular median.\n    - **H\u2081**: At least one group has a different circular median.\n\n    Parameters\n    ----------\n    samples : list of np.ndarray\n        List of circular data arrays (angles in radians) for different groups.\n    verbose : bool, optional\n        If `True`, prints the test summary.\n\n    Returns\n    -------\n    result : dict\n        A dictionary containing:\n        - `'common_median'`: Estimated shared median if H\u2080 is not rejected; otherwise, `NaN`.\n        - `'test_statistic'`: Test statistic (Chi-Square).\n        - `'p_value'`: p-value.\n        - `'reject'`: Boolean indicating whether to reject H\u2080.\n\n    References\n    ----------\n    - Fisher, N. I. (1995). Statistical Analysis of Circular Data.\n    - `circ_cmtest` from MATLAB's Circular Statistics Toolbox.\n    \"\"\"\n\n    # Number of groups\n    k = len(samples)\n    if k &lt; 2:\n        raise ValueError(\"At least two groups are required for the test.\")\n\n    # Sample sizes\n    ns = np.array([len(group) for group in samples])\n    N = np.sum(ns)  # Total number of observations\n\n    # Compute the common circular median\n    common_median = circ_median(np.hstack(samples))\n\n    # Compute deviations from the common median\n    m = np.zeros(k)\n    for i, group in enumerate(samples):\n        deviations = circ_dist(group, common_median)\n        m[i] = np.sum(deviations &lt; 0)  # Count how many are \"below\" the median\n\n    # Compute test statistic\n    M = np.sum(m)\n    P = (N**2 / (M * (N - M))) * np.sum(m**2 / ns) - (N * M) / (N - M)\n\n    # Compute p-value\n    df = k - 1\n    p_value = 1 - chi2.cdf(P, df)\n    reject = p_value &lt; 0.05  # Reject H\u2080 if p-value is below 0.05\n\n    # If the null hypothesis is rejected, return NaN for the median\n    if reject:\n        common_median = np.nan\n\n    result = {\n        \"common_median\": common_median,\n        \"test_statistic\": P,\n        \"p_value\": p_value,\n        \"reject\": reject,\n    }\n\n    # Print results if verbose is enabled\n    if verbose:\n        print(\"\\nCommon Median Test (Equal Median Test)\")\n        print(\"--------------------------------------\")\n        print(f\"Estimated Common Median: {common_median if not reject else 'NaN'}\")\n        print(f\"Test Statistic: {P:.5f}\")\n        print(f\"P-value: {p_value:.5f}\")\n        print(f\"Reject H\u2080: {'Yes' if reject else 'No'}\")\n        print(\"--------------------------------------\\n\")\n\n    return result\n</code></pre>"},{"location":"reference/regression/","title":"Regression","text":""},{"location":"reference/regression/#pycircstat2.regression.CLRegression","title":"<code>CLRegression</code>","text":"<p>Circular-Linear Regression.</p> <p>Fits a circular response to linear predictors using iterative optimization.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>A formula string like '\u03b8 ~ x1 + x2 + x3' specifying the model.</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>A pandas DataFrame containing the response and predictors.</p> <code>None</code> <code>theta</code> <code>ndarray</code> <p>A numpy array of circular response values in radians.</p> <code>None</code> <code>X</code> <code>ndarray</code> <p>A numpy array of predictor values.</p> <code>None</code> <code>model_type</code> <code>str</code> <p>Type of model to fit. Must be one of 'mean', 'kappa', or 'mixed'.</p> <ul> <li>'mean': Fit a model for the mean direction.</li> <li>'kappa': Fit a model for the concentration parameter.</li> <li>'mixed': Fit a mixed circular-linear model.</li> </ul> <code>'mixed'</code> <code>beta0</code> <code>ndarray</code> <p>Initial values for the beta coefficients.</p> <code>None</code> <code>alpha0</code> <code>float</code> <p>Initial value for the intercept.</p> <code>None</code> <code>gamma0</code> <code>ndarray</code> <p>Initial values for the gamma coefficients.</p> <code>None</code> <code>tol</code> <code>float</code> <p>Convergence tolerance for the optimization.</p> <code>1e-08</code> <code>max_iter</code> <code>int</code> <p>Maximum number of iterations for the optimization.</p> <code>100</code> <code>verbose</code> <code>bool</code> <p>Whether to print optimization progress.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>result</code> <code>dict</code> <p>A dictionary containing the estimated coefficients and other statistics.</p> <ul> <li>beta : np.ndarray     Estimated beta coefficients for the mean direction.</li> <li>alpha : float     Estimated intercept for the concentration parameter..</li> <li>gamma : np.ndarray     Estimated coefficients for the concentration parameter.</li> <li>mu : float     Estimated mean direction of the circular response.</li> <li>kappa : float     Estimated concentration parameter of the circular response.</li> <li>log_likelihood : float     Log-likelihood of the model.</li> </ul> <p>Methods:</p> Name Description <code>summary</code> <p>Print a summary of the regression results.</p> Notes <p>The implementation is ported from the <code>lm.circular.cl</code> in the <code>circular</code> R package.</p> References <ul> <li>Fisher, N. I. (1993). Statistical analysis of circular data. Cambridge University Press.</li> <li>Pewsey, A., Neuh\u00e4user, M., &amp; Ruxton, G. D. (2014) Circular Statistics in R. Oxford University Press.</li> </ul> Source code in <code>pycircstat2/regression.py</code> <pre><code>class CLRegression:\n    \"\"\"\n    Circular-Linear Regression.\n\n    Fits a circular response to linear predictors using iterative optimization.\n\n    Parameters\n    ----------\n    formula : str, optional\n        A formula string like '\u03b8 ~ x1 + x2 + x3' specifying the model.\n    data : pd.DataFrame, optional\n        A pandas DataFrame containing the response and predictors.\n    theta : np.ndarray, optional\n        A numpy array of circular response values in radians.\n    X : np.ndarray, optional\n        A numpy array of predictor values.\n    model_type : str, optional\n        Type of model to fit. Must be one of 'mean', 'kappa', or 'mixed'.\n\n        - 'mean': Fit a model for the mean direction.\n        - 'kappa': Fit a model for the concentration parameter.\n        - 'mixed': Fit a mixed circular-linear model.\n\n    beta0 : np.ndarray, optional\n        Initial values for the beta coefficients.\n    alpha0 : float, optional\n        Initial value for the intercept.\n    gamma0 : np.ndarray, optional\n        Initial values for the gamma coefficients.\n    tol : float, optional\n        Convergence tolerance for the optimization.\n    max_iter : int, optional\n        Maximum number of iterations for the optimization.\n    verbose : bool, optional\n        Whether to print optimization progress.\n\n    Attributes\n    ----------\n    result : dict\n        A dictionary containing the estimated coefficients and other statistics.\n\n        - beta : np.ndarray\n            Estimated beta coefficients for the mean direction.\n        - alpha : float\n            Estimated intercept for the concentration parameter..\n        - gamma : np.ndarray\n            Estimated coefficients for the concentration parameter.\n        - mu : float\n            Estimated mean direction of the circular response.\n        - kappa : float\n            Estimated concentration parameter of the circular response.\n        - log_likelihood : float\n            Log-likelihood of the model.\n\n    Methods\n    -------\n    summary()\n        Print a summary of the regression results.\n\n\n    Notes\n    -----\n    The implementation is ported from the `lm.circular.cl` in the `circular` R package.\n\n    References\n    ----------\n    - Fisher, N. I. (1993). Statistical analysis of circular data. Cambridge University Press.\n    - Pewsey, A., Neuh\u00e4user, M., &amp; Ruxton, G. D. (2014) Circular Statistics in R. Oxford University Press.\n    \"\"\"\n\n    def __init__(\n        self,\n        formula: Optional[str] = None,\n        data: Optional[pd.DataFrame] = None,\n        theta: Optional[np.ndarray] = None,\n        X: Optional[np.ndarray] = None,\n        model_type: str = \"mixed\",\n        beta0: Union[np.ndarray, None] = None,\n        alpha0: Union[float, None] = None,\n        gamma0: Union[np.ndarray, None] = None,\n        tol: float = 1e-8,\n        max_iter: int = 100,\n        verbose: bool = False,\n    ):\n        self.verbose = verbose\n        self.tol = tol\n        self.max_iter = max_iter\n        self.model_type = model_type\n\n        # Parse inputs\n        if formula and data is not None:\n            self.theta, self.X, self.feature_names = self._parse_formula(formula, data)\n        elif theta is not None and X is not None:\n            self.theta = theta\n            self.X = X\n            self.feature_names = [f\"x{i}\" for i in range(X.shape[1])]\n        else:\n            raise ValueError(\"Provide either a formula + data or theta and X.\")\n\n        # Validate model type\n        if model_type not in [\"mean\", \"kappa\", \"mixed\"]:\n            raise ValueError(\"Model type must be 'mean', 'kappa', or 'mixed'.\")\n\n        # Initialize parameters\n        self.alpha = alpha0 if alpha0 is not None else 0.0\n        self.beta = beta0 if beta0 is not None else np.zeros(self.X.shape[1])\n        self.gamma = gamma0 if gamma0 is not None else np.zeros(self.X.shape[1])\n\n        # Fit the model\n        self.result = self._fit()\n\n    def _parse_formula(\n        self, formula: str, data: pd.DataFrame\n    ) -&gt; Tuple[np.ndarray, np.ndarray, List[str]]:\n        theta_col, x_cols = formula.split(\"~\")\n        theta = data[theta_col.strip()].to_numpy()\n        x_cols = [col.strip() for col in x_cols.split(\"+\")]\n        X = data[x_cols].to_numpy()\n        return theta, X, x_cols\n\n    def _A1(self, kappa: np.ndarray) -&gt; np.ndarray:\n        return i1(kappa) / i0(kappa)\n\n    def _A1inv(self, R: float) -&gt; float:\n        if 0 &lt;= R &lt; 0.53:\n            return 2 * R + R**3 + (5 * R**5) / 6\n        elif R &lt; 0.85:\n            return -0.4 + 1.39 * R + 0.43 / (1 - R)\n        else:\n            return 1 / (R**3 - 4 * R**2 + 3 * R)\n\n    def _A1_prime(self, kappa: np.ndarray) -&gt; np.ndarray:\n        a1 = A1(kappa)\n        return 1 - a1 / kappa - a1**2\n\n    def _fit(self):\n        theta = self.theta\n        n = len(theta)\n        X = self.X\n        X1 = np.column_stack((np.ones(n), X))  # Add intercept\n        beta, alpha, gamma = self.beta, self.alpha, self.gamma\n        diff = self.tol + 1\n        log_likelihood_old = -np.inf\n\n        for iter_count in range(self.max_iter):\n            if self.model_type == \"mean\":\n                # Step 1: Compute mu and kappa\n                raw_deviation = theta - 2 * np.arctan(X @ beta)\n                S = np.mean(np.sin(raw_deviation))\n                C = np.mean(np.cos(raw_deviation))\n                R = np.sqrt(S**2 + C**2)\n                kappa = A1inv(R)\n                mu = np.arctan2(S, C)\n\n                # Step 2: Update beta\n                G = 2 * X / (1 + (X @ beta) ** 2)[:, None]\n                A = np.eye(n) * (kappa * A1(np.asarray(kappa)))\n                u = kappa * np.sin(raw_deviation - mu)\n                beta_new = np.linalg.solve(G.T @ A @ G, G.T @ (u + A @ G @ beta))\n                alpha_new, gamma_new = np.nan, np.nan\n\n                # Log-likelihood\n                log_likelihood = -n * np.log(i0(kappa)) + kappa * np.sum(\n                    np.cos(raw_deviation - mu)\n                )\n\n            elif self.model_type == \"kappa\":\n                # Step 1: Compute mu and kappa\n                kappa = np.exp(alpha + X @ gamma)\n                S = np.sum(kappa * np.sin(theta))\n                C = np.sum(kappa * np.cos(theta))\n                mu = np.arctan2(S, C)\n\n                # Step 2: Update gamma\n                residuals_gamma = np.cos(theta - mu) - self._A1(kappa)\n                y_gamma = residuals_gamma / (self._A1_prime(kappa) * kappa)\n                W_gamma = np.diag((kappa**2) * self._A1_prime(kappa))\n                XtWX = X1.T @ W_gamma @ X1\n                XtWy = X1.T @ W_gamma @ y_gamma\n                update = np.linalg.solve(XtWX, XtWy)\n                alpha_new = alpha + update[0]\n                gamma_new = gamma + update[1:]\n                beta_new = np.nan\n                # Log-likelihood\n                log_likelihood = -np.sum(np.log(i0(kappa))) + np.sum(\n                    kappa * np.cos(theta - mu)\n                )\n\n            elif self.model_type == \"mixed\":\n                # Step 1: Compute mu and kappa\n                kappa = np.exp(alpha + X @ gamma)\n                raw_deviation = theta - 2 * np.arctan(X @ beta)\n                S = np.sum(kappa * np.sin(raw_deviation))\n                C = np.sum(kappa * np.cos(raw_deviation))\n                mu = np.arctan2(S, C)\n                residuals = theta - mu\n\n                # Step 2: Update beta\n                G = 2 * X / (1 + (X @ beta) ** 2)[:, None]\n                W_kappa = np.diag(kappa * self._A1(kappa))\n                beta_new = np.linalg.solve(\n                    G.T @ W_kappa @ G, G.T @ W_kappa @ np.sin(residuals)\n                )\n\n                # Step 3: Update gamma\n                residuals_gamma = np.cos(raw_deviation - mu) - self._A1(kappa)\n                y_gamma = residuals_gamma / (self._A1_prime(kappa) * kappa)\n                W_gamma = np.diag((kappa**2) * self._A1_prime(kappa))\n                XtWX = X1.T @ W_gamma @ X1\n                XtWy = X1.T @ W_gamma @ y_gamma\n                update = np.linalg.solve(XtWX, XtWy)\n                alpha_new = alpha + update[0]\n                gamma_new = gamma + update[1:]\n\n                # Log-likelihood\n                log_likelihood = -np.sum(np.log(i0(kappa))) + np.sum(\n                    kappa * np.cos(raw_deviation - mu)\n                )\n\n            # Convergence check\n            diff = np.abs(log_likelihood - log_likelihood_old)\n            if self.verbose:\n                print(\n                    f\"Iteration {iter_count + 1}: Log-Likelihood = {log_likelihood:.5f}, diff = {diff:.2e}\"\n                )\n            if diff &lt; self.tol:\n                break\n\n            beta, alpha, gamma = beta_new, alpha_new, gamma_new\n            log_likelihood_old = log_likelihood\n\n        result = {\n            \"beta\": beta,\n            \"alpha\": alpha,\n            \"gamma\": gamma,\n            \"mu\": mu,\n            \"kappa\": kappa,\n            \"log_likelihood\": log_likelihood,\n        }\n\n        se_result = self._compute_standard_errors(result)\n\n        result.update(se_result)\n\n        return result\n\n    def _compute_standard_errors(self, result):\n        \"\"\"\n        Compute standard errors for the parameters based on the fitted model.\n        \"\"\"\n        theta = self.theta\n        X = self.X\n        n = len(theta)\n        kappa = result[\"kappa\"]\n        beta = result[\"beta\"]\n        gamma = result[\"gamma\"]\n        alpha = result[\"alpha\"]\n\n        se_results = {}\n\n        if self.model_type == \"mean\":\n            # Mean Direction Model\n            G = 2 * X / (1 + (X @ beta) ** 2)[:, None]\n            A = np.eye(n) * (kappa * self._A1(kappa))\n            XtAX = G.T @ A @ G\n            cov_beta = np.linalg.solve(XtAX, np.eye(XtAX.shape[0]))\n            se_beta = np.sqrt(np.diag(cov_beta))\n\n            se_mu = 1 / np.sqrt((n - X.shape[1]) * kappa * self._A1(kappa))\n            se_kappa = np.sqrt(\n                1 / (n * (1 - self._A1(kappa) ** 2 - self._A1(kappa) / kappa))\n            )\n\n            se_results.update(\n                {\n                    \"se_beta\": se_beta,\n                    \"se_mu\": se_mu,\n                    \"se_kappa\": se_kappa,\n                }\n            )\n\n        elif self.model_type == \"kappa\":\n            # Concentration Parameter Model\n            X1 = np.column_stack((np.ones(n), X))  # Add intercept\n            W = np.diag(\n                (np.exp(X1 @ np.hstack([alpha, gamma])) ** 2) * self._A1_prime(kappa)\n            )\n            XtWX = X1.T @ W @ X1\n\n            cov_gamma_alpha = np.linalg.solve(XtWX, np.eye(XtWX.shape[0]))\n\n            se_alpha = np.sqrt(cov_gamma_alpha[0, 0])\n            se_gamma = np.sqrt(np.diag(cov_gamma_alpha[1:, 1:]))\n\n            se_mu = 1 / np.sqrt(np.sum(kappa * self._A1(kappa)) - 0.5)\n\n            se_kappa = np.sqrt(1 / (n * self._A1_prime(kappa)))\n\n            se_results.update(\n                {\n                    \"se_alpha\": se_alpha,\n                    \"se_gamma\": se_gamma,\n                    \"se_mu\": se_mu,\n                    \"se_kappa\": se_kappa,\n                }\n            )\n\n        elif self.model_type == \"mixed\":\n            # Mixed Model\n            G = 2 * X / (1 + (X @ beta) ** 2)[:, None]\n            K = np.diag(kappa * self._A1(kappa))\n            XtGKGX = G.T @ K @ G\n\n            cov_beta = np.linalg.solve(XtGKGX, np.eye(XtGKGX.shape[0]))\n            se_beta = np.sqrt(np.diag(cov_beta))\n\n            X1 = np.column_stack((np.ones(n), X))  # Add intercept\n            W_gamma = np.diag(\n                (np.exp(X1 @ np.hstack([alpha, gamma])) ** 2) * self._A1_prime(kappa)\n            )\n            XtWX_gamma = X1.T @ W_gamma @ X1\n\n            # Check positive definiteness and regularize if needed\n            eigenvalues_gamma = np.linalg.eigvals(XtWX_gamma)\n            if np.any(eigenvalues_gamma &lt;= 0):\n                XtWX_gamma += np.eye(XtWX_gamma.shape[0]) * 1e-8\n\n            cov_gamma_alpha = np.linalg.solve(XtWX_gamma, np.eye(XtWX_gamma.shape[0]))\n            se_alpha = np.sqrt(cov_gamma_alpha[0, 0])\n            se_gamma = np.sqrt(np.diag(cov_gamma_alpha[1:, 1:]))\n\n            se_mu = 1 / np.sqrt(np.sum(kappa * self._A1(kappa)) - 0.5)\n            se_kappa = np.sqrt(\n                1 / (n * (1 - self._A1(kappa) ** 2 - self._A1(kappa) / kappa))\n            )\n            se_results.update(\n                {\n                    \"se_beta\": se_beta,\n                    \"se_alpha\": se_alpha,\n                    \"se_gamma\": se_gamma,\n                    \"se_mu\": se_mu,\n                    \"se_kappa\": se_kappa,\n                }\n            )\n\n        else:\n            raise ValueError(f\"Unknown model type: {self.model_type}\")\n\n        return se_results\n\n    def AIC(self):\n        \"\"\"\n        Calculate Akaike Information Criterion (AIC).\n        \"\"\"\n        if self.result is None:\n            raise ValueError(\"Model must be fitted before calculating AIC.\")\n\n        log_likelihood = self.result[\"log_likelihood\"]\n        if self.model_type == \"mean\":\n            n_params = len(self.result[\"beta\"])  # Only beta\n        elif self.model_type == \"kappa\":\n            n_params = 1 + len(self.result[\"gamma\"])  # alpha + gamma\n        elif self.model_type == \"mixed\":\n            n_params = (\n                1 + len(self.result[\"beta\"]) + len(self.result[\"gamma\"])\n            )  # alpha + beta + gamma\n        else:\n            raise ValueError(f\"Unknown model type: {self.model_type}\")\n\n        return -2 * log_likelihood + 2 * n_params\n\n    def BIC(self):\n        \"\"\"\n        Calculate Bayesian Information Criterion (BIC).\n        \"\"\"\n        if self.result is None:\n            raise ValueError(\"Model must be fitted before calculating BIC.\")\n\n        log_likelihood = self.result[\"log_likelihood\"]\n        n = len(self.theta)\n        if self.model_type == \"mean\":\n            n_params = len(self.result[\"beta\"])  # Only beta\n        elif self.model_type == \"kappa\":\n            n_params = 1 + len(self.result[\"gamma\"])  # alpha + gamma\n        elif self.model_type == \"mixed\":\n            n_params = (\n                1 + len(self.result[\"beta\"]) + len(self.result[\"gamma\"])\n            )  # alpha + beta + gamma\n        else:\n            raise ValueError(f\"Unknown model type: {self.model_type}\")\n\n        return -2 * log_likelihood + n_params * np.log(n)\n\n    def predict(self, X_new):\n        \"\"\"\n        Predict circular response values for new predictor values.\n\n        Parameters\n        ----------\n        X_new: array-like, shape (n_samples, n_features)\n            New predictor data.\n\n        Returns\n        -------\n        theta_new: array-like, shape(n_samples, )\n            New circular response values.\n        \"\"\"\n        if self.result is None:\n            raise ValueError(\"Model must be fitted before making predictions.\")\n\n        mu = self.result[\"mu\"]\n        beta = self.result[\"beta\"]\n        return mu + 2 * np.arctan(X_new @ beta)\n\n    def summary(self):\n        if self.result is None:\n            raise ValueError(\"Model must be fitted before summarizing.\")\n\n        # Title based on model type\n        if self.model_type == \"mean\":\n            print(\"\\nCircular Regression for the Mean Direction\\n\")\n        elif self.model_type == \"kappa\":\n            print(\"\\nCircular Regression for the Concentration Parameter\\n\")\n        elif self.model_type == \"mixed\":\n            print(\"\\nMixed Circular-Linear Regression\\n\")\n\n        # Call\n        print(\"Call:\")\n        print(f\"  CLRegression(model_type='{self.model_type}')\\n\")\n\n        # Coefficients for mean direction (Beta)\n        if self.model_type in [\"mean\", \"mixed\"] and self.result[\"beta\"] is not None:\n            print(\"Coefficients for Mean Direction (Beta):\\n\")\n            print(\n                f\"{'':&lt;5} {'Estimate':&lt;12} {'Std. Error':&lt;12} {'t value':&lt;10} {'Pr(&gt;|t|)'}\"\n            )\n            for i, coef in enumerate(self.result[\"beta\"]):\n                # Placeholder for standard error and p-values\n                se_beta = self.result[\"se_beta\"][i]\n                t_value = np.abs(coef / se_beta) if se_beta else np.nan\n                p_value = (\n                    2 * (1 - norm.cdf(np.abs(t_value)))\n                    if not np.isnan(t_value)\n                    else np.nan\n                )\n                print(\n                    f\"\u03b2{i:&lt;3} {coef:&lt;12.5f} {se_beta:&lt;12.5f} {t_value:&lt;10.2f} {p_value:&lt;12.5f}{significance_code(p_value):&lt;3}\"\n                )\n\n        # Coefficients for concentration parameter (Gamma)\n        if self.model_type in [\"kappa\", \"mixed\"] and self.result[\"gamma\"] is not None:\n            print(\"\\nCoefficients for Concentration (Gamma):\\n\")\n            print(\n                f\"{'':&lt;5} {'Estimate':&lt;12} {'Std. Error':&lt;12} {'t value':&lt;10} {'Pr(&gt;|t|)':&lt;12}\"\n            )\n            # Report alpha as the first coefficient\n            alpha = self.result[\"alpha\"]\n            se_alpha = self.result[\"se_alpha\"]\n            t_value_alpha = alpha / se_alpha if se_alpha else np.nan\n            p_value_alpha = (\n                2 * (1 - norm.cdf(np.abs(t_value_alpha)))\n                if not np.isnan(t_value_alpha)\n                else np.nan\n            )\n            print(\n                f\"\u03b1{'':&lt;5} {alpha:&lt;12.5f} {se_alpha:&lt;12.5f} {t_value_alpha:&lt;10.2f} {p_value_alpha:&lt;12.5f}{significance_code(p_value_alpha)}\"\n            )\n            for i, coef in enumerate(self.result[\"gamma\"]):\n                # Placeholder for standard error and p-values\n                se_gamma = self.result[\"se_gamma\"][i]\n                t_value = coef / se_gamma if se_gamma else np.nan\n                p_value = (\n                    2 * (1 - norm.cdf(np.abs(t_value)))\n                    if not np.isnan(t_value)\n                    else np.nan\n                )\n                print(\n                    f\"\u03b3{i:&lt;5} {coef:&lt;12.5f} {se_gamma:&lt;12.5f} {t_value:&lt;10.2f} {p_value:&lt;12.5f}{significance_code(p_value)}\"\n                )\n\n        # Summary for mu and kappa\n        print(\"\\nSummary:\")\n        print(\"  Mean Direction (mu) in radians:\")\n        mu = self.result[\"mu\"]\n        se_mu = self.result[\"se_mu\"]\n        print(f\"    \u03bc: {mu:.5f} (SE: {se_mu:.5f})\")\n\n        print(\"\\n  Concentration Parameter (kappa):\")\n        kappa = self.result[\"kappa\"]\n        se_kappa = self.result[\"se_kappa\"]\n        if isinstance(kappa, np.ndarray):\n            print(\"    Index    kappa        Std. Error\")\n            for i, (k, se) in enumerate(zip(kappa, se_kappa), start=1):\n                print(f\"    [{i}]    {k:&gt;10.5f}    {se:&gt;10.5f}\")\n            print(f\"    Mean:    {np.mean(kappa):.5f} (SE: {np.mean(se_kappa):.5f})\")\n        else:\n            print(f\"    \u03ba: {kappa:.5f} (SE: {se_kappa:.5f})\")\n\n        # Summary for model fit metrics\n        print(\"\\nModel Fit Metrics:\\n\")\n        print(f\"{'Metric':&lt;12} {'Value':&lt;12}\")\n        log_likelihood = self.result.get(\"log_likelihood\", float(\"nan\"))\n        nll = -log_likelihood  # Negative log-likelihood\n        print(f\"{'nLL':&lt;12} {nll:&lt;12.5f}\")\n        print(f\"{'AIC':&lt;12} {self.AIC():&lt;12.5f}\")\n        print(f\"{'BIC':&lt;12} {self.BIC():&lt;12.5f}\")\n\n        # Notes\n        print(\"\\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\")\n        print(\"p-values are approximated using the normal distribution.\\n\")\n</code></pre>"},{"location":"reference/regression/#pycircstat2.regression.CLRegression.AIC","title":"<code>AIC()</code>","text":"<p>Calculate Akaike Information Criterion (AIC).</p> Source code in <code>pycircstat2/regression.py</code> <pre><code>def AIC(self):\n    \"\"\"\n    Calculate Akaike Information Criterion (AIC).\n    \"\"\"\n    if self.result is None:\n        raise ValueError(\"Model must be fitted before calculating AIC.\")\n\n    log_likelihood = self.result[\"log_likelihood\"]\n    if self.model_type == \"mean\":\n        n_params = len(self.result[\"beta\"])  # Only beta\n    elif self.model_type == \"kappa\":\n        n_params = 1 + len(self.result[\"gamma\"])  # alpha + gamma\n    elif self.model_type == \"mixed\":\n        n_params = (\n            1 + len(self.result[\"beta\"]) + len(self.result[\"gamma\"])\n        )  # alpha + beta + gamma\n    else:\n        raise ValueError(f\"Unknown model type: {self.model_type}\")\n\n    return -2 * log_likelihood + 2 * n_params\n</code></pre>"},{"location":"reference/regression/#pycircstat2.regression.CLRegression.BIC","title":"<code>BIC()</code>","text":"<p>Calculate Bayesian Information Criterion (BIC).</p> Source code in <code>pycircstat2/regression.py</code> <pre><code>def BIC(self):\n    \"\"\"\n    Calculate Bayesian Information Criterion (BIC).\n    \"\"\"\n    if self.result is None:\n        raise ValueError(\"Model must be fitted before calculating BIC.\")\n\n    log_likelihood = self.result[\"log_likelihood\"]\n    n = len(self.theta)\n    if self.model_type == \"mean\":\n        n_params = len(self.result[\"beta\"])  # Only beta\n    elif self.model_type == \"kappa\":\n        n_params = 1 + len(self.result[\"gamma\"])  # alpha + gamma\n    elif self.model_type == \"mixed\":\n        n_params = (\n            1 + len(self.result[\"beta\"]) + len(self.result[\"gamma\"])\n        )  # alpha + beta + gamma\n    else:\n        raise ValueError(f\"Unknown model type: {self.model_type}\")\n\n    return -2 * log_likelihood + n_params * np.log(n)\n</code></pre>"},{"location":"reference/regression/#pycircstat2.regression.CLRegression.predict","title":"<code>predict(X_new)</code>","text":"<p>Predict circular response values for new predictor values.</p> <p>Parameters:</p> Name Type Description Default <code>X_new</code> <p>New predictor data.</p> required <p>Returns:</p> Name Type Description <code>theta_new</code> <code>(array - like, shape(n_samples))</code> <p>New circular response values.</p> Source code in <code>pycircstat2/regression.py</code> <pre><code>def predict(self, X_new):\n    \"\"\"\n    Predict circular response values for new predictor values.\n\n    Parameters\n    ----------\n    X_new: array-like, shape (n_samples, n_features)\n        New predictor data.\n\n    Returns\n    -------\n    theta_new: array-like, shape(n_samples, )\n        New circular response values.\n    \"\"\"\n    if self.result is None:\n        raise ValueError(\"Model must be fitted before making predictions.\")\n\n    mu = self.result[\"mu\"]\n    beta = self.result[\"beta\"]\n    return mu + 2 * np.arctan(X_new @ beta)\n</code></pre>"},{"location":"reference/regression/#pycircstat2.regression.CCRegression","title":"<code>CCRegression</code>","text":"<p>Circular-Circular Regression.</p> <p>Fits a circular response to circular predictors using a specified order of harmonics.</p> <p>Parameters:</p> Name Type Description Default <code>theta</code> <code>ndarray</code> <p>A numpy array of circular response values in radians.</p> <code>None</code> <code>x</code> <code>ndarray</code> <p>A numpy array of circular predictor values in radians.</p> <code>None</code> <code>order</code> <code>int</code> <p>Order of harmonics to include in the model (default is 1).</p> <code>1</code> <code>level</code> <code>float</code> <p>Significance level for testing higher-order terms (default is 0.05).</p> <code>0.05</code> <p>Attributes:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular correlation coefficient.</p> <code>fitted</code> <code>ndarray</code> <p>Fitted values of the circular response in radians.</p> <code>residuals</code> <code>ndarray</code> <p>Residuals of the circular response in radians.</p> <code>coefficients</code> <code>dict</code> <p>Coefficients of the cos and sin terms for each harmonic order.</p> <code>p_values</code> <code>ndarray</code> <p>P-values for higher-order terms.</p> <code>message</code> <code>str</code> <p>Message indicating the significance of higher-order terms.</p> <p>Methods:</p> Name Description <code>summary</code> <p>Print a summary of the regression results.</p> Notes <p>The implementation is ported from the <code>lm.circular.cc</code> in the <code>circular</code> R package.</p> References <ul> <li>Jammalamadaka, S. R., &amp; Sengupta, A. (2001) Topics in Circular Statistics. World Scientific.</li> <li>Pewsey, A., Neuh\u00e4user, M., &amp; Ruxton, G. D. (2014) Circular Statistics in R. Oxford University Press.</li> </ul> Source code in <code>pycircstat2/regression.py</code> <pre><code>class CCRegression:\n    \"\"\"\n    Circular-Circular Regression.\n\n    Fits a circular response to circular predictors using a specified order of harmonics.\n\n    Parameters\n    ----------\n    theta : np.ndarray\n        A numpy array of circular response values in radians.\n    x : np.ndarray\n        A numpy array of circular predictor values in radians.\n    order : int, optional\n        Order of harmonics to include in the model (default is 1).\n    level : float, optional\n        Significance level for testing higher-order terms (default is 0.05).\n\n    Attributes\n    ----------\n    rho : float\n        Circular correlation coefficient.\n    fitted : np.ndarray\n        Fitted values of the circular response in radians.\n    residuals : np.ndarray\n        Residuals of the circular response in radians.\n    coefficients : dict\n        Coefficients of the cos and sin terms for each harmonic order.\n    p_values : np.ndarray\n        P-values for higher-order terms.\n    message : str\n        Message indicating the significance of higher-order terms.\n\n    Methods\n    -------\n    summary()\n        Print a summary of the regression results.\n\n\n    Notes\n    -----\n    The implementation is ported from the `lm.circular.cc` in the `circular` R package.\n\n    References\n    ----------\n    - Jammalamadaka, S. R., &amp; Sengupta, A. (2001) Topics in Circular Statistics. World Scientific.\n    - Pewsey, A., Neuh\u00e4user, M., &amp; Ruxton, G. D. (2014) Circular Statistics in R. Oxford University Press.\n    \"\"\"\n\n    def __init__(\n        self,\n        formula: Optional[str] = None,\n        data: Optional[pd.DataFrame] = None,\n        theta: Optional[np.ndarray] = None,\n        x: Optional[np.ndarray] = None,\n        order: int = 1,\n        level: float = 0.05,\n    ):\n        if formula and data is not None:\n            self.theta, self.x, self.feature_names = self._parse_formula(formula, data)\n        elif theta is not None and x is not None:\n            self.theta = self._validate_input(theta)\n            self.x = self._validate_input(x)\n            if self.x.ndim == 1:\n                self.x = self.x[:, None]\n            self.feature_names = [f\"x{i}\" for i in range(self.x.shape[1])]\n        else:\n            raise ValueError(\"Provide either a formula + data or theta and x.\")\n\n        self.order = order\n        self.level = level\n\n        # Fit the model\n        self.result = self._fit()\n\n    @staticmethod\n    def _validate_input(arr: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Validate input array and ensure it is in radians.\n        \"\"\"\n        if not isinstance(arr, np.ndarray):\n            raise ValueError(\"Input must be a numpy array.\")\n        return arr % (2 * np.pi)\n\n    def _parse_formula(\n        self, formula: str, data: pd.DataFrame\n    ) -&gt; Tuple[np.ndarray, np.ndarray, List[str]]:\n        theta_col, x_cols = formula.split(\"~\")\n        theta = data[theta_col.strip()].to_numpy()\n        x_cols = [col.strip() for col in x_cols.split(\"+\")]\n        X = data[x_cols].to_numpy()\n        return theta, X, x_cols\n\n    def _fit(self):\n        n = self.x.shape[0]\n        order = self.order\n\n        # Create harmonic terms\n        order_matrix = np.arange(1, order + 1)\n        cos_x = np.cos(self.x * order_matrix)\n        sin_x = np.sin(self.x * order_matrix)\n\n        # Linear models for cos(theta) and sin(theta)\n        Y_cos = np.cos(self.theta)\n        Y_sin = np.sin(self.theta)\n\n        X = np.column_stack([np.ones(n), cos_x, sin_x])\n        beta_cos, _, _, _ = lstsq(X, Y_cos)\n        beta_sin, _, _, _ = lstsq(X, Y_sin)\n\n        # Fitted values\n        cos_fit = X @ beta_cos\n        sin_fit = X @ beta_sin\n        fitted = np.arctan2(sin_fit, cos_fit) % (2 * np.pi)\n\n        # Residuals\n        residuals = (self.theta - fitted) % (2 * np.pi)\n\n        # Circular correlation coefficient\n        rho = np.sqrt(np.mean(cos_fit**2) + np.mean(sin_fit**2))\n\n        # Test higher-order terms\n        higher_order_cos = np.cos((order + 1) * self.x)\n        higher_order_sin = np.sin((order + 1) * self.x)\n\n        # Projection matrix for the current model\n        M = X @ np.linalg.inv(X.T @ X) @ X.T\n        W = np.column_stack([higher_order_cos, higher_order_sin])\n        H = W.T @ (np.eye(n) - M) @ W\n        H_inv = np.linalg.inv(H)\n        N = W @ H_inv @ W.T\n\n        residual_cos = (np.eye(n) - M) @ Y_cos\n        residual_sin = (np.eye(n) - M) @ Y_sin\n\n        T1 = (\n            (n - (2 * order + 1))\n            * (residual_cos.T @ N @ residual_cos)\n            / (residual_cos.T @ residual_cos)\n        )\n        T2 = (\n            (n - (2 * order + 1))\n            * (residual_sin.T @ N @ residual_sin)\n            / (residual_sin.T @ residual_sin)\n        )\n\n        p1 = 1 - chi2.cdf(T1, 2)\n        p2 = 1 - chi2.cdf(T2, 2)\n\n        p_values = np.array([p1, p2])\n\n        # Message about higher-order terms\n        if np.all(p_values &gt; self.level):\n            message = (\n                f\"Higher-order terms are not significant at the {self.level} level.\"\n            )\n        else:\n            message = f\"Higher-order terms are significant at the {self.level} level.\"\n\n        return {\n            \"rho\": rho,\n            \"fitted\": fitted,\n            \"residuals\": residuals,\n            \"coefficients\": {\n                \"cos\": beta_cos,\n                \"sin\": beta_sin,\n            },\n            \"p_values\": p_values,\n            \"message\": message,\n        }\n\n    def summary(self):\n        \"\"\"\n        Print a summary of the regression results.\n        \"\"\"\n        print(\"\\nCircular-Circular Regression\\n\")\n        print(f\"Circular Correlation Coefficient (rho): {self.result['rho']:.5f}\\n\")\n\n        print(\"Coefficients:\")\n        cos_coeffs = self.result[\"coefficients\"][\"cos\"]\n        sin_coeffs = self.result[\"coefficients\"][\"sin\"]\n\n        # Headers\n        print(f\"{'Harmonic':&lt;12} {'Cosine Coeff':&lt;14} {'Sine Coeff':&lt;14}\")\n\n        # Intercept\n        print(f\"{'(Intercept)':&lt;12} {cos_coeffs[0]:&lt;14.5f} {sin_coeffs[0]:&lt;14.5f}\")\n\n        # Group harmonics: Cosine and Sine\n        for i in range(1, len(cos_coeffs)):\n            if i &lt;= self.order:\n                print(\n                    f\"{'cos.x' + str(i):&lt;12} {cos_coeffs[i]:&lt;14.5f} {sin_coeffs[i]:&lt;14.5f}\"\n                )\n            else:\n                print(\n                    f\"{'sin.x' + str(i - self.order):&lt;12} {cos_coeffs[i]:&lt;14.5f} {sin_coeffs[i]:&lt;14.5f}\"\n                )\n\n        print(\"\\nP-values for Higher-Order Terms:\")\n        print(\n            f\"p1: {self.result['p_values'][0]:.5f}, p2: {self.result['p_values'][1]:.5f}\"\n        )\n\n        print(f\"\\n{self.result['message']}\\n\")\n</code></pre>"},{"location":"reference/regression/#pycircstat2.regression.CCRegression.summary","title":"<code>summary()</code>","text":"<p>Print a summary of the regression results.</p> Source code in <code>pycircstat2/regression.py</code> <pre><code>def summary(self):\n    \"\"\"\n    Print a summary of the regression results.\n    \"\"\"\n    print(\"\\nCircular-Circular Regression\\n\")\n    print(f\"Circular Correlation Coefficient (rho): {self.result['rho']:.5f}\\n\")\n\n    print(\"Coefficients:\")\n    cos_coeffs = self.result[\"coefficients\"][\"cos\"]\n    sin_coeffs = self.result[\"coefficients\"][\"sin\"]\n\n    # Headers\n    print(f\"{'Harmonic':&lt;12} {'Cosine Coeff':&lt;14} {'Sine Coeff':&lt;14}\")\n\n    # Intercept\n    print(f\"{'(Intercept)':&lt;12} {cos_coeffs[0]:&lt;14.5f} {sin_coeffs[0]:&lt;14.5f}\")\n\n    # Group harmonics: Cosine and Sine\n    for i in range(1, len(cos_coeffs)):\n        if i &lt;= self.order:\n            print(\n                f\"{'cos.x' + str(i):&lt;12} {cos_coeffs[i]:&lt;14.5f} {sin_coeffs[i]:&lt;14.5f}\"\n            )\n        else:\n            print(\n                f\"{'sin.x' + str(i - self.order):&lt;12} {cos_coeffs[i]:&lt;14.5f} {sin_coeffs[i]:&lt;14.5f}\"\n            )\n\n    print(\"\\nP-values for Higher-Order Terms:\")\n    print(\n        f\"p1: {self.result['p_values'][0]:.5f}, p2: {self.result['p_values'][1]:.5f}\"\n    )\n\n    print(f\"\\n{self.result['message']}\\n\")\n</code></pre>"},{"location":"reference/utils/","title":"Utilities","text":""},{"location":"reference/utils/#pycircstat2.utils.data2rad","title":"<code>data2rad(data, k=360)</code>","text":"<p>Convert data measured on a circular scale to corresponding angular directions.</p> \\[ \\alpha = \\frac{2\\pi \\times \\mathrm{data}}{k} \\] <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray or float</code> <p>Data measured on a circular scale.</p> required <code>k</code> <code>float or int</code> <p>Number of intervals in the full cycle. Default is 360.</p> <code>360</code> <p>Returns:</p> Name Type Description <code>angle</code> <code>ndarray or float</code> <p>Angular directions in radian.</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def data2rad(\n    data: Union[np.ndarray, float, int],\n    k: Union[float, int] = 360,  # number of intervals in the full cycle\n) -&gt; Union[np.ndarray, float]:  # eq(26.1), zar 2010\n    r\"\"\"Convert data measured on a circular scale to\n    corresponding angular directions.\n\n    $$ \\alpha = \\frac{2\\pi \\times \\mathrm{data}}{k} $$\n\n    Parameters\n    ----------\n    data : np.ndarray or float\n        Data measured on a circular scale.\n    k : float or int\n        Number of intervals in the full cycle. Default is 360.\n\n    Returns\n    -------\n    angle: np.ndarray or float\n        Angular directions in radian.\n    \"\"\"\n    return 2 * np.pi * data / k\n</code></pre>"},{"location":"reference/utils/#pycircstat2.utils.time2float","title":"<code>time2float(x, sep=':')</code>","text":"<p>Convert an array of strings in time (hh:mm) to an array of floats.</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def time2float(x: Union[np.ndarray, list, str], sep: str = \":\") -&gt; np.ndarray:\n    \"\"\"Convert an array of strings in time (hh:mm) to an array of floats.\"\"\"\n\n    def _t2f(x: str, sep: str):\n        \"\"\"Convert string of time to float. E.g. 12:45 -&gt; 12.75\"\"\"\n        hr, min = x.split(sep)\n        return float(hr) + float(min) / 60\n\n    t2f = np.vectorize(_t2f)\n    return t2f(x, sep)\n</code></pre>"},{"location":"reference/utils/#pycircstat2.utils.angmod","title":"<code>angmod(rad, bounds=[0, 2 * np.pi])</code>","text":"<p>Normalize angles to a specified range.</p> Parameters: <p>rad : Union[np.ndarray, float, int]     An angle or array of angles in radians. bounds : list, optional     A list or tuple of two values [min, max] defining the target range. Default is [0, 2\u03c0).</p> Returns: <p>Union[np.ndarray, float]     The normalized angle(s), constrained to the specified range.</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def angmod(\n    rad: Union[np.ndarray, float, np.float64, int], bounds: list = [0, 2 * np.pi]\n) -&gt; Union[np.ndarray, float, np.float64]:\n    \"\"\"\n    Normalize angles to a specified range.\n\n    Parameters:\n    -----------\n    rad : Union[np.ndarray, float, int]\n        An angle or array of angles in radians.\n    bounds : list, optional\n        A list or tuple of two values [min, max] defining the target range. Default is [0, 2\u03c0).\n\n    Returns:\n    --------\n    Union[np.ndarray, float]\n        The normalized angle(s), constrained to the specified range.\n    \"\"\"\n    if len(bounds) != 2 or bounds[0] &gt;= bounds[1]:\n        raise ValueError(\n            \"bounds must be a list or tuple with two values [min, max] where min &lt; max.\"\n        )\n\n    bound_min, bound_max = bounds\n    bound_span = bound_max - bound_min\n    result = ((rad - bound_min) % bound_span + bound_span) % bound_span + bound_min\n\n    # Adjust values equal to bound_max to bound_min for consistency\n    if isinstance(result, np.ndarray):\n        result[result == bound_max] = bound_min\n    elif result == bound_max:\n        result = bound_min\n\n    return result\n</code></pre>"},{"location":"reference/utils/#pycircstat2.utils.angular_distance","title":"<code>angular_distance(a, b)</code>","text":"<p>Angular distance between two angles.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[ndarray, list, float]</code> <p>angle(s).</p> required <code>b</code> <code>float</code> <p>target angle.</p> required <p>Returns:</p> Name Type Description <code>e</code> <code>ndarray</code> <p>angular distance</p> Reference <p>P642, Section 27.2, Zar, 2010</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def angular_distance(a: Union[np.ndarray, list, float], b: float) -&gt; np.ndarray:\n    \"\"\"Angular distance between two angles.\n\n    Parameters\n    ----------\n    a: np.ndarray or float\n        angle(s).\n\n    b: float\n        target angle.\n\n    Returns\n    -------\n    e: np.ndarray\n        angular distance\n\n    Reference\n    ---------\n    P642, Section 27.2, Zar, 2010\n    \"\"\"\n\n    if isinstance(a, list):\n        a = np.asarray(a)\n\n    c = angmod(a - b)\n    d = 2 * np.pi - c\n    e = np.min(np.array([c, d]), axis=0)\n\n    return e\n</code></pre>"},{"location":"reference/utils/#pycircstat2.utils.is_within_circular_range","title":"<code>is_within_circular_range(value, lb, ub)</code>","text":"<p>Check if a value lies within the circular range [lb, ub].</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>The value to check.</p> required <code>lb</code> <code>float</code> <p>The lower bound of the range.</p> required <code>ub</code> <code>float</code> <p>The upper bound of the range.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the value is within the circular range, False otherwise.</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def is_within_circular_range(value: float, lb: float, ub: float) -&gt; bool:\n    \"\"\"\n    Check if a value lies within the circular range [lb, ub].\n\n    Parameters\n    ----------\n    value : float\n        The value to check.\n    lb : float\n        The lower bound of the range.\n    ub : float\n        The upper bound of the range.\n\n    Returns\n    -------\n    bool\n        True if the value is within the circular range, False otherwise.\n    \"\"\"\n    value = np.mod(value, 2 * np.pi)\n    lb = np.mod(lb, 2 * np.pi)\n    ub = np.mod(ub, 2 * np.pi)\n\n    if lb &lt;= ub:\n        # Standard range\n        return lb &lt;= value &lt;= ub\n    else:\n        # Wrapping range\n        return value &gt;= lb or value &lt;= ub\n</code></pre>"},{"location":"reference/utils/#pycircstat2.utils.rotate_data","title":"<code>rotate_data(alpha, angle, unit='radian')</code>","text":"<p>Rotate a circular dataset by a given angle, supporting degrees, radians, and hours.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Angles in the specified unit.</p> required <code>angle</code> <code>float</code> <p>Rotation angle in the specified unit.</p> required <code>unit</code> <code>str</code> <p>Unit of measurement (\"degree\", \"radian\", or \"hour\"). Default is \"radian\".</p> <code>'radian'</code> <p>Returns:</p> Name Type Description <code>rotated_alpha</code> <code>ndarray</code> <p>Rotated angles, normalized within the unit's full cycle.</p> Source code in <code>pycircstat2/utils.py</code> <pre><code>def rotate_data(alpha: np.ndarray, angle: float, unit: str = \"radian\") -&gt; np.ndarray:\n    \"\"\"\n    Rotate a circular dataset by a given angle, supporting degrees, radians, and hours.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Angles in the specified unit.\n    angle : float\n        Rotation angle in the specified unit.\n    unit : str, optional\n        Unit of measurement (\"degree\", \"radian\", or \"hour\"). Default is \"radian\".\n\n    Returns\n    -------\n    rotated_alpha : np.ndarray\n        Rotated angles, normalized within the unit's full cycle.\n    \"\"\"\n    if unit == \"degree\":\n        n_intervals = 360\n    elif unit == \"radian\":\n        n_intervals = 2 * np.pi\n    elif unit == \"hour\":\n        n_intervals = 24\n    else:\n        raise ValueError(\"Unit must be 'degree', 'radian', or 'hour'.\")\n\n    # Convert to radians for consistent computation\n    alpha_rad = data2rad(alpha, k=n_intervals)\n    angle_rad = data2rad(angle, k=n_intervals)\n\n    # Perform rotation and normalize in radians\n    rotated_alpha_rad = angmod(alpha_rad + angle_rad, bounds=[0, 2 * np.pi])\n\n    # Convert back to the original unit\n    rotated_alpha = rad2data(rotated_alpha_rad, k=n_intervals)\n\n    return np.asarray(rotated_alpha)\n</code></pre>"},{"location":"reference/visualization/","title":"Visualization","text":""},{"location":"reference/visualization/#pycircstat2.visualization.circ_plot","title":"<code>circ_plot(circ_data, ax=None, config=None)</code>","text":"<p>Plots circular data with various visualization options.</p> <p>Parameters:</p> Name Type Description Default <code>circ_data</code> <code>Circular</code> <p>A Circular object containing the data to plot.</p> required <code>ax</code> <code>Axes</code> <p>The axis to plot on. If None, a new figure is created.</p> <code>None</code> <code>config</code> <code>dict</code> <p>Configuration dictionary that overrides defaults.</p> <ul> <li> <p>\"figsize\" : tuple, default=(5, 5)     Size of the figure in inches.</p> </li> <li> <p>\"projection\" : str, default=\"polar\"     Type of projection used for the plot.</p> </li> <li> <p>\"grid\" : bool, default=True     Whether to display grid lines.</p> </li> <li> <p>\"spine\" : bool, default=False     Whether to show the polar spine.</p> </li> <li> <p>\"axis\" : bool, default=True     Whether to display the axis.</p> </li> <li> <p>\"outward\" : bool, default=True     Determines whether scatter points are plotted outward or inward.</p> </li> <li> <p>\"zero_location\" : str, default=\"N\"     The reference direction for 0 degrees (e.g., \"N\", \"E\", \"S\", \"W\").</p> </li> <li> <p>\"clockwise\" : int, default=-1     Direction of angle increase: -1 for clockwise, 1 for counterclockwise.</p> </li> <li> <p>\"radius\" : dict     Controls radial axis settings:</p> <ul> <li>\"ticks\" : list, default=[0, 1]     Radial tick values.</li> <li>\"lim_max\" : float or None, default=None     Maximum radial axis limit.</li> </ul> </li> <li> <p>\"scatter\" : dict     Controls scatter plot settings:</p> <ul> <li>\"marker\" : str, default=\"o\"     Marker style for scatter points.</li> <li>\"color\" : str, default=\"black\"     Color of scatter points.</li> <li>\"size\" : int, default=10     Size of scatter markers.</li> <li>\"r_start\" : float, default=1     Starting radius for scatter points.</li> </ul> </li> <li> <p>\"rose\" : dict     Controls rose diagram settings:</p> <ul> <li>\"bins\" : int, default=12     Number of bins for histogram.</li> <li>\"counts\" : bool, default=False     Whether to display counts on bars.</li> </ul> </li> <li> <p>\"density\" : dict or bool     Controls density estimation settings:</p> <ul> <li>If False, disables density plotting.</li> <li>If True, uses default settings.</li> <li>If dict, allows customization:<ul> <li>\"method\" : str, default=\"nonparametric\"     Method for density estimation (\"nonparametric\" or \"MovM\").</li> <li>\"color\" : str, default=\"black\"     Color of the density line.</li> <li>\"linestyle\" : str, default=\"-\"     Line style of the density plot.</li> </ul> </li> </ul> </li> <li> <p>\"mean\" : dict or bool     Controls mean direction plotting:</p> <ul> <li>If False, disables mean plot.</li> <li>If True, uses default settings.</li> <li>If dict, allows customization:<ul> <li>\"color\" : str, default=\"black\"     Color of the mean line.</li> <li>\"linestyle\" : str, default=\"-\"     Line style of the mean plot.</li> <li>\"kind\" : str, default=\"arrow\"     Type of mean representation.</li> <li>\"ci\" : bool, default=True     Whether to display mean confidence intervals.</li> </ul> </li> </ul> </li> <li> <p>\"median\" : dict or bool     Controls median direction plotting:</p> <ul> <li>If False, disables median plot.</li> <li>If True, uses default settings.</li> <li>If dict, allows customization:  <ul> <li>\"color\" : str, default=\"black\"     Color of the median line.</li> <li>\"linestyle\" : str, default=\"dotted\"     Line style of the median plot.</li> <li>\"ci\" : bool, default=True     Whether to display median confidence intervals.</li> </ul> </li> </ul> </li> </ul> <code>None</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The matplotlib Axes object containing the plot.</p> Source code in <code>pycircstat2/visualization.py</code> <pre><code>def circ_plot(\n    circ_data,\n    ax=None,\n    config=None,\n):\n\n    \"\"\"Plots circular data with various visualization options.\n\n    Parameters\n    ----------\n    circ_data : Circular\n        A Circular object containing the data to plot.\n    ax : matplotlib.axes._axes.Axes, optional\n        The axis to plot on. If None, a new figure is created.\n    config : dict, optional\n        Configuration dictionary that overrides defaults.\n\n        - **\"figsize\"** : tuple, default=(5, 5)  \n            Size of the figure in inches.\n\n        - **\"projection\"** : str, default=\"polar\"  \n            Type of projection used for the plot.\n\n        - **\"grid\"** : bool, default=True  \n            Whether to display grid lines.\n\n        - **\"spine\"** : bool, default=False  \n            Whether to show the polar spine.\n\n        - **\"axis\"** : bool, default=True  \n            Whether to display the axis.\n\n        - **\"outward\"** : bool, default=True  \n            Determines whether scatter points are plotted outward or inward.\n\n        - **\"zero_location\"** : str, default=\"N\"  \n            The reference direction for 0 degrees (e.g., \"N\", \"E\", \"S\", \"W\").\n\n        - **\"clockwise\"** : int, default=-1  \n            Direction of angle increase: -1 for clockwise, 1 for counterclockwise.\n\n        - **\"radius\"** : dict  \n            Controls radial axis settings:\n            - **\"ticks\"** : list, default=[0, 1]  \n                Radial tick values.\n            - **\"lim_max\"** : float or None, default=None  \n                Maximum radial axis limit.\n\n        - **\"scatter\"** : dict  \n            Controls scatter plot settings:\n            - **\"marker\"** : str, default=\"o\"  \n                Marker style for scatter points.\n            - **\"color\"** : str, default=\"black\"  \n                Color of scatter points.\n            - **\"size\"** : int, default=10  \n                Size of scatter markers.\n            - **\"r_start\"** : float, default=1  \n                Starting radius for scatter points.\n\n        - **\"rose\"** : dict  \n            Controls rose diagram settings:\n            - **\"bins\"** : int, default=12  \n                Number of bins for histogram.\n            - **\"counts\"** : bool, default=False  \n                Whether to display counts on bars.\n\n        - **\"density\"** : dict or bool  \n            Controls density estimation settings:\n            - **If False**, disables density plotting.\n            - **If True**, uses default settings.\n            - **If dict**, allows customization:\n                - **\"method\"** : str, default=\"nonparametric\"  \n                    Method for density estimation (\"nonparametric\" or \"MovM\").\n                - **\"color\"** : str, default=\"black\"  \n                    Color of the density line.\n                - **\"linestyle\"** : str, default=\"-\"  \n                    Line style of the density plot.\n\n        - **\"mean\"** : dict or bool  \n            Controls mean direction plotting:\n            - **If False**, disables mean plot.\n            - **If True**, uses default settings.\n            - **If dict**, allows customization:\n                - **\"color\"** : str, default=\"black\"  \n                    Color of the mean line.\n                - **\"linestyle\"** : str, default=\"-\"  \n                    Line style of the mean plot.\n                - **\"kind\"** : str, default=\"arrow\"  \n                    Type of mean representation.\n                - **\"ci\"** : bool, default=True  \n                    Whether to display mean confidence intervals.\n\n        - **\"median\"** : dict or bool  \n            Controls median direction plotting:\n            - **If False**, disables median plot.\n            - **If True**, uses default settings.\n            - **If dict**, allows customization:  \n                - **\"color\"** : str, default=\"black\"  \n                    Color of the median line.\n                - **\"linestyle\"** : str, default=\"dotted\"  \n                    Line style of the median plot.\n                - **\"ci\"** : bool, default=True  \n                    Whether to display median confidence intervals.\n\n    Returns\n    -------\n    ax : matplotlib.axes._axes.Axes\n        The matplotlib Axes object containing the plot.\n    \"\"\"\n\n    # Merge user config with defaults recursively\n    config = _merge_dicts(DEFAULT_CIRC_PLOT_CONFIG, config or {})\n\n    # check axes\n    if ax is None:\n        fig, ax = plt.subplots(\n            figsize=config[\"figsize\"],\n            subplot_kw={\"projection\": config[\"projection\"]},\n            layout=\"constrained\",\n        )\n\n    # plot\n    if not circ_data.grouped:\n\n        # plot scatter\n        alpha, counts = np.unique(circ_data.alpha.round(3), return_counts=True)\n        alpha = np.repeat(alpha, counts)\n\n        if config[\"outward\"]:\n            radii = np.hstack(\n                [\n                    config[\"scatter\"][\"r_start\"]\n                    + 0.05\n                    + np.arange(0, 0.05 * int(f), 0.05)[: int(f)]\n                    for f in counts\n                ]\n            )\n        else:\n            radii = np.hstack(\n                [\n                    config[\"scatter\"][\"r_start\"]\n                    - 0.05\n                    - np.arange(0, 0.05 * int(f), 0.05)[: int(f)]\n                    for f in counts\n                ]\n            )\n        ax.scatter(\n            alpha, radii, \n            marker=config[\"scatter\"][\"marker\"], \n            color=config[\"scatter\"][\"color\"], \n            s=config[\"scatter\"][\"size\"]\n        )\n\n        # plot density\n        if config[\"density\"]:  # and not np.isclose(circ_data.r, 0):\n\n            density_method = config[\"density\"].get(\"method\", \"nonparametric\")\n            density_color = config[\"density\"].get(\"color\", \"black\")\n            density_linestyle = config[\"density\"].get(\"linestyle\", \"-\")\n\n            if density_method == \"nonparametric\":\n                h0 = config[\"density\"].get(\n                    \"h0\", compute_smooth_params(circ_data.r, circ_data.n)\n                )\n                x, f = nonparametric_density_estimation(circ_data.alpha, h0)\n\n            elif density_method == \"MovM\":\n\n                x = np.linspace(0, 2 * np.pi, 100)\n                f = circ_data.mixture_opt.predict_density(x=x, unit=\"radian\")\n\n            else:\n                raise ValueError(\n                    f\"`{config['density']['method']}` in `density` is not supported.\"\n                )\n\n            # save density to circ_data\n            circ_data.density_x = x\n            circ_data.density_f = f\n            f_ = f + 1.05  # add the radius of the plotted circle\n            ax.plot(\n                x,\n                f_,\n                color=density_color,\n                linestyle=density_linestyle,\n            )\n            if config[\"radius\"][\"lim_max\"] is None:\n                ax.set_ylim(0, f_.max())\n            else:\n                ax.set_ylim(0, config[\"radius\"][\"lim_max\"])\n        else:\n            if config[\"radius\"][\"lim_max\"] is None:\n                ax.set_ylim(0, radii.max() + 0.025)\n            else:\n                ax.set_ylim(0, config[\"radius\"][\"lim_max\"])\n\n    # plot rose diagram\n    if config[\"rose\"]:\n\n        if not circ_data.grouped:\n            alpha = circ_data.alpha\n            w, beta = np.histogram(\n                alpha, bins=config[\"rose\"][\"bins\"], range=(0, 2 * np.pi)\n            )  # np.histogram return bin edges\n            beta = 0.5 * (beta[:-1] + beta[1:])\n        else:\n            w = circ_data.w\n            beta = circ_data.alpha\n\n        w_sqrt = np.sqrt(w)\n        w_norm = w_sqrt / w_sqrt.max()\n\n        width = config.get(\"width\", 2 * np.pi / len(beta))\n\n        bars = ax.bar(\n            beta,\n            w_norm,\n            width=width,\n            color=config[\"rose\"][\"color\"],\n            ec=config[\"rose\"][\"edgecolor\"],\n            alpha=config[\"rose\"][\"alpha\"],\n            bottom=0,\n            zorder=2,\n        )\n        if config[\"rose\"][\"counts\"]:\n\n            for i, v in enumerate(w):\n\n                angle = rotation = beta[i].round(3)\n                if angle &gt;= np.pi / 2 and angle &lt; 3 * np.pi / 2:\n                    # alignment = \"right\"\n                    rotation = rotation + np.pi\n                # else:\n                #     alignment = \"left\"\n\n                if v != 0:\n                    ax.text(\n                        x=angle,\n                        y=bars[i].get_height() - 0.075,\n                        s=str(v),\n                        ha=\"center\",\n                        va=\"center\",\n                        rotation=rotation,\n                        rotation_mode=\"anchor\",\n                        color=\"black\",\n                    )\n\n        if circ_data.grouped and config[\"density\"]:\n            x = np.linspace(0, 2 * np.pi, 100)\n            f = circ_data.mixture_opt.predict_density(x=x, unit=\"radian\") + 1\n            ax.plot(x, f, color=\"black\", linestyle=\"-\")\n            if config[\"rlim_max\"] is None:\n                ax.set_ylim(0, f.max())\n            else:\n                ax.set_ylim(0, config[\"rlim_max\"])\n    else:\n        w = circ_data.w\n        config[\"radius\"][\"ticks\"] = [1]  # overwrite\n\n    if config[\"mean\"]:\n\n        radius = circ_data.r\n\n        ax.plot(\n            [0, circ_data.mean],\n            [0, radius],\n            color=config[\"mean\"].get(\"color\", \"black\"),\n            ls=config[\"mean\"].get(\"linestyle\", \"-\"),\n            label=\"mean\",\n            zorder=5,\n        )\n\n        if config[\"mean\"][\"ci\"]:\n\n            if circ_data.mean_lb &lt; circ_data.mean_ub:\n                x1 = np.linspace(circ_data.mean_lb, circ_data.mean_ub, num=50)\n            else:\n                x1 = np.linspace(\n                    circ_data.mean_lb, circ_data.mean_ub + 2 * np.pi, num=50\n                )\n\n            # plot arc\n            ax.plot(\n                x1,\n                np.ones_like(x1) * radius,\n                ls=\"-\",\n                color=config[\"mean\"][\"color\"],\n                zorder=5,\n                lw=2,\n            )\n            # plot arc cap\n            ax.errorbar(x1[0], radius, yerr=0.03, capsize=0, color=config[\"mean\"][\"color\"], lw=2)\n            ax.errorbar(x1[-1], radius, yerr=0.03, capsize=0, color=config[\"mean\"][\"color\"], lw=2)\n\n    if config[\"median\"]:\n        ax.plot(\n            [0, circ_data.median],\n            [0, 0.95],\n            color=config[\"median\"][\"color\"],\n            ls=config[\"median\"].get(\"linestyle\", \"dotted\"),\n            label=\"median\",\n            zorder=5,\n        )\n\n        if config[\"median\"][\"ci\"]:\n            if circ_data.median_lb &lt; circ_data.median_ub:\n                x1 = np.linspace(circ_data.median_lb, circ_data.median_ub, num=50)\n            else:\n                x1 = np.linspace(\n                    circ_data.median_lb, circ_data.median_ub + 2 * np.pi, num=50\n                )\n            # plot arc\n            ax.plot(\n                x1,\n                np.ones_like(x1) - 0.05,\n                ls=\"dotted\",\n                color=config[\"median\"][\"color\"],\n                zorder=5,\n                lw=2,\n            )\n            # plot arc cap\n            ax.errorbar(x1[0], 0.95, yerr=0.03, capsize=0, color=config[\"median\"][\"color\"], lw=2)\n            ax.errorbar(x1[-1], 0.95, yerr=0.03, capsize=0, color=config[\"median\"][\"color\"], lw=2)\n\n    ax.set_theta_zero_location(config[\"zero_location\"])\n    ax.set_theta_direction(config[\"clockwise\"])\n    ax.grid(config[\"grid\"])\n    ax.axis(config[\"axis\"])\n    ax.spines[\"polar\"].set_visible(config[\"spine\"])\n    ax.set_rgrids(config[\"radius\"][\"ticks\"], [\"\" for _ in range(len(config[\"radius\"][\"ticks\"]))], fontsize=16)\n\n    if circ_data.unit == \"hour\":\n        position_major = np.arange(0, 2 * np.pi, 2 * np.pi / 8)\n        position_minor = np.arange(0, 2 * np.pi, 2 * np.pi / 24)\n        labels = [f\"{i}:00\" for i in np.arange(0, circ_data.full_cycle, 3)]\n        ax.xaxis.set_major_locator(ticker.FixedLocator(position_major))\n        ax.xaxis.set_minor_locator(ticker.FixedLocator(position_minor))\n        ax.xaxis.set_major_formatter(ticker.FixedFormatter(labels))\n\n    gridlines = ax.yaxis.get_gridlines()\n    gridlines[-1].set_color(\"k\")\n    gridlines[-1].set_linewidth(1)\n\n    if config[\"median\"] or config[\"mean\"]:\n        ax.legend(frameon=False)\n\n    return ax\n</code></pre>"}]}